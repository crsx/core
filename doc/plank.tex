\documentclass[letterpaper,11pt]{article}

%% Style.
%\usepackage{charter}
\renewcommand{\rmdefault}{pplx}
\usepackage{eulervm}
\bibliographystyle{plain}
\usepackage[margin=1in]{geometry}

%% Format.
\input{setup}
\usepackage{cite}
\usepackage{stmaryrd}

%% Topmatter.
\title{ \hax: A Plank for Higher-order Attribute Contraction Schemes }
\author{%
  Cynthia Kop \\
  University of Copenhagen
  \and
  Kristoffer H. Rose \\
  Two Sigma Investments, LLC
  \and
  Maria Schett \\
  University of Innsbruck
  \and
  Lionel Villard \\
  IBM Research
}

%% Discussion
\newcommand{\CK}[1]{\textcolor{blue}{CK: #1}}
\newcommand{\KR}[1]{\textcolor{red}{KR: #1}}
\newcommand{\LV}[1]{\textcolor{green}{LV: #1}}
\newcommand{\MS}[1]{\textcolor{violet}{MS: #1}}
\newcommand{\JN}[1]{\textcolor{orange!70!black}{JN: #1}}

\begin{document}
\maketitle

\begin{abstract}\noindent
  %%
  We present \hax, a core (or ``plank'') calculus that can serve as the foundation for the \CRSX
  (Combinatory Reductions Systems with eXtensions) and \HAX (Higher-order Attribute Contraction
  Schemes) compiler specification languages.
  %%
  Formally, \hax is a general higher order rewriting formalism extended with first class
  \emph{associations}, and equipped with a parametric polymorphic sort system.
  %%
  In this paper we give the formal definition of the \hax calculus and its sort system, and we show
  how the central constructs of the much richer \HAX and \CRSX formalisms can be represented in
  \hax. We also outline how \hax can be implemented, and summarize central properties of the system.

  \CK{Cynthia!} \KR{Kris!} \LV{Lionel!} \MS{Maria!} \JN{Julian!}
\end{abstract}

\compacttableofcontents

%------------------------------------------------------------------------

\section{Introduction}\label{sec:intro}

Several systems that manipulate programs, so-called \emph{meta-programming} systems, have emerged
over the years, ranging from generic specification languages, where the goal is not to define how
but only declare the semantics of the program manipulation, all the way to tools that support
specific aspects of program execution or compiler generation.

One direction has been to combine \emph{higher order rewriting}~\cite{Jouannaud:klop2005} with
\emph{higher order abstract syntax} (HOAS) \cite{PfenningElliot:pldi1988}. This approach is used by
\CRSX (Combinatory Reduction Systems with eXtensions)~\cite{Rose:1996}, developed for writing
industrial compilers at IBM Research~\cite{Rose:hor2010,Rose:rta2011,dp60:ibm2013}, and the derived
system \HAX (Higher-order Attribute Contration Schemes)~\cite{Rose:ts2015}, developed to teach
compiler construction at NYU~\cite{RoseRose:cims2015}.

However, the direct implementation of the full \CRSX language~\cite{crsx} turned out to be quite
complex, and over time we have developed notions of what the ``core'' elements of the language
are. At the same time, \HAX has highlighted what additional programming paradigms one should add to
get a more useful programming language for writing compilers.

\hax is our attempt at providing such a foundation.  \hax is specifically based on Aczel's
\emph{Contraction Schemes}~\cite{Aczel:1978} (where the restriction we shall see of only permitting
abstractions as constrution arguments is first found) with the substitution notion from Klop's
\emph{Combinatory Reduction Systems}~\cite{Klop+:tcs1993} and imposing a typing discipline similar
to the the second-order limitation of Blanqui's \emph{Inductive Data Type
  Systems}~\cite{BlanquiJouannaudOkada:tcs2002}. The novelty of \hax is the mechanism used to add
first class \emph{environments} and \emph{free variables}, and integrates those with the type
discipline; these features are derived from the CRSX system~\cite{Rose:rta2011}, where they were
never provided a formal foundation.

\TBD{Example of complex feature that can be simplified.}

The \hax calculus, presented here, represents the synthesis or what we have found to be the
essential features of a system for implementing most features of compilers.

\TBD{Plan}%
and finally Section~\ref{sec:conc} concludes and compares to related work.

%------------------------------------------------------------------------

\section{Overview}
\label{sec:overview}

In this section we outline the \hax calculus, and give several examples.

\begin{notation}[vectors]
  We will use \emph{vector notation} with $\ov{X}$ denoting $X_1,…,X_n$ for some $n≥0$. Inside
  brackets we'll allow use of ``nothing'' as the empty vector, elsewhere we use the explicit
  symbol~$ε$.  Vectors are combined by simple concatenation with ``$,$'' (comma) if needed. We will
  freely abuse this notation and, for example, write $\ov{[\ov{x}]x}$ as an abbreviation of the nested
  $[x_{11}…x_{1m_1}]x_1,…,[x_{n1}…x_{nm_n}]x_n$ for suitable $n,m_1,…,m_n ≥ 0$. We further abuse the
  notation by letting $\ov{\mathcal{S}}$ denote the set of all vectors from any base
  set~$\mathcal{S}$.
\end{notation}

\begin{figure}[h!t]
  \begin{align}
    \tag{\hax{}Script}
    H &::= \ov{D} 
    \\
    \tag{Declaration}
    D &::= S~\kw{data}~d\,\kw(\,\ov{F}\,\kw)\,\kw;
    \bigm| S~\kw{scheme}~f\,\kw(\,\ov{F}\,\kw)\,\kw;
    \bigm| S~\kw{variable}\,\kw;
    \bigm| S~\kw{rule}~M~\kw{$→$}~M\,\kw;
    \\
    \tag{Form}
    F &::= \kw[\,\ov{S}\,\kw]\,S
    \bigm| \kwm\{\, S:S \,\kwm\}
    \\
    \tag{Sort}
    S &::= s\,\kwm{⟨}\,\ov{S}\,\kwm{⟩}
    \bigm| α
    \\[\jot]
    \tag{Meta-Term}
    M &::= c\,\kw(\,\ov{P}\,\kw)
    \bigm| v
    \bigm| m\,\kw(\,\ov{M}\,\kw)
    \\
    \tag{Piece}
    P &::= \kw[\,\ov{v}\,\kw]\,M
    \bigm| \kwm\{\, \ov{A} \,\kwm\}
    \\
    \tag{Association}
    A &::= M\,\kw:\,M
    \bigm| \kw{$¬$}\,M
    \bigm| \kw\,m\,\kw(\,\ov{v}\,\kw)
  \end{align}
  \vspace*{-2em}
  \caption{\hax syntax.}
  \label{fig:syntax}
\end{figure}

\begin{definition}[\hax syntax]\label{def:syntax}
  %%
  The \hax syntax is shown in Figure~\ref{fig:syntax}. The top level of a \hax script is $H$ and the
  grammar assumes that we have three categories of identifier tokens defined:
  %%
  \begin{itemize}

  \item $c,s,d,f ∈ \mathcal{C}$ stand for \emph{constructor} tokens, which are capitalized words
    like "Integer" or "A" or "CamelCaseWord" or "Λρ". They are used for sort, function symbol, and data
    symbol names. By convention, we use $s$/$d$/$f$ for sort/data/function names, respectively, and
    $c$ when either a data or function constructor makes sense.  

  \item $v,α ∈ \mathcal{V}$ stand for \emph{variable} tokens, which are lower case words like "x" or
    "foo" or even "lowWord", used for plain variables and sort variables (respectively).

  \item $m ∈ \mathcal{M}$ stands for \emph{meta-variable} tokens, which are tokens that start with
    "#" like "#arg" or "#BigFoot" or even just "#1" or merely~"#".

  \end{itemize}
  %%
  Finally, we allow \emph{comments} in \hax scripts from "//" to the end of lines.
  %%
\end{definition}

We shall use the following terminology:
%% 
\begin{itemize}

\item A meta-term of the form $c(P_1,…,P_n)$, for $n≥0$, is called a \emph{construction}; if furthermore
  the top symbol $c$ is declared with a "scheme c {…}" declaration then it is called a
  \emph{function construction}, and if it is declared with "data c {…}" then it is called a
  \emph{data construction}. If $n=0$, i.e., the function or data symbol does not take any arguments,
  we usually drop the $()$. That is, we write $0$ instead of $0()$.

\item Argument ``pieces'' $P$ of constructions take one of two forms: \emph{scopes} $[v_1,…,v_n]M$,
  $n≥0$, which introduce new local variables $v_1,…,v_n$ along with a meta-term $M$ wherein they can
  occur, and \emph{associations} $\{A_1,…,A_n\}$, $n≥0$, where each $A$ is either an \emph{entry}
  $M:M$, an \emph{exclusion} $¬M$, or a \emph{catcher} $m(v_1,…,v_n)$, $n≥0$.

  For scopes, if $n=0$, \ie, there are no new variables introduced by the scope, then $[]$ can be
  omitted: we write $S(0)$ instead of $S([]0)$.

\item A meta-term of the form $m(M_1,…,M_n)$, $n≥0$, is a \emph{meta-application}.  A meta-term that
  does not contain any meta-applications, exclusions, or catchers, is called (simply) a \emph{term}.

  Terms are the primary objects in the system, which the rules define a relation on.
  We will consider in particular rules where all variables are bound or \emph{syntactic}
  (more about this later).

\item A meta-term of the form $v$ is a \emph{variable occurrence}; if the variable $v$ occurs contained
  in a scope $[…v…]M$ then the variable occurrence is \emph{bound}.

\item \TBD{Bullet on \kw{rule}.}

\item \TBD{Bullet on \kw{variable}.}

\item \TBD{Bullet on the use of sorts.}

\end{itemize}

In summary, we distinguish four different ways to brace elements. For data and scheme
\emph{subterms}, and for \emph{meta-application arguments} we use $\kw{(…)}$.  For \emph{binders} we
use $\kw{[…]}$.  For \emph{associations} we use $\kwm{\{…\}}$.  For \emph{sort parameters} we use
$\kwm{⟨…⟩}$.

The \hax formalism includes traditional ``constructor'' term rewriting systems, where there is a
distinction between \emph{defined} symbols (\hax function constructors) and undefined symbols (\hax
data constructors).

\begin{example}\label{ex:peano}
  The classical first order \emph{Peano arithmetic} rules can be encoded as the following simple
  \hax system:
  %% 
  \begin{hacs}[numbers=right,texcl]
    // N is natural number sort
    N data Z ;                                            // zero
    N data S(N) ;                                         // successor
    N scheme Plus(N, N) ;                                // $+$ operator
    N rule Plus(Z, #2) →  #2 ;                           // $0+x = x$
    N rule Plus(S(#1), #2) →  S(Plus(#1, #2)) ;          // $(1+x)+y=1+(x+y)$
  \end{hacs}
  %%
  The example illustrates how a sort is defined with data constructors and a scheme for
  rewriting:
  %%
  \begin{itemize}

  \item The defined sort is "N". All the other declarations define artifacts of sort~"N". (Notice
    that we have omitted the empty sort parameter list, it is really "N⟨⟩".)

  \item There are two \kw{data} constructors declared: "Z" with no parameters, and "S" with a single
    numeric argument. Again we write "Z" instead of the full "Z()".

  \item There is a single function (\kw{scheme}) constructor, "Plus", with two numeric
    arguments.

  \item There are two \kw{rule}s for the function symbol, implementing the usual Peano addition
    rules. Since the contained scopes have no binders or meta-application arguments, we write, \eg,
    "Plus(Z,#2)" instead of the full "Plus([]Z(),[]#2())".

  \end{itemize}
  %%
  A sample rewrite sequence using this system, corresponding to the computation $1+1=2$, is
  %%
  \begin{displaymath}
    "Plus(S(Z), S(Z))" →
    "S(Plus(Z, S(Z)))" →
    "S(S(Z))"
  \end{displaymath}
  %%
\end{example}

\hax includes traditional higher-order rewriting systems (again with distinct defined symbols).
Indeed, \hax is specifically based on Aczel's \emph{Contraction Schemes}~\cite{Aczel:1978} (where
the restriction of only permitting abstractions as constrution arguments is first found) with the
substitution notion from Klop's \emph{Combinatory Reduction Systems}~\cite{Klop+:tcs1993} and
imposing a typing discipline similar to the second-order limitation of Blanqui's \emph{Inductive
  Data Type Systems}~\cite{BlanquiJouannaudOkada:tcs2002}. \hax then adds first class
\emph{environments}, and integrates those with the type discipline.

To illustrate the use of the higher-order rewriting features of \hax, we return to a classic.

\begin{example}\label{ex:lambda}
  %%
  The \emph{untyped λ calculus} can be encoded in \hax directly:
  %%
  \begin{hacs}[numbers=right,texcl]
    // Λ is the sort of λ terms
    Λ  data Lm([Λ]Λ) ;                                        // abstraction
    Λ  scheme Ap(Λ, Λ) ;                                      // application
    Λ  rule Ap(Lm([x]#body(x)), #arg) →  #body(#arg) ;    // β-reduction
  \end{hacs}
  %%
  The declarations can be explained as follows:
  %%
  \begin{itemize}

  \item "Λ" includes an abstraction construction, which is a "data" case, and which includes a
    subterm with a single binder scoped over that subterm. The scoped subterm is written as
    "[Λ]Λ", which should be read as ``a subterm with a locally bound variable of sort "Λ" and a
    body of sort "Λ" in which it can occur.''

  \item "Λ" includes a usual case for application construction, which is a "scheme" because it
    can (sometimes) be rewritten.

  \item We specify one rewrite "rule" for "Λ": β-reduction. As usual, the rule specifies how an
    application of an abstraction is simplified. The interesting aspect of the pattern is how the
    abstraction is matched: the part of the pattern "[x]#body(x)" means ``the scoped subterm with
    binder "x" and subterm "#bind" wherein we keep track of where "x" occurs.'' Note the similarity
    to the declaration of the subterm of the "Lm" constructor. Another interesting issue is that the
    β-reduction rule is a \emph{partial} scheme: it is not defined for all possible forms of the
    "Ap" construction, only for those where the first subterm is an "Lm" ``abstraction.'' This
    creates the possibility for ``stuck'' application, just like in the actual λ calculus.

    \CK{This partiality is debatable: in fact, the scheme is defined for all constructor-terms
    with output sort Λ.  It is only undefined for variables, but the same could be said for the
    Plus rules! I suppose the difference is that the Plus system does not admit closed terms
    containing a variable, while this system does.  But if that is the crucial point, it should
    be explained more fully, or not be brought up at all.}

  \item Once an application of an abstraction is matched, the "rule" gives the result of
    simplification as "#body(#arg)", which means that we construct a copy of "#body" except all
    occurrences of the variable we matched (and kept track of) in the pattern "#body(x)" are
    substituted with what "#arg" matched.

    \TBD{Also explain why things are sort correct.}

  \end{itemize}
  %%
  A usual λ term like $(λx.x x)(λy.y)$ simplifies like this:
  %%
  \begin{displaymath}
    "Ap(Lm([x]Ap(x, x)), Lm([y]y))" →
    "Ap(Lm([y]y), Lm([y]y))" →
    "Lm([y]y))"
  \end{displaymath}
  %%
  Notice that \hax describes the classic untyped λ-calculus with ``normalization'' all the way to
  \emph{normal form}: there are no constraints on simplification under binders, and no implied
  evaluation order like ``call-by-value.'' Furthermore, because variables can only be introduced
  through the scope mechanism, the $Λ$ sort can only express and simplify \emph{closed} λ-terms.
  %%
  \CK{Oh? What about representing a variable as a variable?  Can you not make your start term
  Ap(x,y)?}
\end{example}

As a many-sorted rewriting formalism, \hax also supports traditional recursive data structures.

\begin{example}\label{ex:list}
  The sort of \emph{polymorphic lists} can be described as follows, with a ``map'' operator to apply
  a function to each member of the list.
  %%
  \begin{hacs}[numbers=right]
    List⟨α⟩ data Nil; List⟨α⟩ data Cons(α, List⟨α⟩);
    List⟨α⟩ scheme Map([β]α, List⟨β⟩);
    List⟨α⟩ rule Map([x]#(x), Nil) →  Nil;
    List⟨α⟩ rule Map([x]#(x), Cons(#1, #2)) →  Cons(#(#1), Map([x]#(x), #2));
  \end{hacs}
  %%
  The target sort "List⟨α⟩" captures lists where the elements are of the unknown sort~"α".
  %%
  Line~1 defines the two data constructors for lists, "Nil" and "Cons", the latter with the usual
  arguments.
  %%
  Line~2 declares the "Map" scheme in the usual way, using a \hax scope as a representation of the
  function to apply to all members.
  %%
  Lines 3~and 4 then give the usual rules for simplifying a mapping; in line~4, the function is
  applied in the same way that we saw for the untyped λ-calculus: the pattern (left side of "→")
  captures the function's effect as $x↦\#(x)$ with "[x]#(x)", and the contraction (right side of
  "→") applies the captured function to the first element with "#(#1)".

  An example simplification would be
  %%
  \begin{displaymath}
    "Map([x]S(x), Cons(Z, Nil))"
    → "Cons(S(Z), Map([x]S(x), Nil))"
    → "Cons(S(Z), Nil)"
  \end{displaymath}
  %%
  Notice that there is no ``apply'' operator: the formalism \emph{immediately} performs the
  substitution as part of the "Map" rewrite step.
  %%
\end{example}

In addition to being a higher-order rewriting formalism, \hax allows ``free'' variables in terms and
rules, with some restrictions. This is what the \kw{variable} declaration is for.

\begin{example}\label{ex:lambda-x}
  %%
  Here is an example from the literature, $λ$x~\cite{BlooRose:csn1995}, which changes the λ calculus
  from Example~\ref{ex:lambda} in two ways:
  %%
  \begin{enumerate}

  \item Variables are made \emph{syntactic}: they are declared with "variable", so they \emph{can}
    be matched in rules but in turn \emph{only} substituted by other free variables.

  \item The β-reduction rule is replaced with a new scheme "Ex", which performs the substitution
    explicitly, without appealing to the primitive substitution of \hax except for renaming.

  \end{enumerate}
  %%
  The rules in \hax for the system follow the original presentation closely.
  %%
  \begin{hacs}[numbers=right,texcl]
     Λx variable; // the sort uses explicit variables
     Λx data Lm([Λx]Λx); // abstraction
 
     Λx scheme Ap(Λx,Λx); // application
     Λx rule Ap(Lm([x]#(x)),#x) → Ex([x]#(x),#x);  // (b) ``β-introduction''
 
     Λx scheme Ex([Λx]Λx,Λx); // (x\_) rules for ``explicit substitution''
     Λx rule Ex([x]x,#x) → #x;  // (xv)
     Λx rule Ex([x]y,#x) → y;   // (xvgc)
     Λx rule Ex([x]Ap(#f(x), #a(x)), #x) →  Ap(Ex([x]#f(x),#x), Ex([x]#a(x),#x));  // (xap)
     Λx rule Ex([x]Lm([y]#(x,y)), #x) →  Lm([y]Ex([x]#(x,y), #x));                 // (xab)
  \end{hacs}
  %%
  \CK{Do we want to allow this (non-constructor rules) in the long run?  I doubt it's
  going to be a problem for the core calculus, of course, as it's simply a restriction...}

  Two of the rules are only possible because of the \kw{variable} classification for "Λx": the
  \thetag{xv} and \thetag{xvgc} rules (in lines 8 and 9, respectively). This is because these rules
  match \emph{explicit} variable names in the pattern. For \thetag{xv}, the pattern explicitly
  matches just "Ex" instances where the first argument is a scope that binds a variable and then
  have just a single occurrence of that variable. For \thetag{xvgc}, the pattern explicitly matches
  just "Ex" instances where the first argument is a scope that binds a variable and then have just a
  single occurrence of a \emph{different} variable. The latter is ensured by the way matching is
  defined in terms of the usual ``variable convention'' for higher order terms: bound and free
  variables in a term \emph{must} be distinct, so the condition "x"$≠$"y" is implicit.

  An example evaluation would be the following (where every arrow is marked with the rule name):
  %%
  \begin{align*}
    \lefteqn{ \hacsc|Ap(Lm([x]Ap(x, x)), Lm([y]y))| }\qquad\qquad\\
    &\hbox to 3em{$→_{\text{b}}$\hfil}  \hacsc|Ex([x]Ap(x, x), Lm([y]y))| \\
    &\hbox to 3em{$→_{\text{xap}}$\hfil}  \hacsc|Ap(Ex([x]x, Lm([y]y)), Ex([x]x, Lm([y]y)))| \\
    &\hbox to 3em{$→_{\text{xv}}$\hfil}  \hacsc|Ap(Lm([y]y), Ex([x]x, Lm([y]y)))| \\
    &\hbox to 3em{$→_{\text{xv}}$\hfil}  \hacsc|Ap(Lm([y]y), Lm([y]y))| \\
    &\hbox to 3em{$→_{\text{b}}$\hfil}  \hacsc|Ex([y]y, Lm([y]y))| \\
    &\hbox to 3em{$→_{\text{xv}}$\hfil}  \hacsc|Lm([y]y)| \\
  \end{align*}
  %%
\end{example}

Formally, when a sort has a \kw{variable} declaration then it is said to have \emph{syntactic
  variables}, which has some consequences:
%%
\begin{itemize}

\item variables of that sort may occur unbound in the meta-terms whose reduction you consider
  (others will only occur bound);

  \CK{Mind if I change meta-terms to terms here?}

\item you can \emph{match} on an explicit variable (either bound or free) of one of these sorts;

\item variables of these sorts may occur free in the right-hand side of a rule, which corresponds to
  \emph{creating} new ``fresh'' variables in the contracted term.

\item substitution is restricted to variables for the sort.

  \CK{You mean, substition is not permitted for variables of the sort?}

\end{itemize}
%%
So it is not possible to combine the "Λ" sort from Example~\ref{ex:lambda} with "Λx" from
Example~\ref{ex:lambda-x}: each sort is either ``classic'' higher-order, like "Λ", or ``syntactic''
higher-order, like "Λx", but never both.





\KR{Examples under here need further work…}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Abstract Syntax.
Program⟨α,β⟩ data Block(α, β, Program⟨α,β⟩);
Program⟨α,β⟩ data Then(Program⟨α,β⟩, Program⟨α,β⟩);
Program⟨α,β⟩ data Stat(α);

// Type Environment.
Γ⟨α,β⟩ data Env({α:β});

// Create environment from Program
Γ⟨α,β⟩ scheme Mk(Program⟨α,β⟩);
Γ⟨α,β⟩ rule Mk(Stat(#)) → Env({});
Γ⟨α,β⟩ rule Mk(Then(#1, #2)) → Union(Mk(#1), Mk(#2));
Γ⟨α,β⟩ rule Mk(Block(#x, #t, #)) → Union(Env({#x : #t}, Mk(#)));

// Helper to create union of two environments.
Γ⟨α,β⟩ scheme Union(Γ⟨α,β⟩, Γ⟨α,β⟩);
Γ⟨α,β⟩ rule Union(Env({#1}), Env({#2})) → Env({#1,#2});
  \end{hacs}
  \caption{Type environment over simple AST.}
  \label{fig:te}
\end{figure}

\begin{example}[environment handling]\label{ex:te}
  %%
  Figure~\ref{fig:te} shows sorts and rules for 
  %%
\CK{This example is interesting, because it combines two catchers in
the same association set on the right! I wonder how that's defined.
(Although it's easily avoided if undesirable, by simply replacing the
``union'' by an ``add''.)}
\KR{Indeed! I think Lionel has it implemented as ``add''…but here we should describe the ideal as
 long as it allows for add, I think.}
\CK{So what \emph{should} the semantics be?  If there are conflicting
 pairs in \#1 and \#2, what happens? Does the first or the second take
 priority, or should it crash?}
\LV{Yes it's implemented as add. In this case the semantic could
be \#2 is added to \#1. Entries in \#2 override entries in \#1.}

\JN{So, is the conclusion that we have a biased union? that seems a bit awkward though, doesn't it?
  Since then the semantics of $Env(\{\#1,\#2\})$ and $Env(\{\#2,\#1\})$ would be different but it's
  a set so \dots}

\KR{If we go with add/biased union then associations are indeed not sets. Maps are so fundamental in
  semantics that I think any complications arising from the ``non-setness'' of them are a necessary
  price to pay.}

\CK{I don't agree that it is a \emph{necessary} price to pay, as there are
  syntactical solutions; for example the $\{\#1 \mid \dots\}$ and $\{\#1 +
  \dots\}$ syntaxes we used before, which could be extended to combine
  catcher meta-variables in the form $\{\#1 + \#2 + \dots\}$.  In fact, to
  define substitution it is going to be somewhat inconvenient if we
  \emph{don't} have something like this, because the way we must
  instantiate $\{\#catcher, x : y\}$ is different depending on whether we're
  instantiating the left-hand side of a rule (where $\#catcher$ should be
  catching the whole mapping, including $x:y$) or the right-hand side (where
  $x:y$ is an addition).}

\end{example}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Booleans with conditional.
Bool data True; Bool data False; α scheme If(Bool, α, α);

// If rules.
α rule If(True, #1, #2) → #1;
α rule If(False, #1, #2) → #2;

// Pick number.
N scheme Pick(List⟨N⟩, [N,N]Bool);
N rule Pick(#, [x,y]#greater(x,y)) → Pick2(#, [x,y]#pick(x,y), Zero);

N scheme Pick2(List⟨N⟩, [N,N]Bool, N);
N rule Pick2(Nil, [x,y]#greater(x,y), #n) → #n;
N rule Pick2(Cons(#1, #rest), [x,y]#greater(x,y), #n)
  → Pick2(#rest, [x,y]#greater(x,y), If(#greater(#1,#n),#1,#n));
  \end{hacs}
  \caption{Find largest element of a list of natural numbers.}
  \label{fig:pick}
\end{figure}

\begin{example}[]\label{ex:pick}
  %%
  Figure~\ref{fig:pick} shows a simple ``pick a number from a list'' program
  (assuming the "N" sort from example~\ref{ex:peano}, and the "List" sort from
  Example~\ref{ex:list}).

  \CK{This example seems incomplete.  For example, what's N? Is that meant to
  be 0? It's not declared; we have thus far only seen Z (of sort N, not Int).
  But if you want the largest element (as the caption suggests) of a list of
  \emph{integers}, defaulting to 0 does not seem like a good idea!  Also, the
  figure declares booleans and an if scheme, but does not use them.  Oh, and
  the second Pick2 rule is not well-typed (as the third argument of the RHS
  has type Bool rather than Int).}
  \KR{Yep, its a bit sketchy. Anyone?}
  \CK{Do you like it like this? I wasn't sure about adding the If rules (which
  were given before, but not in an example that I could refer to), and whether
  any rules for the comparison should be given.}
  %%
\end{example}

Syntactic higher-order sorts can, however, be used with associations, and in this context
associations can be used to store environments. The next example explores this.

\begin{example}
  %%
  Variation: evaluator with a proper environment. \TBD{Find proper reference.}
  %%
  \begin{hacs}
    Λρ  variable; // explicit variable
    Λρ  data Lm([Λρ]Λρ); // abstraction
    Λρ  data Ap(Λρ,Λρ); // application

    Λρ  scheme E(Λρ, {Λρ:Λρ}); // evaluation context

    Λρ  rule E(x, {x : #x}) → #x;
    Λρ  rule E(x, {¬x}) → x;
    Λρ  rule E(Lm([y]#(y)), {#}) →  Lm([y]E(#(y), {#}));

    Λρ  rule E(Ap(x, #a), {#}) →  E(Ap(E(x, {#}), E(#a, {#})), {#});
    Λρ  rule E(Ap(Ap(#f, #1), #2), {#}) →   E(Ap(E(Ap(#f, #1), {#}), E(#2, {#})), {#});
    Λρ  rule E(Ap(Lm([x]#(x)), #a), {#}) →  E(#(x), {#, x : E(#a,{#})});
  \end{hacs}
  \CK{This is very non-terminating even for most terminating lambda-terms!}
  %%
  Notice how application is now data
  %%
  \KR{Finish it…the idea is one starts with Ec(term, \{\})…}
  %%
\end{example}

\begin{remark}
  One difference between the CRSX family, including \hax, and other higher order rewriting
  formalisms, is that the binder mechanism is part of the parent construction, \eg, the sort of the
  "S" constructor defines that instances must have the shape "S([]…)" with "…" being itself a Peano
  number.  Otherwise, binding and substitution are in the style of CRS higher order rewrite
  systems~\cite{Klop+:tcs1993}---The notation does differ from the original CRS notation in that we
  use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$, and we use
  square brackets instead of round for meta-application arguments. \KR{Update!}
\end{remark}


%------------------------------------------------------------------------

\section{Sorting}
\label{sec:sorting}

In this Section we define \hax script formation formally by restricting the terms of the grammar in
Definition~\ref{def:syntax} further to only allow well-formed ``sortable'' scripts. Informally,
sorting ensures that
%%
\begin{itemize}
\item the pattern and contraction restrictions are obeyed;
\item syntactic variables are used correctly;
\item binders are used in the shape declared for constructors;
\item subterms (including variable and meta-variable occurrences) have the right sort;
\item association keys and values have the proper sorts.
\end{itemize}
%%
We first formalize the sorting rules and last discuss an algorithm for sort checking.

\begin{definition}
  %%
  A \emph{global sort environment} $Γ$ is a structure that combines
  %% 
  \begin{itemize}

  \item $Γ_{\op{rank}}\colon \mathcal{C} → \mathcal{N}$ gives the rank of each sort
    constructor (all sorts must be fully applied, there are no higher kinds).

  \item $Γ_{\op{hasvar}}$ is a set of sort names (the sorts that allow variables).

  \item $Γ_{\op{con}}\colon \mathcal{C} → S×F^*$ from constructor name to pairs of a sort and a
    list of forms (the pair consists of the construction's sort and the shape of the arguments).
    
  \item $Γ_{\op{fun}}$ is a set of constructor names (those declared as schemes).

  \end{itemize}
  %% 
\end{definition}

\begin{definition}
  %%
  A \emph{rule environment} $Δ$ is a structure that combines
  %% 
  \begin{itemize}

  \item $Δ_{\op{var}}\colon \mathcal{V} → S$ mapping from variable names to sorts (the sort assigned
    to each variable for the rule).

  \item $Δ_{\op{meta}}\colon \mathcal{M} → MF$ mapping from meta-variable names to ``meta-forms''
    defined by
    %% 
    \begin{equation}
      MF ::= \ov{S}⇒S \mid \ov{S}⇒\{S{:}S\} \tag{MetaForm}
    \end{equation}
    %%
    (defines the shape of allowed meta-applications for the meta-variable).

  \end{itemize}
  %%
\end{definition}

With these definitions, sorting will amount to ``inventing'' a global sort environment and a rule
environment for each rule such that the 

$MF$ captures the difference between regular meta-variables and ``catch-all'' ones:
%%
\begin{itemize}

\item The shape $\ov{S}⇒S$ is used for meta-variables that need to be meta-applied to
  arguments with the sorts $\ov{S}$ to then form a term of the sort~$S$.
  
\item The shape $\ov{S}⇒\{S_1{:}S_2\}$ used for meta-variables that catch all the associations in an
  association list from $S_1$ to~$S_2$.
  
\end{itemize}

\begin{definition}
  %%
  A \hax script $H$ is \emph{well-sorted} if we can prove $⊢H$ with the rule
  %%
  \begin{align}
    &
    \dfrac
    { Γ ⊢ D_1 ~~\cdots~~ Γ ⊢ D_n }
    { ⊢ D_1…D_n }
    \qquad\qquad
    && (∃Γ) \qquad\qquad\qquad\qquad
    \tag{SH}
    % 
  \end{align}
  %%
  using the rules below for sorting each declaration.
  %%
\end{definition}

Thus sorting relies on a sort environment ``witness'' to establish that a script is well sorted. In
practice, $Γ$ will be assembled from the constraints of the component declarations. We'll argue
below why there is a ``principal'' such witness.

\begin{definition}
  %%
  A \hax declaration $D$ is well-sorted for a sort environment $Γ$ if we can prove $Γ⊢D$ with the
  following rules.
  %%
  \begin{align}
    %
    &\dfrac
    { Γ ⊢ s⟨\ov{α}⟩ }
    { Γ ⊢ s⟨\ov{α}⟩~\kw{data}~d\kw( \ov{F} \kw)\,\kw; }
    && Γ_{\op{con}}(d) = \left⟨ s⟨\ov{α}⟩, \ov{F} \right⟩,~d∉Γ_{\op{fun}}
    \tag{SD-Data}
    %
    \\[1ex]
    %
    &\dfrac
    { Γ ⊢ S }
    { Γ ⊢ S~\kw{scheme}~f\kw( \ov{F} \kw)\,\kw; }
    && Γ_{\op{con}}(f) = \left⟨ S, \ov{F} \right⟩,~f∈Γ_{\op{fun}}
    \tag{SD-Fun}
    %
    \\[1ex]
    %
    &\dfrac
    { Γ ⊢ s⟨\ov{α}⟩ }
    { Γ ⊢ s⟨\ov{α}⟩~\kw{variable}\,\kw; }
    && s ∈ Γ_{\op{hasvar}}
    \tag{SD-Var}
    %
    \\[1ex]
    %
    &\dfrac
    { Γ ⊢ S \quad Γ,Δ,\op{Pat},ε ⊢ M_1 : S  \quad Γ,Δ,\op{Con},ε ⊢ M_2 : S }
    { Γ ⊢ S~\kw{rule}~M_1~\kw{→}~M_2\,\kw; }
    && (∃Δ)
    \tag{SD-Rule}
    %
  \end{align}
  %%
  (using the further rules below for sorting sorts and terms).
  %%
\end{definition}

\begin{itemize}

\item Rule \thetag{SD-Data} expresses that a new data constructor can be introduced as belonging to
  a specific named sort, possibly with sort parameters. The sort itself must be well-formed. The
  sort environment must record this, and the constructor must not be a function constructor.

\item Conversely, \thetag{SD-Fun} permits the introduction of ``defined'' function constructors:
  these can build a term of a generic sort (see Example~\ref{ex:pick}).

\item \thetag{SD-Var} declares that a sort has syntactic variables, recorded in the sort
  environment. (This has consequences for the use of substitution in the sort below.)

\item \thetag{SD-Rule} is the main sort checking of rules. Once the arbitrary sort has been
  checked, we check that the pattern and contraction terms are sortable with it. The pattern is
  checked with the ``Pat'' variant of the term sorting judgment, and the contraction with the
  ``Con'' variant, and we have to invent a witness rule environment $Δ$ that works for both.

\end{itemize}

\CK{Pondering\dots\ these definitions say that the declarations must correspond
to the global sort environment.  They do \emph{not} say that everything in the
global sort environment must be declared.  You could add a requirement for this
to be the case, but then you still would not have the property that schemes have
to be declared before they're used. \\
Do you want to have this?  Because if so, I think you'd have to adapt the
schemes so they can \emph{change} the global sort environment; for example:
  \begin{align}
    &
    \dfrac
    { \emptyset ⊢ (Γ_1,D_1) ~~\cdots~~ Γ_{n-1} ⊢ (Γ_n,D_n) }
    { ⊢ D_1…D_n }
    \qquad\qquad
    && \qquad\qquad\qquad\qquad
    \tag{SH}
    % 
  \end{align}
I think I prefer your way of doing it, though.  Just pondering the consequences. \\
Another question is whether we should already demand at this point that
$\Delta_{\op{var}}$ contains only syntactic variables.  I believe doing so would
allow us to remove the requirements $s \in \Gamma_{\op{hasvar}}$ when variables
are sorted.}

\begin{definition}
  %%
  A sort denotation $S$ is well-sorted for a sort environment $Γ$ if we can prove $Γ⊢S$ with the
  following rules.
  %%
  \begin{align}
    %\intertext{\shoveright{Sorting of Sorts\hfil\smash{\fbox{$ Γ ⊢ S $}}}}
    %
    &\dfrac
    { Γ ⊢ S_1 ~~\cdots~~ Γ ⊢ S_n }
    { Γ ⊢ s⟨S_1,…,S_n⟩ }
    && Γ_{\op{rank}}(s) = n %\underbrace{{*}→…→{*}}_n
    \tag{SS-Cons}
    %
    \\[1ex]
    %
    &\dfrac
    {}
    { Γ ⊢ α }
    \tag{SS-Var}
    %
  \end{align}
  %%
\end{definition}

\begin{itemize}

\item Sorts are well-formed when they have consistent rank in the sort environment.

\end{itemize}

\begin{figure*}[p]\small
  \vspace*{-3em}
  \begin{align}
    \intertext{\shoveright{Sorting of Meta-term\hfil\smash{\fbox{$ Γ,Δ,TC,\ov{\mathcal{V}} ⊢ M : S $}}}}
    %
    &\dfrac
    { Γ,Δ,\op{InPat},\ov{v} ⊢ P_1 : F_1 ~~\cdots~~ Γ,Δ,\op{InPat},\ov{v} ⊢ P_n : F_n }
    { Γ,Δ,\op{Pat},\ov{v} ⊢ f\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : S }
    &&\Cases{
      f∈Γ_{\op{fun}}\\
      Γ_{\op{con}}(f) = \left⟨ S, (F_1\kw,…\kw,F_n) \right⟩
    }
    \tag{SMP-Fun}
    % 
    \\[1ex]
    %
    &\dfrac
    { Γ,Δ,\op{InPat},\ov{v} ⊢ P_1 : F_1 ~~\cdots~~ Γ,Δ,\op{InPat},\ov{v} ⊢ P_n : F_n }
    { Γ,Δ,\op{InPat},\ov{v} ⊢ d\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : S }
    &&\Cases{
      d∉Γ_{\op{fun}}\\
      Γ_{\op{con}}(d) = \left⟨ S, (F_1\kw,…\kw,F_n) \right⟩
    }
    \tag{SMP-Data}
    % 
    \\[1ex]
    %
    &\dfrac
    { }
    { Γ,Δ,\op{InPat},\ov{v} ⊢ m\,\kw(\,w_1\kw,…\kw,w_n\,\kw) : S }
    &&\Cases{
      Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒S \right) \\
      ∀i\colon w_i∈\ov{v} \\
      ∀i\colon Δ_{\op{var}}(w_i) = S_i \\
      \text{All the $w_i$ are different}
    }
    \tag{SMP-Meta}
    % 
    \\[1ex]
    %
    &\dfrac
    { }
    { Γ,Δ,\op{InPat},\ov{v} ⊢ w : s⟨\ov{S}⟩ }
    &&\Cases{
      Δ_{\op{var}}(w) = s⟨\ov{S}⟩ \\
      s ∈ Γ_{\op{hasvar}}
    }
    \tag{SMP-Var}
    %
    \\[1em]
    %
    &\dfrac
    { Γ,Δ,\op{Con},\ov{v} ⊢ P_1 : F_1 ~~\cdots~~ Γ,Δ,\op{Con},\ov{v} ⊢ P_n : F_n }
    { Γ,Δ,\op{Con},\ov{v} ⊢ c\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : S }
    && Γ_{\op{con}}(c) = \left⟨ S, (F_1\kw,…\kw,F_n) \right⟩
    \tag{SMC-Cons}
    % 
    \\[1ex]
    %
    &\dfrac
    { Γ,Δ,\op{Sub},\ov{v} ⊢ M_1 : S_1 ~~\cdots~~  Γ,Δ,\op{Sub},\ov{v} ⊢ M_n : S_n }
    { Γ,Δ,\op{Con},\ov{v} ⊢ m\,\kw(\,M_1\kw,…\kw,M_n\,\kw) : S }
    && Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒S \right)
    \tag{SMC-Meta}
    %
    \\[1ex]
    %
    &\dfrac
    { }
    { Γ,Δ,\op{Con},\ov{v} ⊢ w : s⟨\ov{S}⟩ }
    &&\Cases{
      Δ_{\op{var}}(w) = s⟨\ov{S}⟩ \\
      s ∈ Γ_{\op{hasvar}}
    }
    \tag{SMC-Var}
    %
    \\[1em]
    %
    &\dfrac
    { Γ,Δ,\op{Con},\ov{v} ⊢ c\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : s⟨\ov{S}⟩ }
    { Γ,Δ,\op{Sub},\ov{v} ⊢ c\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : s⟨\ov{S}⟩ }
    && s ∉ Γ_{\op{hasvar}}
    \tag{SMS-Cons}
    % 
    \\[1ex]
    %
    &\dfrac
    { Γ,Δ,\op{Con},\ov{v} ⊢ m\,\kw(\,M_1\kw,…\kw,M_n\,\kw) : s⟨\ov{S}⟩ }
    { Γ,Δ,\op{Sub},\ov{v} ⊢ m\,\kw(\,M_1\kw,…\kw,M_n\,\kw) : s⟨\ov{S}⟩ }
    && s ∉ Γ_{\op{hasvar}}
    \tag{SMS-Meta}
    %
    \\[1ex]
    %
    &\dfrac
    { }
    { Γ,Δ,\op{Sub},\ov{v} ⊢ w : S }
    && Δ_{\op{var}}(w) = S
    \tag{SMS-Var}
    %
    \\[1ex]
    \intertext{\shoveright{Sorting of Piece\hfil\smash{\fbox{$ Γ,Δ,TC,\ov{\mathcal{V}} ⊢ P : F $}}}}
    %
    &\dfrac
    { Γ,Δ',TC,(\ov{v}\,\ov{w}) ⊢ M : S }
    { Γ,Δ,TC,\ov{v} ⊢ \kw[\,\ov{w}\,\kw]\,M : [\ov{S}]S }
    && (∃Δ'⊇Δ),~ Δ'_{\op{var}}(\ov{v}) = \ov{S}
    \tag{SP-Bind}
    %
    \\[1ex]
    %
    &\dfrac
    { Γ,Δ,TC,\ov{v} ⊢ A_1 : \{S{:}S'\} ~~\cdots~~ Γ,Δ,TC,\ov{v} ⊢ A_n : \{S{:}S'\} }
    { Γ,Δ,TC,\ov{v} ⊢ \kwm\{\,A_1\kw,…\kw,A_n\,\kwm\} : \{S{:}S'\} }
    \tag{SP-Assoc}
    %
    \\[1ex]
    \intertext{\shoveright{Sorting of Association\hfil\smash{\fbox{$ Γ,Δ,TC,\ov{\mathcal{V}} ⊢ A : \{S{:}S\} $}}}}
    %
    &\dfrac
    { Γ,Δ,TC,\ov{v} ⊢ M : S \quad Γ,Δ,TC,\ov{v} ⊢ M' : S' }
    { Γ,Δ,TC,\ov{v} ⊢ M\kw:M' : \{S{:}S'\} } 
    \tag{SA-Map}
    % 
    \\[1ex]
    %
    &\dfrac
    { Γ,Δ,\op{InPat},\ov{v} ⊢ M : S }
    { Γ,Δ,\op{InPat},\ov{v} ⊢ {\kwm{¬}M\kw{:}} : \{S{:}S'\} }
    \tag{SAP-Not}
    % 
    \\[1ex]
    %
    &\dfrac
    { }
    { Γ,Δ,\op{InPat},\ov{v} ⊢ m\,\kw(\,w_1\kw,…\kw,w_n\,\kw) : \{S{:}S'\} }
    &&\Cases{
      Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒\{S{:}S'\} \right) \\
      ∀i\colon w_i∈\ov{v} \\
      ∀i\colon Δ_{\op{var}}(w_i) = S_i
    }
    \tag{SAP-All}
    % 
    \\[1ex]
    %
    &\dfrac
    { Γ,Δ,\op{Sub},\ov{v} ⊢ M_1 : S_1 ~~\cdots~~  Γ,Δ,\op{Sub},\ov{v} ⊢ M_n : S_n }
    { Γ,Δ,\op{Con},\ov{v} ⊢ m\,\kw(\,M_1\kw,…\kw,M_n\,\kw) : \{S{:}S'\} }
    && Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒\{S{:}S'\} \right)
    \tag{SAC-All}
    %
  \end{align}
  \vspace*{-1em}
  \caption{\hax meta-term sorting rules.}
  \label{fig:termsortrules}
\end{figure*}

\begin{definition}
  %%
  Given a ``term context'' helper sort of
  %%
  \begin{equation}
    TC ::= \op{Pat} \mid \op{InPat} \mid \op{Con} \mid \op{Sub} \tag{TermContext}
  \end{equation}
  %%
  Given a sort environment $Γ$ and a rule environment $Δ$. A meta-term $M$ has sort $S$ in term
  context $TC$ and bound variables $\ov{v}$ if we can prove
  \begin{equation}
    Γ,Δ,TC,\ov{v} ⊢ M : S
  \end{equation}
  %%
  using the rules in Figure~\ref{fig:termsortrules}.
  %%
\end{definition}

\begin{itemize}

\item The rules in Figure~\ref{fig:termsortrules} give the primary term rules per term context $TC$,
  which indicates the context of our meta-term fragment:
  %% 
  \begin{itemize}
  \item ``Pat'' indicates the pattern (left side) of a rule, at the outermost level.
  \item ``InPat'' is used inside a piece of the pattern of a rule, not the outermost level.
  \item ``Con'' denotes any location in the contraction (right side) of a rule except a substitution.
  \item ``Sub'' denotes a substitution location (an immediate child of a meta-application) in the
    contraction (right side) of a rule.
  \end{itemize}

\item The \thetag{SMP-*} rules handle patterns. The first rule \thetag{SMP-Fun} is the entry rule
  for patterns, with $TC=\op{Pat}$, which must be function constructions, and have pieces that are
  well-sorted. Fragments of patterns are then handled by the three following rules,
  \thetag{SMP-Data,SMP-Meta,SMP-Var}, with $TC=\op{InPat}$, which capture the sort propagation as
  well as the special constraints for patterns:
  %%
  \begin{enumerate}

  \item \thetag{SMP-Data} sort checks that only data constructors are allowed;

  \item \thetag{SMP-Meta} verifies that pattern meta-application arguments are restricted to
    distinct bound variables;

  \item \thetag{SMP-Var} verifies that other instances of variables only occur where a \kw{variable}
    declaration explicitly permits it.

  \end{enumerate}

\item The \thetag{SMC-*} rules handle contraction meta-terms.
  %%
  \begin{enumerate}

  \item \thetag{SMC-Cons} verifies that each construction (function or data) is well sorted.

  \item \thetag{SMC-Meta} verifies that every meta-application is sorted consistently with the rule
    environment, and checks that the implied substitutions are well formed.

  \item \thetag{SMC-Var} checks that variables are used at the right sort, and are permitted (by a
    \kw{variable} declaration for the sort).

  \end{enumerate}

\item The \thetag{SMS-*} rules handle contraction substitution arguments. They really just wrap the
  corresponding \thetag{SMC-*} rules except that \thetag{SMS-Cons,SMS-Meta} checks that the
  non-trivial substitution is permitted by the sort \emph{not} having a \kw{variable} declaration,
  and \thetag{SMS-Var} just checks the sort of the replacement variable \emph{without} any
  constraints on whether the sort has a \kw{variable} declaration.

\item The \thetag{SP-*} rules handle ``pieces,'' \ie, parameters of constructions (which at the
  outermost level have a different structure than other subterms). Note that these do \emph{not}
  depend on the term context, which is merely passed to the premises. (From the other rules we can
  see that the term context will always be \op{InPat} or \op{Con}.)
  %%
  \begin{enumerate}

  \item \thetag{SP-Bind} handles scopes. It creates a \emph{locally extended} version of the rule
    environment, $Δ'$, which extends the variable bindings part of $Δ$ with the binders in the
    scope; the sorts of these are fixed by the parent construction.

  \item \thetag{SP-Assoc} handles collections of associations. These are checked by separate
    individual rules for association, below.

  \end{enumerate}

\item The \thetag{SA*} rules handle associations. These are categorized in a slightly different ways
  than the others above, as associations have different rules in patterns and contractions.
  %%
  \begin{enumerate}

  \item \thetag{SA-Map} gives the rule for a simple mapping. Such mappings are permitted in both 
    \TBD{key patterns should be restricted}

  \item \thetag{SAP-Not} expresses that negation patterns

  \end{enumerate}

  \CK{So data rules are permanently off the table, then?}

  \CK{Also, for SMP-Var I think you should allow $w \in \{\ov{v}\}$ as an alternative to
    $s \in \Gamma_{\op{hasvar}}$.  Or do you want to allow bound variables to \emph{only}
    occur as meta-variable arguments?  I must confess that this is an interesting idea,
    but it is not usual (indeed, normally bound variables are the only variables you can
    match on).  The same question applies to SMC-Var.}

  \CK{With regards to SP-Bind:
  \begin{itemize}
  \item I think you meant to require that $Δ'_{\op{var}}(\ov{w}) = \ov{S}$
    rather than for $Δ'_{\op{var}}(\ov{w})$?
  \item Why not simply \emph{define} $Δ'$ as $Δ ∪ \{ \ov{w}:=\ov{S} \}$?  As is,
    the definition allows $Δ'$ to contain additional variables which $Δ$ does not contain.
    This for instance gives $\emptyset \vdash [x]f(y)$, which I would consider undesirable.
  \item Do you want to require that $\{\ov{v}\} \cap \{\ov{w}\} = \emptyset$ or not?
    This is unclear from the notation (and indeed, could go either way in the
    lambda-calculus).
  \end{itemize}}

\end{itemize}

\TBD{Example sort derivation.}


%------------------------------------------------------------------------

\section{Rewriting}
\label{sec:rewriting}

In this section we formally define rewriting in the \hax calculus. We follow [\TBD{Cynthia?}] in
defining rewriting in the context of a sort assignment.

\CK{Oof, no idea who came up with that.  It's a fairly standard thing.}

\bigskip
\JN{MS and JN thought about behavior of association maps -- thoughts and proposals below}:
\paragraph{Commutativity}
\JN{%
\[
\text{Question 1: }
\{x : 1, y : 0\} =^? \{y : 0, x : 1\}
\]}
Although the two association maps $"{x : T, y : F}"$ and $"{y : F, x : T}"$ are not syntactically
equal, one would expect them to behave identically, as they contain the same associations. That is
one could argue that we consider association maps modulo commutativity (one possibility to model
this formally could be to treat ``,'' as a commutative binary symbol). But then we seem to run into
problems with ``inconsistent'' associations, because $"{x : T, x : F}"$ and $"{x : F, x : T}"$ would
then also be indistinguishable. This problem becomes particularly apparent when considering
matching: Suppose we have a rule $"Fun({ x : #1, #2}) → #1"$. The following two rewrite steps are
expected: $"Fun({ x : T, y : F}) → T"$ with $\#1 \mapsto T, \#2 \mapsto y : F$ and
$"Fun({y : F, x : T}) → T"$ again with $\#1 \mapsto T, \#2 \mapsto y : F$ (but using
commutativity). 
\JN{%
\[
\text{Question 2: }
\{x : 1, x : 0\} =^? \{x : 0, x : 1\}
\]}
But then one might argue that, simply exchanging the $y$ for another $x$, also the
two steps $"Fun({ x : T, x : F}) → T"$ with $\#1 \mapsto T, \#2 \mapsto x : F$ and
$"Fun({ x : F, x : T}) → T"$ again with $\#1 \mapsto T, \#2 \mapsto x : F$ should be possible. But
then so should $"Fun({ x : F, x : T}) → F"$ and $"Fun({ x : T, x : F}) → F"$.
\begin{center}
\JN{Answer 1 to Question 2: ``Don't-Care'' -- Nondeterminism}
\end{center}
There are multiple ways to resolve this. A first is to not resolve, but embrace it and simply allow
this behavior.\footnote{But this doesn't fit the behavior in \CRSX, right? So that's maybe not the
  way to go.} Then it should be possible to define association maps via rewriting modulo ACU, i.e.,
with a binary symbol for building association sets (say ``,'') that is considered modulo
associativity, commutativity and with the empty association map as a unit element. This makes
matching and unification quite a bit harder, but also allows to build on well-studied theory.

\CK{Does it really make matching and unification harder? It seems
quite reasonable to think of associations simply as sets of pairs.
Mind, I do not believe that this is truly what we want, as I think we
want to \emph{override} existing mappings.}

\begin{center}
\JN{Answer 2 to Question 2: No equal keys allowed by construction}
\end{center}
Another way would be to disallow ``inconsistent'' association maps (where we will have to specify,
what exactly inconsistent means). So assume we forbid association maps that are already inconsistent
both in rules and the terms we rewrite. The question then obviously is how to make sure we do not
introduce inconsistencies. One way is via instantiations -- that is we need to apply substitutions
to association maps such that no key can be present twice, either by favoring the already present
one or by overwriting it. A possible (partial) definition for the former is given below:
\begin{align*}
  \{\}\sigma &= \{\}\\
  \{A_1,\ldots,A_n\}\sigma &= \{A_1,\ldots,A_{n-1}\}\sigma \uplus A_n\sigma\\
  \{\} \uplus A &= \{A\}\\
  \{k_1:v_1,\ldots,k_n:v_n\} \uplus \{k : v\} &=
  \begin{cases}
    \{k_1:v_1,\ldots,k_n:v_n\} &\text{if $k\approx k_i$ for some $1 \leq i \leq n$}\\
    \{k_1:v_1,\ldots,k_n:v_n, k : v\} &\text{otherwise}
  \end{cases}
\end{align*}

\CK{Problem is, I do \emph{not} like imposing an order on these sets.
It gets kind of icky, and also does not match the implementation, I
think.}

Now we would also have to define what it means for two keys to be ``equal'', written $\approx$
above, i.e., when a map would become inconsistent. The obvious checking for syntactic equality seems
too weak, since (at least by the syntax) arbitrary meta-terms are allowed as keys. When considering
that we probably want to avoid situations where through instantiation the map could become
inconsistent, instantiating $\approx$ by unifiability seems like a good choice.

\CK{Except we absolutely do want to allow a mapping with different
variables as keys, which this idea would disallow.}

In any case we should get the following behavior for the example from above: starting from the
inconsistent term $"Fun({ x : T, x : F})"$ there is no rewrite step using the rule
$"Fun({ x : #1, #2}) → #1"$, since no instantiation of $"{x : #1, #2}"$ can produce the required map:
trying e.g.\ $[\#1 \mapsto T, \#2 \mapsto x : F]$ we get
$"{x : #1, #2}"[\#1 \mapsto T, \#2 \mapsto x : F] = ("{}" \uplus "{x : T}") \uplus "{x : F}" =
"{x :T}"$.

The second case to introduce inconsistencies is by rewriting the keys themselves. Suppose we have a
term $"Fun({x : T, G(x) : F})"$ and a rule $"G(#) → #"$. One way to avoid this would be by demanding
that keys must not be joinable (have a common reduct), but that is in general not decidable. So
maybe a better option would be to enforce that keys do not contain function constructions (we
probably do not want rewriting in keys anyway, do we?).

\CK{I think we do not want rewriting in keys.}

\CK{Question: is it safe to assume that the only variables occurring
as (part of) keys in associations are syntactic?  Since syntactic
variables may not be substituted other than by other syntactic
variables, it already avoids many problems.  It does not avoid the
possibility of substituting two key-variables by the same variable,
though\dots\ what do we \emph{want} to do if that happens?  Is it
possible in practice?}

\paragraph{Non-deterministic Catching}
\begin{center}
  \JN{Question 3: Possible to forbid in lhs: $\{\#X, \#Y\}$?\\To avoid blowup in matchers.}
\end{center}
Is using two catchers in pattern allowed? We probably want to forbid this to get an easy, efficient
matching procedure. Otherwise already for the term $"Fun({x : 0, y : 1})"$ we have four different
matchers with the pattern $"Fun({#1, #2})"$.

\CK{I would strongly prefer not!  Or if it is allowed, that they both
match the full set.}

\paragraph{Nested Association Maps}
\begin{center}
  \JN{Question 4: Pattern $\{x: 0, \#X\}$ matches $\{x:0\}$?}
\end{center}
The syntax for catchers could become a bit weird. Consider a left-hand side $"Fun({x : 0, #})"$.
Does it match a term $"Fun({x : 0})"$? If so, $\#$ somehow needs to be mapped to ``nothing'',
but directly mapping it to the empty map $\{\}$ seems awkward because then one would get
$"Fun({x : 0, {}})"$. Similarly when matching with $"Fun({x : 0, y : 1, z : 2})"$
one would expect to map $\#$ to $"{y : 1, z : 2}"$ which again nests maps.
So somehow maps need to be ``flattened'' when instantiating catchers. The above definition tries to
take care of that.

\begin{center}
  \JN{Question 5: Sort system: allows}
  \begin{xalignat*}{2}
    &\{x : 0\} & &\{Var : Nat\}\\
    &\{\{x : 0\}\} & &\{Var : Nat\}\\
    &\{\{\{x : 0\}\}\} & &\{Var : Nat\}\\
    &\vdots & & \vdots
  \end{xalignat*}
  \JN{so should $\{x : 0\}$ and $\{\{ x : 0\}\}$ behave the same?}
\end{center}
A similar effect is present in the sort system where by using the rule S-P-ASSOC it seems to be
possible to arbitrarily nest $"{}"$.

\JN{end of thoughts and proposals on association maps}

\CK{I think this shows the benefits of using the syntax $\{\# \mid
x : 0 \}$ instead: it makes it more clear that the catcher should
always capture the whole map!}

\bigskip

\begin{definition}[substitution]
  
\end{definition}

\TBD{mv, fv, substitution, rewriting.}

\CK{I'm happy to write something up, but I think discussion points
need to be answered first:
\begin{itemize}
\item Can I define it using $\{\# \mid \dots\}$ on the left and
  $\{\# + \dots\}$ on the right, or would it be preferable if we
  simply give different definitions of substitution for the left- and
  right-hand side?
\item What happens if a substitution collapses two keys in an
  association?
\end{itemize}
}

\begin{theorem}[subject reduction]
  Given a well-sorted \hax script $H$ with the rewrite 


A well-sorted term can only rewrite to a well-sorted term.
\end{theorem}

%------------------------------------------------------------------------

\section{Properties}
\label{sec:properties}

In this section we provide proofs for several standard rewrite properties of~\hax.

\TBD{What do we know of properties of such a system… Cynthia or Maria or Julian?
  \\
  Also: decidability of type checking, possibly type inference?}


%------------------------------------------------------------------------

\section{Implementing \hax}
\label{sec:implement}

In this section we give notes on how we see \hax implemented. The implementation uses classic term
graph rewriting extended to handle binders and associations.

The basic \hax implementation consists of a term representation with sharing and a rewrite engine. Both are described
in more details below.     


\subsection{Term graph representation}

\begin{definition}[identifiers]
  %%
  In the implementation we keep track of the following \emph{identifiers}:
  %%
  \begin{itemize}

  \item \emph{Variable identifiers}. A variable identifier is globally unique. It should be suitable
    for \emph{comparison} and \emph{hashing}.

  \item \emph{Constructor identifiers}. A constructor identifier is globally unique and suitable for
    hashing. From the constructor identifier one can derive the kind and signature of the
    constructor:
    \begin{itemize}
    \item Is it a function or data constructor? Data constructors should be suitable for use as C
      switch keys.
    \item How many scope-formed formal arguments (declared as $[S^*]S$) does the constructor take,
      and how many local variables are bound by each?
    \item How many association-formed formal arguments (declared as $\{S:S\}$) does the constructor
      take?
    \end{itemize}
    Note that everything is assumed to be well-sorted.

  \end{itemize}
  %%
  In addition, both forms of identifiers support \emph{printing} the identifier in an identifiable
  fashion [sic].
  %%
\end{definition}

\begin{structure}[term representation]
  %%
  Terms are maintained as a graph structure with nodes containing:
  %%
  \begin{itemize}
  \item Constructor identifier.
  \item Reference count.
  \item Pointer to cached free variable set (more on this below).
  \item Two-dimensional array of bound variable identifiers (with length as required by constructor to cover all
    scopes). 
  \item Array of pointers to scoped subterms (with length as required by the constructor).
  \item Array of association sets (with length as required by the constructor). \LV{Plank shouldn't need this}
  \end{itemize}
  %%
\end{structure}

This structure allows for term sharing, similar to a Jungle \cite{Hoffmann91implementingterm}. Explain differences if any...

\begin{structure}[association set]
  %%
  Association sets are implemented as a mix of linked list and hash map. Linked list are generally used when the association sets size is under a
  configurable threshold, as well as when extending shared sets (see below). When the association set reaches a certain size, it is indexed 
  and represented as hashmap. 
  
  Association sets can be shared by several different terms. Destructive update on hash map is performed when association set is uniquely owned. 
  
  Association sets can only be extended (see section...), any previous entries can be shadowed by a new entry. There is no attempt to
  garbage collect shadowed entries. Only when the association set is a hash map, previous entries can be reclaimed.
  
\end{structure}

\subsection{Rewrite Engine}

The reduction strategy follows a leftmost-outermost evaluation \cite{Toyama05reductionstrategies}. 
 

\TBD{What about dispatchification…Maria?}


%------------------------------------------------------------------------

\section{Supporting Compiler Paradigms}
\label{sec:compiling}

In this section we outline how the core idioms of the full \CRSX and \HAX languages translate
into~\hax.

\KR{For \HAX I am developing these in crsx/hacs/doc/hacs2.tex.}


%------------------------------------------------------------------------

\section{Conclusion}
\label{sec:conc}

With \hax, we have presented a rather small calculus that can serve as the underlying formalism for
reasoning about as well as implementing the \CRSX and \HAX languages.

\TBD{What is covered.}

~\cite{Knuth:mst1968} 
~\cite{Aho+:2006}


\paragraph*{Related work.}

We would like to give credit to SIS~\cite{Mosses:daimi1979}, which shares with \hax the use of
\emph{simplification} using a λ-calculus based formalism.

The most prominent system that supports implementation of compilers in formal (rewriting and
attribute grammar) form is ASF+SDF~\cite{Brand+:toplas2002}, which is based on first order
rewriting. While modules have been added for symbol table management, these lack the full
integration and easy way to handle scoped intermediate languages. The successor,
Rascal~\cite{Bos+:eptcs2011} adds a module for HOAS, but Rascal specifications operate in a world of
side effects, which we find hard to reconcile with higher-order term structures (with scopes).

The notion of ``higher-order'' used by \hax is similar to but not quite the same as in higher-order
attribute grammars (HAG)~\cite{VogtSwierstraKuiper:pldi1989}. Like HAGs, \hax specifications permit
constructing and passing of abstract syntax fragments in attributes but the ``higher order'' aspect
of \hax also covers the rewriting side, where we can build parameterized abstractions over any part
of a specification, including with attributes. Indeed, one can use substitution inside attributes,
and have absence of attributes and substitution block rewriting.

\paragraph*{Future work.} \TBD{Speculate!}


\paragraph*{Acknowledgements.} \TBD{Thank everyone.}

EU-funded Marie Skłodowska-Curie ``HORIP'' action collaboration with Cynthia Kop.


%------------------------------------------------------------------------

\bibliography{crs}


\TBD{End of sane part.}
\hrule
\vspace*{1pc}

%------------------------------------------------------------------------
\appendix

\section{\bhax in \HAX}

We encode \hax in \HAX…\KR{It may even work, eventually.}
%
\begin{hacs}[numbers=right,texcl]
// HACS module for the \hax calculus.
module org.crsx.hacs.Plank {

// \textbf{Lexical.}

// Spaces and comments.
space " " | [\t\n] | "//" ([^/\n] | "/" [^/\n])*;

// Identifiers (TODO: proper Unicode).
token CON   | [A-Z] ⟨IDCHAR*⟩;   // $c$
token VAR   | [a-z] ⟨IDCHAR*⟩;    // $v$
token META  | "#" ⟨IDCHAR*⟩;     // $m$
token fragment IDCHAR | [A-Za-z0-9_];

// \textbf{Grammar.} Only captures syntax, not binding.

sort H // \hax script.
| ⟦ ⟨D*⟩ ⟧
;

sort D // Declaration.
| ⟦ ⟨S⟩ data ⟨CON⟩ ( ⟨F*,⟩ ) ; ⟧
| ⟦ ⟨S⟩ scheme ⟨CON⟩ ( ⟨F*,⟩ ) ; ⟧
| ⟦ ⟨S⟩ variable ; ⟧
| ⟦ ⟨S⟩ rule ⟨M⟩ → ⟨M⟩ ; ⟧
;

sort F // Form.
| ⟦ [ ⟨S*,⟩ ] ⟨S⟩ ⟧  | sugar ⟦ ⟨S#⟩ ⟧ → ⟦ []⟨S#⟩ ⟧
| ⟦ { ⟨S⟩ : ⟨S⟩ } ⟧
;


sort S // Sort.
| ⟦ ⟨CON⟩ ⟨ ⟨S*,⟩ ⟩ ⟧  | sugar ⟦ ⟨CON#⟩ ⟧ → ⟦ ⟨CON#⟩ ⟨ ⟩ ⟧
| ⟦ ⟨VAR⟩ ⟧
;

sort M // Meta-term.
| ⟦ ⟨CON⟩ ( ⟨P*,⟩ ) ⟧  | sugar ⟦ ⟨CON#⟩ ⟧ → ⟦ ⟨CON#⟩() ⟧
| ⟦ ⟨VAR⟩ ⟧
| ⟦ ⟨META⟩ ( ⟨M*,⟩ ) ⟧  | sugar ⟦ ⟨META#⟩ ⟧ → ⟦ ⟨META#⟩() ⟧
;

sort P // Piece.
| ⟦ { ⟨A*,⟩ } ⟧
| ⟦ [ ⟨VAR*,⟩ ] ⟨M⟩ ⟧   | sugar ⟦ ⟨M#⟩ ⟧ → ⟦ []⟨M#⟩ ⟧
;

sort A // Association.
| ⟦ ⟨M⟩ : ⟨M⟩ ⟧
| ⟦ ¬ ⟨M⟩ ⟧
| ⟦ ⟨M⟩ ⟧  // really only $m(v^*)$ but that's ambiguous
;

}
\end{hacs}


\section{Bra-Ket}

\KR{Just for fun: Here is ``bra-ket'' notation (from physics), also kind of cool. I'd love this, and
  it would be different and make us associate even more to the \hax symbol. The explanation then
  associates a \emph{bra} with a binder state and a \emph{ket} with a substitution of it.}
\CK{That's\dots\ very weird to me. But then, I never did physics after high school! But in general,
  I think this notation is unlikely to appeal to rewriters.}
\begin{align}
  \tag{\hax{}Script}
  H &::= D^* 
  \\
  \tag{Declaration}
  D &::= S~\kw{data}~d\,\kw(\,\ov{F}\,\kw)\,\kw;
  \bigm| S~\kw{scheme}~f\,\kw(\,\ov{F}\,\kw)\,\kw;
  \bigm| S~\kw{variable}\,\kw;
  \bigm| S~\kw{rule}~M~\kw{$→$}~M\,\kw;
  \\
  \tag{Form}
  F &::= \kwm{⟨}\,\ov{S}\,\kwm|\,S
  \bigm| \kwm\{\, S:S \,\kwm\}
  \\
  \tag{Sort}
  S &::= s\,\kw[\,\ov{S}\,\kw]
  \bigm| α
  \\[\jot]
  \tag{Term}
  M &::= c\,\kw(\,\ov{P}\,\kw)
  \bigm| v
  \bigm| m\,\kwm|\,\ov{M}\,\kwm{⟩}
  \\
  \tag{Piece}
  P &::= \kwm{⟨}\,\ov{v}\,\kwm|\,M
  \bigm| \kwm\{\, \ov{A} \,\kwm\}
  \\
  \tag{Association}
  A &::= M\,\kw:\,M
  \bigm| \kw{$¬$}\,M
  \bigm| \kw:\,m
\end{align}
\KR{We now distinguish \emph{five} different ways to brace elements; all empty can be omitted
  except associations.
  For data and scheme \emph{subterms}, we use $\kw{( )}$.
  For \emph{binders} we use $\kwm{⟨~|}$ (``bra'').
  For \emph{meta-application arguments} we use $\kwm{|~⟩}$ (``ket'').
  For \emph{associations} we use $\kwm{\{\,\}}$.
  For \emph{sort parameters} we use $\kwm{[\,]}$.}
\begin{hacs}
  List[α] scheme Map(⟨β|α, List[β]);
  List[α] rule Map(⟨x|#|x⟩, Nil) →  Nil;
  List[Int] rule Map(⟨x|#|x⟩, Cons(#1, #2)) →  Cons(#|#1⟩, Map(⟨x|#|x⟩, #2));
  Int scheme Pick(List[Int], ⟨Int,Int|Bool);
  Int rule Pick(#, ⟨x,y|#p|x,y⟩) → If(#p|#,#⟩, Pick(#, ⟨x,y|#p|x,y⟩), #);
\end{hacs}

\section{Term stuff}

In Figure~\ref{fig:syntax}, the $S$ in $S~\kw{rule}~M~\kw{$→$}~M\,\kw;$ is not superflous. Consider
the following two rules:
\begin{hacs}[numbers=right]
    List⟨α⟩ rule Map([x]#(x), Nil) →  Nil;
    List⟨Int⟩ rule Map([x]#(x), Cons(#1, #2)) →  Cons(#(#1), Map([x]#(x), #2));
\end{hacs}
\MS{I am not sure, I completely understand yet.}
\CK{This states why it is important to give the sort of a rule: because
sometimes, sorts may be ambiguous.  The first rule is defined for arbitrary
lists, the second only for lists of integers, and will be met with a
compiler error if you try to use it on a list of strings.  I'm not convinced
it's a very good example, though: it doesn't make it clear why you would
\emph{want} the rule to be limited to integer lists!}
%%
\KR{Yes, we need a better example. Essentially it seems \hax can have \emph{sort dispatch} by
  allowing two rules that overlap \emph{except} for the parameter sort.}

It is even possible to have function constructors that live in \emph{all} sorts:
\begin{hacs}[numbers=right]
    α scheme If(Bool, α, α);
    α rule If(True, #1, #2) → #1;
    α rule If(False, #1, #2) → #2;
\end{hacs}

\begin{example}
  Example terms without Associations are: 
  %% 
  \begin{hacs}[numbers=right, texcl]
      Zero, Plus(#X, #Y), S(Zero), x, #X, S([x,y]#X[y,x,z]), #X[x], #F[Zero], #F[#X]
      [x,y]#F[y,x]
    \end{hacs}
    \MS{So currently, a meta-application is (strictly speaking) not called a term (except for
      $\#X$). Do we want this?}

    \CK{A meta-application $\#X[\kw{0}]$ or $\#X[z]$ is a term.  However,
    \emph{scopes} are not considered terms (I would propose not calling it
    a ``pattern meta-application'' as that is misleading, though).}
    
    Example terms with Associations of the form $M \kw{:} M$, where the key is a variable or a
    constant, are
    %% 
    \begin{hacs}[numbers=right,texcl]
      Plus(x, { x : Zero }), Plus(#X, { x : Zero }), Plus(Zero, {Zero : S(Zero)}) 
    \end{hacs}
    
    Example terms, where the keys are meta-variables. \MS{I am sorry, I forgot, is this allowed?}
    \CK{Woah, the second one definitely isn't, because the key is not a term;
    even if it was, this would not be sortable with our second-order system.
    I don't think there's any problem with the first.}
    \begin{hacs}[numbers=right,texcl]
     S({ #X : #Y }), #Z[S({ #X : #Y })]                    
     S({[x]#X[x] : Zero }), 
   \end{hacs}

   \MS{The semantic of the following two is unclear, or?}
   \CK{For the former, yes -- an association should be a mapping.  But for the
   latter, couldn't it be a term carrying \emph{two} association mappings?  I
   don't know whether we ever want this, but it doesn't necessarily give
   ambiguity, I think.}
%   \begin{hacs}[numbers=right,texcl]  
%     S( {x : y, x : Zero} )
%     Plus( {x : y}, {x : Zero} )
%   \end{hacs}
   Example terms with Associations of the form $¬M$ are:
   \begin{hacs}[numbers=right,texcl]
     Plus(x, { ¬x }), Plus(x, { ¬Zero }), Plus(#X,{¬Zero}), S({ ¬#X }), 
     #Z[S({ ¬#Z[x] })], S({ ¬S([x]#X[x]) }), Plus(Zero,{¬S(Zero)}), Plus({ ¬x}, { ¬z})
   \end{hacs}
   
   Finally, Example terms with Associations of the form $: m$ are:
   \begin{hacs}[numbers=right,texcl]
     Plus(x, { : #X }), Plus( { : #X}, { : #X}), Plus( { : #X}, { : #Y})
     Plus( #X, { : #X })  // note, here \#X are distinct, the former is acutally []\#X
   \end{hacs}
   
  \MS{The semantic of the following is unclear, or?}
  \begin{hacs}[numbers=right,texcl]
    Plus( { : #X, : #Y})
  \end{hacs}
  \CK{Seems to be used despite the unclearness, though!}
\end{example}  
\MS{I reduced the space they take up and added a couple of questions in between. Is it okay like
  this or do you want me to kick them out at all?}  \KR{A: I think we should give terms in
  connection with the examples below, and make sure to explain that some are incorrectly sorted.}
\MS{Okay, I am on it!} \KR{Looking forward to it: if it works we should perhaps not collect all the
  figures on one page but use individual [h!t] figures? I added one more example, as you can see, for
even more interesting combinations…}


\end{document}


%------------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% TeX-master: t
% TeX-auto-untabify: nil
% End:
