\documentclass[letterpaper,11pt]{article}

%% Style.
%\usepackage{charter}
\renewcommand{\rmdefault}{pplx}
\usepackage{eulervm}
\bibliographystyle{plain}
\usepackage[margin=1in]{geometry}

%% Format.
\input{setup}
\usepackage{cite}
\usepackage{stmaryrd}

%% Topmatter.
\title{ \hax: A Plank for Higher-order Attribute Contraction Schemes }
\author{%
  Cynthia Kop \\
  University of Copenhagen
  \and
  Kristoffer H. Rose \\
  Two Sigma Investments, LLC
  \and
  Maria Schett \\
  University of Innsbruck
  \and
  Lionel Villard \\
  IBM Research
}

%% Discussion
\newcommand{\CK}[1]{\textcolor{blue}{CK: #1}}
\newcommand{\KR}[1]{\textcolor{red}{KR: #1}}
\newcommand{\LV}[1]{\textcolor{green}{LV: #1}}
\newcommand{\MS}[1]{\textcolor{violet}{MS: #1}}
\newcommand{\JN}[1]{\textcolor{orange!70!black}{JN: #1}}

\begin{document}
\maketitle

\begin{abstract}\noindent
  %%
  We present \hax, a core (or ``plank'') calculus that can serve as the foundation for the \CRSX
  (Combinatory Reductions Systems with eXtensions) and \HAX (Higher-order Attribute Contraction
  Schemes) compiler specification languages.
  %%
  Formally, \hax is a general higher order rewriting formalism extended with first class
  \emph{associations}, and equipped with a parametric polymorphic sort system.
  %%
  In this paper we give the formal definition of the \hax calculus and its sort system, and we show
  how the central constructs of the much richer \HAX and \CRSX formalisms can be represented in
  \hax. We also outline how \hax can be implemented, and summarize central properties of the system.

  \CK{Cynthia!} \KR{Kris!} \LV{Lionel!} \MS{Maria!}
\end{abstract}

\compacttableofcontents

%------------------------------------------------------------------------

\section{Introduction}\label{sec:intro}

Several systems that manipulate programs, so-called \emph{meta-programming} systems, have emerged
over the years, ranging from generic specification languages, where the goal is not to define how
but only declare the semantics of the program manipulation, all the way to tools that support
specific aspects of program execution or compiler generation.

One direction has been to use a combination of \emph{higher order
  rewriting}~\cite{Jouannaud:klop2005} combined with \emph{higher order abstract syntax} (HOAS)
\cite{PfenningElliot:pldi1988}. This approach is used by \CRSX (Combinatory Reduction Systems with
eXtensions)~\cite{Rose:1996}, developed for writing industrial compilers at IBM
Research~\cite{Rose:hor2010,Rose:rta2011,dp60:ibm2013}, and the derived system \HAX (Higher-order
Attribute Contration Schemes)~\cite{Rose:ts2015}, developed to teach compiler construction at
NYU~\cite{RoseRose:cims2015}.

However, the direct implementation of the full \CRSX language~\cite{crsx} turned out to be quite
complex, and over time we have developed notions of what the ``core'' elements of the language
are. At the same time, \HAX has highlighted what additional programming paradigms one should add to
get a more useful programming language for writing compilers.

\TBD{Example of complex feature that can be simplified.}

The \hax calculus, presented here, represents the synthesis or what we have found to be the
essential features of a system for implementing most features of compilers.

\TBD{Plan}%
and finally Section~\ref{sec:conc} concludes and compares to related work.

%------------------------------------------------------------------------

\section{Overview}
\label{sec:overview}

In this section we outline the \hax calculus, and give several examples.

\begin{notation}[vectors]
  We will use \emph{vector notation} with $\ov{X}$ denoting $X_1,…,X_n$ for some $n≥0$. Inside
  brackets we'll allow use of ``nothing'' as the empty vector, elsewhere we use the explicit
  symbol~$ε$.  Vectors are combined by simple concatenation with ``$,$'' (comma) if needed. We will
  freely abuse this notation and, for example, write $\ov{[\ov{x}]x}$ as an abbreviation of
  $[x_{11}…x_{1m_1}]x_1…[x_{n1}…x_{nm_n}]x_n$ for suitable $n,m_1,…,m_n ≥ 0$. We further abuse the
  notation by letting $\ov{\mathcal{S}}$ denote the set of all vectors from any base
  set~$\mathcal{S}$.
  \KR{With this all Kleene stars (with ``optional commas'') are gone!}
\end{notation}

\begin{figure}[h!t]
  \begin{align}
    \tag{\hax{}Script}
    H &::= \ov{D} 
    \\
    \tag{Declaration}
    D &::= S~\kw{data}~d\,\kw(\,\ov{F}\,\kw)\,\kw;
    \bigm| S~\kw{scheme}~f\,\kw(\,\ov{F}\,\kw)\,\kw;
    \bigm| S~\kw{variable}\,\kw;
    \bigm| S~\kw{rule}~M~\kw{$→$}~M\,\kw;
    \\
    \tag{Form}
    F &::= \kw[\,\ov{S}\,\kw]\,S
    \bigm| \kwm\{\, S:S \,\kwm\}
    \\
    \tag{Sort}
    S &::= s\,\kwm{⟨}\,\ov{S}\,\kwm{⟩}
    \bigm| α
    \\[\jot]
    \tag{Meta-Term}
    M &::= c\,\kw(\,\ov{P}\,\kw)
    \bigm| v
    \bigm| m\,\kw(\,\ov{M}\,\kw)
    \\
    \tag{Piece}
    P &::= \kw[\,\ov{v}\,\kw]\,M
    \bigm| \kwm\{\, \ov{A} \,\kwm\}
    \\
    \tag{Association}
    A &::= M\,\kw:\,M
    \bigm| \kw{$¬$}\,M
    \bigm| \kw\,m\,\kw(\,\ov{v}\,\kw)
  \end{align}
  \vspace*{-2em}
  \caption{\hax syntax.}
  \label{fig:syntax}
\end{figure}

\begin{definition}[\hax syntax]\label{def:syntax}
  %%
  The \hax syntax is shown in Figure~\ref{fig:syntax}. The top level of a \hax script is $H$ and the
  grammar assumes that we have three categories of identifier tokens defined:
  %%
  \begin{itemize}

  \item $c,s,d,f ∈ \mathcal{C}$ stand for \emph{constructor} tokens, which are capitalized words
    like "Integer" or "A" or "CamelCaseWord" or "Λρ". They are used for sort, function symbol, and data
    symbol names. By convention, we use $s$/$d$/$f$ for sort/data/function names, respectively, and
    $c$ when either a data or function constructor makes sense.  

  \item $v,α ∈ \mathcal{V}$ stand for \emph{variable} tokens, which are lower case words like "x" or
    "foo" or even "lowWord", used for plain variables and sort variables (respectively).

  \item $m ∈ \mathcal{M}$ stands for \emph{meta-variable} tokens, which are tokens that start with
    "#" like "#arg" or "#BigFoot" or even just "#1" or merely~"#".

  \end{itemize}
  %%
  Finally, we allow \emph{comments} in \hax scripts from "//" to the end of lines.
  %%
\end{definition}

We shall use the following terminology:
%% 
\begin{itemize}

\item A meta-term of the form $c(P_1,…,P_n)$, for $n≥0$, is called a \emph{construction}; if furthermore
  the top symbol $c$ is declared with a "scheme c {…}" declaration then it is called a
  \emph{function construction}, and if it is declared with "data d {…}" then it is called a
  \emph{data construction}. If $n=0$, i.e., the function or data symbol does not take any arguments,
  we usually drop the $()$. That is, we write $0$ instead of $0()$.

%%    \MS{Here comes a really general question: How do data and function constructors/constructions
%%      relate to constructor and defined symbols in term rewriting (To clarify: A symbol is
%%      \emph{defined} wrt to a set of rules, if it occurs at the root of a left-hand side of a
%%      rule. The other symbols are constructors.) I have a feeling, that this is actually similar?
%%      If so, I may argue, that the distinction is easily computable and is maybe not core?  } \KR{A:
%%      Yes, one can argue this. Not sure what the right answer is.}  \MS{I'd go for simpler. Maybe we
%%      can discuss this on the call?}  \MS{Conclusion: For implementation it is easier to declare
%%      it. It is computable though.} \KR{You can see it in the type rules, now.}

\item Argument ``pieces'' $P$ of constructions take one of two forms: \emph{scopes} $[v_1,…,v_n]M$,
  $n≥0$, which introduce new local variables $v_1,…,v_n$ along with a meta-term $M$ wherein they can
  occur, and \emph{associations} $\{A_1,…,A_n\}$, $n≥0$, where each $A$ is either an \emph{entry}
  $M:M$, an \emph{exclusion} $¬M$, or a \emph{catcher} $m(v_1,…,v_n)$, $n≥0$.

  For scopes, if $n=0$, \ie, there are no new variables introduced by the scope, then $[]$ can be
  omitted: we write $S(0)$ instead of $S([]0)$.

\item A meta-term of the form $m(M_1,…,M_n)$, $n≥0$, is a \emph{meta-application}.  A meta-term that
  does not contain any meta-applications is called (simply) a \emph{term}.
  %%
  \KR{This takes care of the distinction between meta-term and term.}
  \CK{Would it be acceptable to replace ``any meta-applications'' by ``any meta-applications or exclusions'' in that reformulation?}

%%  \MS{E.g., in KR thesis, TeReSe, a distinction between meta term and term (i.e., a meta term
%%    without meta variables) is made. Do we also want to do this?}
%%
%%  \CK{I'd say it's certainly desirable to do so, as we don't really want to have to deal with
%%    rewriting meta-terms, just terms.  Moreover, the difference is larger here than in TeReSe, as
%%    I'd also expect that terms have no exclusions.
%%    \\
%%  \textbf{\emph{Suggestion:}}
%%  In the syntax, replace ``Term'' by ``Meta-term'' (and perhaps the T by an M).  Then add
%%  something like: a \emph{term} is a meta-term without meta-variable tokens or exclusions; that
%%  is, a meta-term generated by the restricted grammar:
%%  \begin{align}
%%    \tag{Term}
%%    T &::= c\,\kw(\,{P'}^{*\kw,}\,\kw)
%%    \bigm| v
%%    \\
%%    \tag{Piece}
%%    P' &::= \kw[\,\ov{v}\,\kw]\,T
%%    \bigm| \kwm\{\, {A'}^{*\kw,} \,\kwm\}
%%    \\
%%    \tag{Association}
%%    A' &::= T\,\kw:\,T
%%  \end{align}
%%}
%%\KR{Done but no grammar needed---just the wording above.}

\item A meta-term of the form $v$ is a \emph{variable occurrence}; if the variable $v$ occurs contained
  in a scope $[…v…]M$ then the variable occurrence is \emph{bound}.

\end{itemize}

%%\MS{About $F ::= \kw[\,S_1^{*\kw,}\,\kw]\,S_2$. Can $S_1$ actually be something different than a sort variable?}
%%\CK{They really shouldn't be.}
%%\KR{Why not? Is there a problem with the new Example~\ref{ex:pick}?}
%%\CK{My mistake, they can be of course. I was thinking of $S\langle S\rangle$, and even then, we
%%only really want to limit the inner $S$ to sort variables when defining data (e.g.~it's allowed
%%to have a scheme with sort $\mathtt{list}\langle\mathtt{nat}\rangle$, but not to define a data
%%constructor with this as output type).}\KR{A: Well stated. We should capture this in the text.}

In summary, we distinguish four different ways to brace elements. For data and scheme
\emph{subterms}, and for \emph{meta-application arguments} we use $\kw{( )}$.  For \emph{binders} we
use $\kw{[ ]}$.  For \emph{associations} we use $\kwm{\{\,\}}$.  For \emph{sort parameters} we use
$\kwm{⟨\,⟩}$.

In Figure~\ref{fig:syntax}, the $S$ in $S~\kw{rule}~M~\kw{$→$}~M\,\kw;$ is not superflous. Consider
the following two rules:
\begin{hacs}[numbers=right]
    List⟨α⟩ rule Map([x]#(x), Nil) →  Nil;
    List⟨Int⟩ rule Map([x]#(x), Cons(#1, #2)) →  Cons(#(#1), Map([x]#(x), #2));
\end{hacs}
\MS{I am not sure, I completely understand yet.}
\CK{This states why it is important to give the sort of a rule: because
sometimes, sorts may be ambiguous.  The first rule is defined for arbitrary
lists, the second only for lists of integers, and will be met with a
compiler error if you try to use it on a list of strings.  I'm not convinced
it's a very good example, though: it doesn't make it clear why you would
\emph{want} the rule to be limited to integer lists!}
%%
\KR{Yes, we need a better example. Essentially it seems \hax can have \emph{sort dispatch} by
  allowing two rules that overlap \emph{except} for the parameter sort.}

It is even possible to have function constructors that live in \emph{all} sorts:
\begin{hacs}[numbers=right]
    α scheme If(Bool, α, α);
    α rule If(True, #1, #2) → #1;
    α rule If(False, #1, #2) → #2;
\end{hacs}

\begin{example}
  Example terms without Associations are: 
  %% 
  \begin{hacs}[numbers=right, texcl]
      Zero, Plus(#X, #Y), S(Zero), x, #X, S([x,y]#X[y,x,z]), #X[x], #F[Zero], #F[#X]
      [x,y]#F[y,x]
    \end{hacs}
    \MS{So currently, a meta-application is (strictly speaking) not called a term (except for
      $\#X$). Do we want this?}

    \CK{A meta-application $\#X[\kw{0}]$ or $\#X[z]$ is a term.  However,
    \emph{scopes} are not considered terms (I would propose not calling it
    a ``pattern meta-application'' as that is misleading, though).}
    
    Example terms with Associations of the form $M \kw{:} M$, where the key is a variable or a
    constant, are
    %% 
    \begin{hacs}[numbers=right,texcl]
      Plus(x, { x : Zero }), Plus(#X, { x : Zero }), Plus(Zero, {Zero : S(Zero)}) 
    \end{hacs}
    
    Example terms, where the keys are meta-variables. \MS{I am sorry, I forgot, is this allowed?}
    \CK{Woah, the second one definitely isn't, because the key is not a term;
    even if it was, this would not be sortable with our second-order system.
    I don't think there's any problem with the first.}
    \begin{hacs}[numbers=right,texcl]
     S({ #X : #Y }), #Z[S({ #X : #Y })]                    
     S({[x]#X[x] : Zero }), 
   \end{hacs}

   \MS{The semantic of the following two is unclear, or?}
   \CK{For the former, yes -- an association should be a mapping.  But for the
   latter, couldn't it be a term carrying \emph{two} association mappings?  I
   don't know whether we ever want this, but it doesn't necessarily give
   ambiguity, I think.}
%   \begin{hacs}[numbers=right,texcl]  
%     S( {x : y, x : Zero} )
%     Plus( {x : y}, {x : Zero} )
%   \end{hacs}
   Example terms with Associations of the form $¬M$ are:
   \begin{hacs}[numbers=right,texcl]
     Plus(x, { ¬x }), Plus(x, { ¬Zero }), Plus(#X,{¬Zero}), S({ ¬#X }), 
     #Z[S({ ¬#Z[x] })], S({ ¬S([x]#X[x]) }), Plus(Zero,{¬S(Zero)}), Plus({ ¬x}, { ¬z})
   \end{hacs}
   
   Finally, Example terms with Associations of the form $: m$ are:
   \begin{hacs}[numbers=right,texcl]
     Plus(x, { : #X }), Plus( { : #X}, { : #X}), Plus( { : #X}, { : #Y})
     Plus( #X, { : #X })  // note, here \#X are distinct, the former is acutally []\#X
   \end{hacs}
   
  \MS{The semantic of the following is unclear, or?}
  \begin{hacs}[numbers=right,texcl]
    Plus( { : #X, : #Y})
  \end{hacs}
  \CK{Seems to be used despite the unclearness, though!}
\end{example}  
\MS{I reduced the space they take up and added a couple of questions in between. Is it okay like
  this or do you want me to kick them out at all?}  \KR{A: I think we should give terms in
  connection with the examples below, and make sure to explain that some are incorrectly sorted.}
\MS{Okay, I am on it!} \KR{Looking forward to it: if it works we should perhaps not collect all the
  figures on one page but use individual [h!t] figures? I added one more example, as you can see, for
even more interesting combinations…}

The \hax formalism includes traditional ``constructor'' term rewriting systems, where there is a
distinction between \emph{defined} symbols (\hax function constructors) and undefined symbols (\hax
data constructors).

\begin{example}\label{ex:peano}
  The classical first order \emph{Peano arithmetic} rules can be encoded as the following simple
  \hax system:
  %% 
  \begin{hacs}[numbers=right,texcl]
    // N is natural number sort
    N data Z ;                                            // zero
    N data S(N) ;                                         // successor
    N scheme Plus(N, N) ;                                // $+$ operator
    N rule Plus(Z, #2) →  #2 ;                           // $0+x = x$
    N rule Plus(S(#1), #2) →  S(Plus(#1, #2)) ;          // $(1+x)+y=1+(x+y)$
  \end{hacs}
  %%
  The example illustrates how a sort is defined with data constructors and a scheme for
  rewriting:
  %%
  \begin{itemize}

  \item The defined sort is "N". All the other declarations define artifacts of sort~"N". (Notice
    that we have omitted the empty sort parameter list, it is really "N⟨⟩".)

  \item There are two \kw{data} constructors declared: "Z" with no parameters, and "S" with a single
    numeric argument. Again we write "Z" instead of the full "Z()".

  \item There is a single function (\kw{scheme}) constructor, "Plus", with two numeric
    arguments.

  \item There are two \kw{rule}s for the function symbol, implementing the usual Peano addition
    rules. Since the contained scopes have no binders or meta-application arguments, we write, \eg,
    "Plus(Z,#2)" instead of the full "Plus([]Z(),[]#2())".

  \end{itemize}
  %%
  A sample rewrite sequence using this system, corresponding to the computation $1+1=2$, is
  %%
  \begin{displaymath}
    "Plus(S(Z), S(Z))" →
    "S(Plus(Z, S(Z)))" →
    "S(S(Z))"
  \end{displaymath}
  %%
\end{example}

\hax also includes traditional higher-order rewriting systems (again with distinct defined symbols).
Indeed, \hax includes
%\KR{Cynthia: please insert proper designation and reference (Inductive Pattern
%  Systems?!?).}
Aczel's \emph{Contraction Schemes}~\cite{Aczel:1978}, and Klop's \emph{Combinatory
Reduction Systems}~\cite{Klop+:tcs1993} when a simple typing is imposed (which can also
be seen as the second-order limitation of Blanqui's \emph{Inductive Data Type
Systems}~\cite{BlanquiJouannaudOkada:tcs2002}).
\CK{Inserted the references, feel free to refomulate.  Basically, IDTSs are
simply-typed CRSs where any typing is permitted, and what we're doing is
second-order simply-typed CRSs plus association lists.  Contraction schemes are
second-order simply-typed CRSs with some unnecessary additional restrictions, so
closest to what we're doing, but it's a not-exactly-published paper that is
somewhat doomed to live in obscurity (although for a nice extra, they share our
notational convention that an abstraction is not considered a term).}

\begin{example}\label{ex:lambda}
  %%
  The \emph{untyped λ calculus} can be encoded in \hax directly:
  %%
  \begin{hacs}[numbers=right,texcl]
    // Λ is the sort of λ terms
    Λ  data Lm([Λ]Λ) ;                                        // abstraction
    Λ  scheme Ap(Λ, Λ) ;                                      // application
    Λ  rule Ap(Lm([x]#body(x)), #arg) →  #body(#arg) ;    // β-reduction
  \end{hacs}
  %%
  The declarations can be explained as follows:
  %%
  \begin{itemize}

  \item "Λ" includes an abstraction construction, which is a "data" case, and which includes a
    subterm with a single binder scoped over that subterm. The scoped subterm is written as
    "[Λ]Λ", which should be read as ``a subterm with a locally bound variable of sort "Λ" and a
    body of sort "Λ" in which it can occur.''

  \item "Λ" includes a usual case for application construction, which is a "scheme" because it
    can (sometimes) be rewritten.

  \item We specify one rewrite "rule" for "Λ": β-reduction. As usual, the rule specifies how an
    application of an abstraction is simplified. The interesting aspect of the pattern is how the
    abstraction is matched: the part of the pattern "[x]#body(x)" means ``the scoped subterm with
    binder "x" and subterm "#bind" wherein we keep track of where "x" occurs.'' Note the similarity
    to the declaration of the subterm of the "Lm" constructor.

  \item Once an application of an abstraction is matched, the "rule" gives the result of
    simplification as "#body(#arg)", which means that we construct a copy of "#body" except all
    occurrences of the variable we matched (and kept track of) in the pattern "#body(x)" are
    substituted with what "#arg" matched.

    \KR{Note: the \kw{variable} declaration has been removed as it was incorrect here.}

  \end{itemize}
  %%
  A usual λ term like $(λx.x x)(λy.y)$ simplifies like this:
  %%
  \begin{displaymath}
    "Ap(Lm([x]Ap(x, x)), Lm([y]y))" →
    "Ap(Lm([y]y), Lm([y]y))" →
    "Lm([y]y))"
  \end{displaymath}
  %%
  Notice that \hax describes the classic untyped λ-calculus with ``normalization'' all the way to
  \emph{normal form}: there are no constraints on simplification under binders, and no implied
  evaluation order like ``call-by-value.'' Furthermore, because variables can only be introduced
  through the scope mechanism, our system can only express and simplify \emph{closed} λ-terms.
  %%
\end{example}

\hax also supports traditional recursive data structures.

\begin{example}\label{ex:list}
  The sort of \emph{polymorphic lists} can be described as follows, with a ``map'' operator to apply
  a function to each member of the list.
  %%
  \begin{hacs}[numbers=right]
    List⟨α⟩ data Nil; List⟨α⟩ data Cons(α, List⟨α⟩);
    List⟨α⟩ scheme Map([β]α, List⟨β⟩);
    List⟨α⟩ rule Map([x]#(x), Nil) →  Nil;
    List⟨α⟩ rule Map([x]#(x), Cons(#1, #2)) →  Cons(#(#1), Map([x]#(x), #2));
  \end{hacs}
  %%
  The target sort "List⟨α⟩" captures lists where the elements are of the unknown sort~"α".
  %%
  Line~1 defines the two data constructors for lists, "Nil" and "Cons", the latter with the usual
  arguments.
  %%
  Line~2 declares the "Map" scheme in the usual way, using a \hax scope as a representation of the
  function to apply to all members.
  %%
  Lines 3~and 4 then give the usual rules for simplifying a mapping. In line~4, the function is
  applied in the same way that we saw for the untyped λ-calculus: the pattern (left side of "→")
  captures the function's effect as $x↦\#(x)$ with "[x]#(x)", and the contraction (right side of
  "→") applies the captured function to the first element with "#(#1)".

  An example simplification would be
  %%
  \begin{displaymath}
    "Map([x]S(x), Cons(Z, Nil))"
    → "Cons(S(Z), Map([x]S(x), Nil))"
    → "Cons(S(Z), Nil)"
  \end{displaymath}
  %%
  Notice that there is no ``apply'' operator: the formalism \emph{immediately} performs the
  substitution as part of the "Map" rewrite step.
  %%
\end{example}

In addition to being a higher-order rewriting formalism, \hax allows ``free'' variables in terms and
rules, with some restrictions. This is what the \kw{variable} declaration is for.

\begin{example}\label{ex:lambda-x}
  %%
  Here is an example from the literature, $λ$x~\cite{BlooRose:csn1995}, which changes the λ calculus
  from Example~\ref{ex:lambda} in two ways:
  %%
  \begin{enumerate}

  \item Variables are made \emph{syntactic}: they are declared with "variable", so they can be
    matched in rules but only substituted by variables.

  \item The β-reduction rule is replaced with a new scheme "Ex", which performs the substitution
    explicitly, without referring to the primitive substitution of \hax except for renaming.

  \end{enumerate}
  %%
  \begin{hacs}
     Λx variable; // explicit variable
     Λx data Lm([Λx]Λx); // abstraction
 
     Λx scheme Ap(Λx,Λx); // application
     Λx rule Ap(Lm([x]#(x)),#x) → Ex([x]#(x),#x);  //(b)
 
     Λx scheme Ex([Λx]Λx,Λx); // explicit substitution
     Λx rule Ex([x]x,#x) → #x;  // (xv)
     Λx rule Ex([x]y,#x) → y;   // (xvgc)
     Λx rule Ex([x]Ap(#f(x), #a(x)), #x) →  Ap(Ex([x]#f(x),#x), Ex([x]#a(x),#x));  // (xap)
     Λx rule Ex([x]Lm([y]#(x,y)), #x) →  Lm([y]Ex([x]#(x,y), #x));                 // (xab)
  \end{hacs}
  %%
  An example evaluation would be
  \begin{displaymath}
    \vbox{
      "Ap(Lm([x]Ap(x, x)), Lm([y]y))"\\
      "→ "\\
    }
  \end{displaymath}
  \KR{Finish this…}
  %%
\end{example}

\KR{\textbf{NOTE:} Example shows that we need a way to ensure that (xv) is selected before (xvgc),
  \ie, in the original formalism all the rules are mutually exclusive. In my thesis, this is ensured
  by the \emph{variable convention}: ``all free and bound variables in any context must be
  distinct'' which implies $x≠y$ in the (xvgc) rule…}

\CK{Are they not still mutually exclusive, even without the variable convention? $[x]x$ and $[x]y$
are not unifiable, and I would always define matching in a way to ensure that a free variable
cannot capture a bound one, regardless of its name.}

\JN{I agree. $[x]y$ should not match anything of the form $[x]\#(x)$, i.e., a term that does contain
  the bound $x$}

\KR{Hm: in \CRSX, both of the (sub)terms $A([x]y)$ and $A([x]x)$ match the pattern $A([x]\#(x))$:
  the variable is \emph{allowed} but \emph{not required}. \CRSX3 includes a special notation
  (introduced by the dispatchifier) such that the pattern $A([x]\#(!x))$ is matched only by
  $A([x]x)$ but not by $A([x]y)$ because $x$ must be present. All the systems have that the pattern
  $A([x]\#())$ matches $A([x]y)$ but not $A([x]x)$. One can argue that it makes sense to have only
  the mutually exclusive forms $A([x]\#(!x))$ and $A([x]\#())$ but that would be a different kind of
  system.}

Formally, when a sort has a \kw{variable} declaration then it is said to have \emph{syntactic
  variables}, which has some consequences:
%%
\begin{itemize}

\item variables of that sort may occur unbound in the meta-terms whose reduction you consider
  (others will only occur bound);

\item you can \emph{match} on an explicit variable (either bound or free) of one of these sorts;

\item variables of these sorts may occur free in the right-hand side of a rule, which corresponds to
  \emph{creating} new ``fresh'' variables in the contracted term.

\item substitution is restricted to variables for the sort.

\end{itemize}
%%
So it is not possible to combine the "Λ" sort from Example~\ref{ex:lambda} with "Λx" from
Example~\ref{ex:lambda-x}: sorts are either ``classic'' higher-order, like "Λ", or ``syntactic''
higher-order, like "Λx", but never both.





\KR{Examples under here need further work…}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Abstract Syntax.
Program⟨α,β⟩ data Block(α, β, Program⟨α,β⟩);
Program⟨α,β⟩ data Then(Program⟨α,β⟩, Program⟨α,β⟩);
Program⟨α,β⟩ data Stat(α);

// Type Environment.
Γ⟨α,β⟩ data Env({α:β});

// Create environment from Program
Γ⟨α,β⟩ scheme Mk(Program⟨α,β⟩);
Γ⟨α,β⟩ rule Mk(Stat(#)) → Env({});
Γ⟨α,β⟩ rule Mk(Then(#1, #2)) → Union(Mk(#1), Mk(#2));
Γ⟨α,β⟩ rule Mk(Block(#x, #t, #)) → Union(Env({#x : #t}, Mk(#)));

// Helper to create union of two environments.
Γ⟨α,β⟩ scheme Union(Γ⟨α,β⟩, Γ⟨α,β⟩);
Γ⟨α,β⟩ rule Union(Env({#1}), Env({#2})) → Env({#1,#2});
  \end{hacs}
  \caption{Type environment over simple AST.}
  \label{fig:te}
\end{figure}

\begin{example}[environment handling]\label{ex:te}
  %%
  Figure~\ref{fig:te} shows sorts and rules for 
  %%
\CK{This example is interesting, because it combines two catchers in
the same association set on the right! I wonder how that's defined.
(Although it's easily avoided if undesirable, by simply replacing the
``union'' by an ``add''.)}
\KR{Indeed! I think Lionel has it implemented as ``add''…but here we should describe the ideal as
 long as it allows for add, I think.}
\CK{So what \emph{should} the semantics be?  If there are conflicting
 pairs in \#1 and \#2, what happens? Does the first or the second take
 priority, or should it crash?}
\LV{Yes it's implemented as add. In this case the semantic could
be \#2 is added to \#1. Entries in \#2 override entries in \#1.}

\JN{So, is the conclusion that we have a biased union? that seems a bit awkward though, doesn't it?
  Since then the semantics of $Env(\{\#1,\#2\})$ and $Env(\{\#2,\#1\})$ would be different but it's
  a set so \dots}

\KR{If we go with add/biased union then associations are indeed not sets. Maps are so fundamental in
  semantics that I think any complications arising from the ``non-setness'' of them are a necessary
  price to pay.}

\end{example}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Booleans with conditional.
Bool data True; Bool data False; α scheme If(Bool, α, α);

// If rules.
α rule If(True, #1, #2) → #1;
α rule If(False, #1, #2) → #2;

// Pick number.
N scheme Pick(List⟨N⟩, [N,N]Bool);
N rule Pick(#, [x,y]#greater(x,y)) → Pick2(#, [x,y]#pick(x,y), Zero);

N scheme Pick2(List⟨N⟩, [N,N]Bool, N);
N rule Pick2(Nil, [x,y]#greater(x,y), #n) → #n;
N rule Pick2(Cons(#1, #rest), [x,y]#pick(x,y), #n)
  → Pick2(#rest, [x,y]#greater(x,y), If(#greater(#1,#n),#1,#n));
  \end{hacs}
  \caption{Find largest element of a list of natural numbers.}
  \label{fig:pick}
\end{figure}

\begin{example}[]\label{ex:pick}
  %%
  Figure~\ref{fig:pick} shows a simple ``pick a number from a list'' program
  (assuming the "N" sort from example~\ref{ex:peano}, and the "List" sort from
  Example~\ref{ex:list}).

  \CK{This example seems incomplete.  For example, what's N? Is that meant to
  be 0? It's not declared; we have thus far only seen Z (of sort N, not Int).
  But if you want the largest element (as the caption suggests) of a list of
  \emph{integers}, defaulting to 0 does not seem like a good idea!  Also, the
  figure declares booleans and an if scheme, but does not use them.  Oh, and
  the second Pick2 rule is not well-typed (as the third argument of the RHS
  has type Bool rather than Int).}
  \KR{Yep, its a bit sketchy. Anyone?}
  \CK{Do you like it like this? I wasn't sure about adding the If rules (which
  were given before, but not in an example that I could refer to), and whether
  any rules for the comparison should be given.}
  %%
\end{example}

Syntactic higher-order sorts can, however, be used with associations, and in this context
associations can be used to store environments. The next example explores this.

\begin{example}
  %%
  Variation: evaluator with a proper environment. \TBD{Find proper reference.}
  %%
  \begin{hacs}
    Λρ  variable; // explicit variable
    Λρ  data Lm([Λρ]Λρ); // abstraction
    Λρ  data Ap(Λρ,Λρ); // application

    Λρ  scheme E(Λρ, {Λρ:Λρ}); // evaluation context

    Λρ  rule E(x, {x : #x}) → #x;
    Λρ  rule E(x, {¬x}) → x;
    Λρ  rule E(Lm([y]#(y)), {#}) →  Lm([y]E(#(y), {#}));

    Λρ  rule E(Ap(x, #a), {#}) →  E(Ap(E(x, {#}), E(#a, {#})), {#});
    Λρ  rule E(Ap(Ap(#f, #1), #2), {#}) →   E(Ap(E(Ap(#f, #1), {#}), E(#2, {#})), {#});
    Λρ  rule E(Ap(Lm([x]#(x)), #a), {#}) →  E(#(x), {#, x : E(#a,{#})});
  \end{hacs}
  %%
  Notice how application is now data
  %%
  \KR{Finish it…the idea is one starts with Ec(term, \{\})…}
  %%
\end{example}

\begin{remark}
  One difference between the CRSX family, including \hax, and other higher order rewriting
  formalisms, is that the binder mechanism is part of the parent construction, \eg, the sort of the
  "S" constructor defines that instances must have the shape "S([]…)" with "…" being itself a Peano
  number.  Otherwise, binding and substitution are in the style of CRS higher order rewrite
  systems~\cite{Klop+:tcs1993}---The notation does differ from the original CRS notation in that we
  use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$, and we use
  square brackets instead of round for meta-application arguments. \KR{Update!}
\end{remark}


%------------------------------------------------------------------------

\section{Sorting}
\label{sec:sorting}

The \hax calculus in practice restricts the terms of the grammar in Figure~\ref{fig:syntax} further
by only allowing sortable scripts. Informally, sorting ensures that
%%
\begin{itemize}
\item the pattern and contraction restrictions are obeyed;
\item binders are used in the shape declared for constructors;
\item subterms (including variable and meta-variable occurrences) have the right sort;
\item association keys and values have the proper sorts.
\end{itemize}

\begin{figure*}[p]
  \vspace*{-3em}
  \begin{align}
    %
    \intertext{\shoveright{Sorting of \hax script \hfil \fbox{$ ⊢ H $}}}
    %
    &\dfrac
    { Γ ⊢ D_1 \quad\cdots\quad Γ ⊢ D_n }
    { ⊢ D_1…D_n }
    && (∃Γ)
    \tag{S-H}
    %
    \\
    \intertext{\shoveright{Sorting of Declaration\hfil\fbox{$ Γ ⊢ D $}}}
    %
    &\dfrac
    {}
    { Γ ⊢ s⟨\ov{α}⟩~\kw{data}~d\kw( \ov{F} \kw)\,\kw; }
    && Γ_{\op{cons}}(d) = \left⟨ s⟨\ov{α}⟩, \ov{F} \right⟩
    \tag{S-D-Data}
    %
    \\[\jot]
    %
    &\dfrac
    {}
    { Γ ⊢ S~\kw{scheme}~f\kw( \ov{F} \kw)\,\kw; }
    && Γ_{\op{cons}}(f) = \left⟨ S, \ov{F} \right⟩,~f∈Γ_{\op{fun}}
    \tag{S-D-Fun}
    %
    \\[\jot]
    %
    &\dfrac
    {}
    { Γ ⊢ s⟨\ov{α}⟩~\kw{variable}\,\kw; }
    && s ∈ Γ_{\op{hasvar}}
    \tag{S-D-Var}
    %
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},ε ⊢ f(\ov{F}) : S  \qquad Γ,Δ,\op{Con},ε ⊢ M : S }
    { Γ ⊢ S~\kw{rule}~f(\ov{F})~\kw{→}~M\,\kw; }
    && (∃Δ),~f∈Γ_{\op{fun}}
    \tag{S-D-Rule}
    %
    \\
    \intertext{\shoveright{Sorting of Term\hfil\smash{\fbox{$ Γ,Δ,RS,\ov{\mathcal{V}} ⊢ M : S $}}}}
    %
    &\dfrac
    { Γ,Δ,RS,\ov{w} ⊢ P_1 : F_1 \quad\cdots\quad Γ,Δ,RS,\ov{w} ⊢ P_n : F_n }
    { Γ,Δ,RS,\ov{w} ⊢ c\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : S }
    &&\Cases{
      Γ_{\op{cons}}(c) = \left⟨ S, (F_1\kw,…\kw,F_n) \right⟩\\
      c∉Γ_{\op{fun}} ∨ RS=\op{Con}
    }
    \tag{S-M-Cons}
    % 
    \\[\jot]
    %
    &\dfrac
    { }
    { Γ,Δ,RS,\ov{w} ⊢ v : s⟨\ov{S}⟩ }
    && Δ_{\op{var}}(v) = s⟨\ov{S}⟩, ~s∈Γ_{\op{hasvar}}
    \tag{S-M-Var}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},\ov{w} ⊢ v_1 : S_1 \quad\cdots\quad  Γ,Δ,\op{Pat},\ov{w} ⊢ v_n : S_n }
    { Γ,Δ,\op{Pat},\ov{w} ⊢ m\,\kw(\,v_1\kw,…\kw,v_n\,\kw) : S }
    &&\Cases{
      ∀i\colon v_i∈\ov{w} \\
      Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒S \right)
    }
    \tag{S-M-MetaP}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Con},\ov{w} ⊢ M_1 : S_1 \quad\cdots\quad  Γ,Δ,\op{Con},\ov{w} ⊢ M_n : S_n }
    { Γ,Δ,\op{Con},\ov{w} ⊢ m\,\kw(\,M_1\kw,…\kw,M_n\,\kw) : S }
    && Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒S \right)
    \tag{S-M-MetaC}
    %
    \\
    \intertext{\shoveright{Sorting of Piece\hfil\smash{\fbox{$ Γ,Δ,RS,\ov{\mathcal{V}} ⊢ P : F $}}}}
    %
    &\dfrac
    { Γ,Δ',RS,(\ov{w}\,\ov{v}) ⊢ M : S }
    { Γ,Δ,RS,\ov{w} ⊢ \kw[\,\ov{v}\,\kw]\,M : \kw[\,\ov{S}\,\kw]\,S }
    && (∃Δ'⊇Δ),~ Δ'_{\op{var}}(\ov{v}) = \ov{S}
    \tag{S-P-Bind}
    %
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,RS,\ov{w} ⊢ A_1 : \{S_1{:}S_2\} \quad\cdots\quad Γ,Δ,RS,\ov{w} ⊢ A_n : \{S_1{:}S_2\} }
    { Γ,Δ,RS,\ov{w} ⊢ \kwm\{\,A_1\kw,…\kw,A_n\,\kwm\} : \kwm\{S_1\kw:S_2\kwm\} }
    \tag{S-P-Assoc}
    %
    \\
    \intertext{\shoveright{Sorting of Association\hfil\smash{\fbox{$ Γ,Δ,RS,\ov{\mathcal{V}} ⊢ A : \{S{:}S\} $}}}}
    %
    &\dfrac
    { Γ,Δ,RS,\ov{w} ⊢ M : S \qquad Γ,Δ,RS,\ov{w} ⊢ M' : S' }
    { Γ,Δ,RS,\ov{w} ⊢ M\kw:M' : \{S{:}S'\} } 
    \tag{S-A-Map}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},\ov{w} ⊢ M : S }
    { Γ,Δ,\op{Pat},\ov{w} ⊢ \kwm{¬}M : \{S{:}S'\} }
    \tag{S-A-Not}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},\ov{w} ⊢ v_1 : S_1 \quad\cdots\quad  Γ,Δ,\op{Pat},\ov{w} ⊢ v_n : S_n }
    { Γ,Δ,RS,\ov{w} ⊢ m\,\kw(\,v_1\kw,…\kw,v_n\,\kw) : \{S{:}S'\} }
    &&\Cases{
      ∀i\colon v_i∈\ov{w} \\
      Δ_{\op{meta}}(m) = \left( (S_1,…,S_n)⇒\{S{:}S'\} \right)
    }
    \tag{S-A-All}
    %
  \end{align}
  \vspace*{-2em}
  \caption{\hax sorting rules.}
  \label{fig:sortrules}
\end{figure*}

\begin{definition}[well-sorted]\label{def:sort}
  Given a \hax script $H$, a sort $\op{Void}∈S$ which does not occur in $H$, and a sort environment
  $Γ$, and define the additional pseudo-syntax rules
  %%
  \begin{align}
    RS &::= \op{Pat} \mid \op{Con} \tag{RuleSide} \\
    MF &::= \ov{S}⇒S \mid \ov{S}⇒\{S{:}S\} \tag{MetaForm}
  \end{align}
  %% 
  The \hax script is \emph{well-sorted for $Γ$} if $Γ$ is the smallest sort environment for which we
  can prove
  %%
  \begin{displaymath}
    ⊢ H
  \end{displaymath}
  %%
  using the rules of Figure~\ref{fig:sortrules}.
  %%
\end{definition}

Each proof will need to invent a \emph{global sort environment} witness $Γ$, a structure that
combines
%% 
\begin{itemize}

\item $Γ_{\op{hasvar}}\colon 2^{\mathcal{C}}$ is a set of sort names (the sorts that allow variables).

\item $Γ_{\op{cons}}\colon \mathcal{C} → S×F^*$ from constructor name to pairs of a sort and a
  list of forms.

  
\item $Γ_{\op{fun}}\colon 2^{\mathcal{C}}$ is a set of constructor names (those declared as schemes).

\end{itemize}
%% 
and one \emph{rule sort environment} witness $Δ$ per rule, a structure that combines
%% 
\begin{itemize}

\item $Δ_{\op{var}}\colon \mathcal{V} → S$ from variable names to sorts.

\item $Δ_{\op{meta}}\colon \mathcal{M} → MF$ from meta-variable names to to 
  names to ``meta-forms'' 

\end{itemize}

Notes.
%%
\begin{itemize}

\item $MF$ captures the difference between regular meta-variables and ``$\kw:m$'' ones:
  \begin{itemize}

  \item The shape $\ov{S}⇒S$ is used for meta-variables that need to be meta-applied to
    arguments with the sorts $\ov{S}$ to then form a term of the sort~$S$.
      
  \item The shape $\ov{S}⇒\{S_1{:}S_2\}$ used for meta-variables that ``catch'' all the associations
    in an association list from $S_1$ to~$S_2$.
    
  \end{itemize}

  \item\TBD{More explanation.}
    
\end{itemize}

\TBD{Example sort derivation.}

%------------------------------------------------------------------------

\section{Rewriting}
\label{sec:rewriting}

In this section we formally define rewriting in the \hax calculus. We follow [\TBD{Cynthia?}] in
defining rewriting in the context of a sort assignment.

\JN{started thinking about how to define rewriting and wondered about inconsistent bindings in
  association maps in general. My mental model so far was that of a partial mapping, but of course I
  can easily write down a term (or even rule) that has inconsistent associations. Put differently:
  are these things really mappings that are represented as sets of pairs, i.e., by their graph, or
  are they actually sets of pairs that are usually used as mappings? Thinking a bit further: if
  inconsistent assocs are possible then what happens when I have a term $t = f(\{x: T, x: F\})$ and
  a rule $f(\{x : \#1, \#2\}) \to \#1$. My intuition would be that $t$ indeed has the two reducts,
  $T$ and $F$. Also, what's the expected semantics of two catchers in the same assoc map in the lhs
  of a rule, e.g.\ $f(\{\#1,\#2\}) \to \#1$. When I apply that rule, do I just get sub-map,
  non-deterministically?}

\begin{definition}[substitution]
  
\end{definition}

\TBD{mv, fv, substitution, rewriting.}

\begin{theorem}[subject reduction]
  Given a well-sorted \hax script $H$ with the rewrite 


A well-sorted term can only rewrite to a well-sorted term.
\end{theorem}

%------------------------------------------------------------------------

\section{Properties}
\label{sec:properties}

In this section we provide proofs for several standard rewrite properties of~\hax.

\TBD{What do we know of properties of such a system…Cynthi or Maria or Julian?
  \\
  Also: decidability of type checking, possibly type inference?}


%------------------------------------------------------------------------

\section{Implementing \hax}
\label{sec:implement}

In this section we give notes on how we see \hax implemented. The implementation uses classic term
graph rewriting extended to handle binders and associations.

The basic \hax implementation consists of a term representation and a main ``progress loop.''

\begin{definition}[identifiers]
  %%
  In the implementation we keep track of the following \emph{identifiers}:
  %%
  \begin{itemize}

  \item \emph{Variable identifiers}. A variable identifier is globally unique. It should be suitable
    for \emph{comparison} and \emph{hashing}.

  \item \emph{Constructor identifiers}. A constructor identifier is globally unique and suitable for
    hashing. From the constructor identifier one can derive the kind and signature of the
    constructor:
    \begin{itemize}
    \item Is it a function or data constructor? Data constructors should be suitable for use as C
      switch keys.
    \item How many scope-formed formal arguments (declared as $[S^*]S$) does the constructor take,
      and how many local variables are bound by each?
    \item How many association-formed formal arguments (declared as $\{S:S\}$) does the constructor
      take?
    \end{itemize}
    Note that everything is assumed to be well-sorted.

  \end{itemize}
  %%
  In addition, both forms of identifiers support \emph{printing} the identifier in an identifiable
  fashion [sic].
  %%
\end{definition}

\begin{structure}[term representation]
  %%
  Terms are maintained as a graph structure with nodes containing:
  %%
  \begin{itemize}
  \item Constructor identifier.
  \item Reference count.
  \item Pointer to cached free variable set (more on this below).
  \item Array of free variable identifiers (with length as required by constructor to cover all
    scopes).
  \item Array of pointers to scoped subterms (with length as required by the constructor).
  \item Array of association sets (with length as required by the constructor).
  \end{itemize}
  %%
\end{structure}

\begin{structure}[association set]
  
\end{structure}



\TBD{What about dispatchification…Maria?}




%------------------------------------------------------------------------

\section{Supporting Compiler Paradigms}
\label{sec:compiling}

In this section we outline how the core idioms of the full \CRSX and \HAX languages translate
into~\hax.

\KR{For \HAX I am developing these in crsx/hacs/doc/hacs2.tex.}

%------------------------------------------------------------------------

\section{Conclusion}
\label{sec:conc}

With \hax, we have presented a rather small calculus that can serve as the underlying formalism for
reasoning about as well as implementing the \CRSX and \HAX languages.

\TBD{What is covered.}

~\cite{Knuth:mst1968} 
~\cite{Aho+:2006}


\paragraph*{Related work.}

We would like to give credit to SIS~\cite{Mosses:daimi1979}, which shares with \hax the use of
\emph{simplification} using a λ-calculus based formalism.

The most prominent system that supports implementation of compilers in formal (rewriting and
attribute grammar) form is ASF+SDF~\cite{Brand+:toplas2002}, which is based on first order
rewriting. While modules have been added for symbol table management, these lack the full
integration and easy way to handle scoped intermediate languages. The successor,
Rascal~\cite{Bos+:eptcs2011} adds a module for HOAS, but Rascal specifications operate in a world of
side effects, which we find hard to reconcile with higher-order term structures (with scopes).

The notion of ``higher-order'' used by \hax is similar to but not quite the same as in higher-order
attribute grammars (HAG)~\cite{VogtSwierstraKuiper:pldi1989}. Like HAGs, \hax specifications permit
constructing and passing of abstract syntax fragments in attributes but the ``higher order'' aspect
of \hax also covers the rewriting side, where we can build parameterized abstractions over any part
of a specification, including with attributes. Indeed, one can use substitution inside attributes,
and have absence of attributes and substitution block rewriting.

\paragraph*{Future work.} \TBD{Speculate!}


\paragraph*{Acknowledgements.} \TBD{Thank everyone.}

EU-funded Marie Skłodowska-Curie ``HORIP'' action collaboration with Cynthia Kop.


%------------------------------------------------------------------------

\bibliography{crs}


\TBD{End of sane part.}
\hrule
\vspace*{1pc}

%------------------------------------------------------------------------
\appendix

\section{\bhax in \HAX}

We encode \hax in \HAX…\KR{It may even work, eventually.}
%
\begin{hacs}[numbers=right,texcl]
// HACS module for the \hax calculus.
module org.crsx.hacs.Plank {

// \textbf{Lexical.}

// Spaces and comments.
space " " | [\t\n] | "//" ([^/\n] | "/" [^/\n])*;

// Identifiers (TODO: proper Unicode).
token CON   | [A-Z] ⟨IDCHAR*⟩;   // $c$
token VAR   | [a-z] ⟨IDCHAR*⟩;    // $v$
token META  | "#" ⟨IDCHAR*⟩;     // $m$
token fragment IDCHAR | [A-Za-z0-9_];

// \textbf{Grammar.} Only captures syntax, not binding.

sort H // \hax script.
| ⟦ ⟨D*⟩ ⟧
;

sort D // Declaration.
| ⟦ ⟨S⟩ data ⟨CON⟩ ( ⟨F*,⟩ ) ; ⟧
| ⟦ ⟨S⟩ scheme ⟨CON⟩ ( ⟨F*,⟩ ) ; ⟧
| ⟦ ⟨S⟩ variable ; ⟧
| ⟦ ⟨S⟩ rule ⟨M⟩ → ⟨M⟩ ; ⟧
;

sort F // Form.
| ⟦ [ ⟨S*,⟩ ] ⟨S⟩ ⟧  | sugar ⟦ ⟨S#⟩ ⟧ → ⟦ []⟨S#⟩ ⟧
| ⟦ { ⟨S⟩ : ⟨S⟩ } ⟧
;


sort S // Sort.
| ⟦ ⟨CON⟩ ⟨ ⟨S*,⟩ ⟩ ⟧  | sugar ⟦ ⟨CON#⟩ ⟧ → ⟦ ⟨CON#⟩ ⟨ ⟩ ⟧
| ⟦ ⟨VAR⟩ ⟧
;

sort M // Meta-term.
| ⟦ ⟨CON⟩ ( ⟨P*,⟩ ) ⟧  | sugar ⟦ ⟨CON#⟩ ⟧ → ⟦ ⟨CON#⟩() ⟧
| ⟦ ⟨VAR⟩ ⟧
| ⟦ ⟨META⟩ ( ⟨M*,⟩ ) ⟧  | sugar ⟦ ⟨META#⟩ ⟧ → ⟦ ⟨META#⟩() ⟧
;

sort P // Piece.
| ⟦ { ⟨A*,⟩ } ⟧
| ⟦ [ ⟨VAR*,⟩ ] ⟨M⟩ ⟧   | sugar ⟦ ⟨M#⟩ ⟧ → ⟦ []⟨M#⟩ ⟧
;

sort A // Association.
| ⟦ ⟨M⟩ : ⟨M⟩ ⟧
| ⟦ ¬ ⟨M⟩ ⟧
| ⟦ ⟨M⟩ ⟧  // really only $m(v^*)$ but that's ambiguous
;

}
\end{hacs}


\section{Bra-Ket}

\KR{Just for fun: Here is ``bra-ket'' notation (from physics), also kind of cool. I'd love this, and
  it would be different and make us associate even more to the \hax symbol. The explanation then
  associates a \emph{bra} with a binder state and a \emph{ket} with a substitution of it.}
\CK{That's\dots\ very weird to me. But then, I never did physics after high school! But in general,
  I think this notation is unlikely to appeal to rewriters.}
\begin{align}
  \tag{\hax{}Script}
  H &::= D^* 
  \\
  \tag{Declaration}
  D &::= S~\kw{data}~d\,\kw(\,\ov{F}\,\kw)\,\kw;
  \bigm| S~\kw{scheme}~f\,\kw(\,\ov{F}\,\kw)\,\kw;
  \bigm| S~\kw{variable}\,\kw;
  \bigm| S~\kw{rule}~M~\kw{$→$}~M\,\kw;
  \\
  \tag{Form}
  F &::= \kwm{⟨}\,\ov{S}\,\kwm|\,S
  \bigm| \kwm\{\, S:S \,\kwm\}
  \\
  \tag{Sort}
  S &::= s\,\kw[\,\ov{S}\,\kw]
  \bigm| α
  \\[\jot]
  \tag{Term}
  M &::= c\,\kw(\,\ov{P}\,\kw)
  \bigm| v
  \bigm| m\,\kwm|\,\ov{M}\,\kwm{⟩}
  \\
  \tag{Piece}
  P &::= \kwm{⟨}\,\ov{v}\,\kwm|\,M
  \bigm| \kwm\{\, \ov{A} \,\kwm\}
  \\
  \tag{Association}
  A &::= M\,\kw:\,M
  \bigm| \kw{$¬$}\,M
  \bigm| \kw:\,m
\end{align}
\KR{We now distinguish \emph{five} different ways to brace elements; all empty can be omitted
  except associations.
  For data and scheme \emph{subterms}, we use $\kw{( )}$.
  For \emph{binders} we use $\kwm{⟨~|}$.
  For \emph{meta-application arguments} we use $\kwm{|~⟩}$.
  For \emph{associations} we use $\kwm{\{\,\}}$.
  For \emph{sort parameters} we use $\kwm{[\,]}$.}
\begin{hacs}
  List[α] scheme Map(⟨β|α, List[β]);
  List[α] rule Map(⟨x|#|x⟩, Nil) →  Nil;
  List[Int] rule Map(⟨x|#|x⟩, Cons(#1, #2)) →  Cons(#|#1⟩, Map(⟨x|#|x⟩, #2));
  Int scheme Pick(List[Int], ⟨Int,Int|Bool);
  Int rule Pick(#, ⟨x,y|#p|x,y⟩) → If(#p|#,#⟩, Pick(#, ⟨x,y|#p|x,y⟩), #);
\end{hacs}

\section{Sugar}

\begin{notation}
  %% 
  \HAX permits some additional syntactic sugar:
  %% 
  \begin{itemize}

  \item Empty parenthesis and brackets can be omitted.

  \item The \kw{data} and \kw{rule} keywords can be omitted.

  \item \TBD{Update to simplified syntax.} Sort cases can be written with \kw{\texttt{|}} and without
    \kw{\texttt{\{\}}}…

  \item "attribute" declarations can be combined: $"attribute"~a_1~\set{AF}_1,…, a_n~\set{AF}_n ;$
    is an abbreviation of $"attribute"~a_1~\set{AF}_1;…; "attribute"~a_n~\set{AF}_n;$.

  \item An additional SortCase contruct is allowed:
    \begin{displaymath}
      \kw{template}~P~\kw{$→$}~M\,\kw;  \quad⇒\quad
      \kw{scheme}~P'\,\kw; ~ \kw{\texttt{|}} ~ \kw{data} ~ T'\,\kw; ~ \kw{rule} ~ P~\kw{$→$}~M\,\kw;
    \end{displaymath}
    where $P'$ and $T'$ are variants of $P$ and $P$ that have been cleared of "#"s.

  \item Finally, we rewrite special \emph{synthesis rules}:
    \begin{displaymath}
      c(\,\ov{\set{PB}}\,)~→~\ov{↑a~\set{V}}\,\kw;
      \quad⇒\quad
      \kw{rule}~c(\,\ov{\set{PB}}\,)~→~c(\,\ov{\set{PB}'}\,)~\ov{↑a~\set{V}}\,\kw;
    \end{displaymath}
    where $\set{PB}_i'$ is $\set{PB}_i$ with negative attribute patterns $\{¬{…}\}$ removed.

  \item We rewrite special \emph{inheritance rules}:
    \begin{displaymath}
      c(\,\ov{\set{PB}}\,)~→~\ov{↓v~\set{V}}\,\kw;
      \quad⇒\quad
      \kw{rule}~c(\,\ov{\set{PB'}}\,)~\ov{↓v~\set{V}}~→~c(\,\ov{\set{PB}'}\,)\,\kw;
    \end{displaymath}
    where 

  \item As defined below, every term $f(…)\ov{A}$ for a symbol $f$ defined with
    \begin{displaymath}
      \kw{\texttt{|} scheme}~f\,\kw(…\kw)~\ov{\set{AI}}
    \end{displaymath}
    must include an $A_i$ instance for every attribute defined by some $\set{AI}_i$.  The system
    automatically includes missing inherited attributes as follows:
    \begin{itemize}
    \item In patterns, a missing attribute is inserted as "↓a(#a)" or "↓a{#a}" as appropriate.
    \item Missing attributes that were defined in the pattern are inserted the same.
    \item Remaining missing attributes must be of a map sort and are inserted as~"↓a{}".
    \end{itemize}

  \item We allow two more forms of \set{PA}:
    \begin{displaymath}
      \set{PA} ::= {…} \bigm| \kw{$↑$}\,m \bigm| \kw{$↓$}\,m
    \end{displaymath}
    They expand to all relevant synthesized and inherited attributes, respectively.

  \end{itemize}
\end{notation}

\begin{example}
  With syntactic sugar, we can simplify the Peano example to
  %%
  \begin{hacs}[numbers=right]
    sort N | Z | S(N) | scheme Plus(N, N) ;
    Plus(Z, S(#2)) → #2 ; 
    Plus(S(#1), #2) → S(Plus(#1, #2)) ;
  \end{hacs}
\end{example}

\begin{example}[untyped λ calculus]
  The untyped λ calculus is specified as follows in \hax with syntactic sugar:
  %%
  \begin{hacs}
    sort L | variable | Lm([x]Lam[x as L]) | scheme Ap(L, L) | x ;
    rule Ap(Lm([x]#body(x)), #arg) →  #body(#arg) ;
  \end{hacs}
  %%
  The example shows how binding is declared and used for substitution in the style of CRS
  systems~\cite{Klop+:tcs1993}:\footnote{The notation differs from the original CRS notation in that
    we use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$, and we
    use square brackets for substitution variables instead of round.}
  %%
  (Note that the same example in the (non-raw) full \HAX notation can include a parser for the
  native custom λ calculus syntax:
  %%
  \begin{hacs}
    token ID | [a-z] [a-z0-9_]* ;
    sort V | symbol ⟦⟨ID⟩⟧ ;
    sort L | ⟦λ⟨V binds x⟩.⟨L[x as L]⟩⟧ | scheme ⟦⟨L@1⟩⟨L@2⟩⟧@1
           | ⟦⟨V⟩⟧@2 | sugar ⟦(⟨L#⟩)⟧@2 →  #;
    ⟦ (λx.⟨L#body(x)⟩) ⟨L#arg⟩ ⟧ →  #body(#arg) ;
  \end{hacs}
  %%
  including precedence markers, syntactic sugar, \etc; for details see the full \HAX
  manual. Essentially the syntax-rich example translates to a parser and the former.)
\end{example}

\section{Inference Systems}
\label{sec:infer}

A common notation for specifying program analysis and …

A set of of inference rules is ...

\begin{definition}
  %%
  A \HAX \emph{ground sequential inference rule} has the form
  %%
  \begin{equation}
    \dfrac{ M_1 ⇒ P_1 \quad\cdots\quad M_n ⇒ P_n }{ P_0 ⇒ M_{n+1} }
    \label{eq:infer}
  \end{equation}
  %%
  where $n≥0$ and
  %%
  \begin{enumerate}
  \item $P_0$ (the \emph{initial} pattern) can be any \HAX pattern.
  \item $M_i$ (the \emph{tests}, $1≤i≤n$) are \HAX terms, and are allowed occurrences of meta-variables from $P_0…P_{i-1}$.
  \item $P_i$ (the \emph{constraints}, $i>0$) must be \HAX subpatterns.
  \item $M_{n+1}$ (the \emph{conclusion}) is allowed occurrences of all meta-variables.
  \end{enumerate}
  %%
  An inference rule with $n=0$ is called an \emph{axiom}, with $n>0$ a \emph{proper inference}.
  %%
  The $M_i⇒P_i$ over the line are called \emph{premise judgments}. The $P_0⇒M_{n+1}$ under the line
  is called the \emph{conclusion judgment}.
  %%
  Below we will vary the indexing scheme to capture various enumerations of sets of inference rules.
\end{definition}

\begin{definition}[pattern family]\label{def:patfam}
  Consider a set of ground sequential inference rules.  Such a set can obviously be indexed by the
  distinct initial patterns into families of rules
  \begin{displaymath}
    \dfrac{ M_{ij1} ⇒ P_{ij1} \cdots M_{ijn_{ij}} ⇒ P_{ijn_{ij}} }{ P_i ⇒ M_{ij} } ~(L_{ij})
  \end{displaymath}
  where all the $P_i$ used to index the family are pairwise distinct.  The groups obtained in this
  way are a \emph{pattern family}.
\end{definition}

\begin{definition}[leftmost matching]
  Consider a pattern family as in Definition~\ref{def:patfam}.  The family is said to be
  \emph{leftmost matching} if the group of rules for each $P_i$ satisfies one of the following
  conditions:
  \begin{itemize}
  \item either the family contains a single axiom, \ie, $1≤j≤1$ with $n_{ij}=0$,
  \item or the family contains only proper inferences, \ie, $1≤j≤m_i$ with $n_{ij}>0$.
  \end{itemize}
\end{definition}

%% Sub-index each non-axiom $P_i$-group by leftmost premise construction into sub-families of
%%    the form
%%    \begin{displaymath}
%%      \dfrac{ M_{ij} ⇒ P_{ijk1} \quad M_{ijk2} ⇒ P_{ijk2} \quad\cdots\quad M_{ijkn_{ijk}} ⇒ P_{ijkn_{ijk}} }{ P_i ⇒ T_{ijk} }
%%    \end{displaymath}
%%    where all the $T_{ij}$ used to index the sub-family within a $P_i$-group are pairwise disjoint.

\begin{definition}[left-operations]
  Given a leftmost-matching pattern family. Each $P$-indexed group of proper inference rules will
  have the following form:
  \begin{displaymath}
    \dfrac{ T_{j1} ⇒ P_{j1} \quad T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ P ⇒ T_j } ~ (L_j)
  \end{displaymath}
  with one $j$ per rule in the family, which is by definition non-empty ($1≤j≤n$) and contains only
  proper inferences ($n_j≥1$).
  %%
  \begin{enumerate}

  \item Given a label $L$, the \emph{left-flattening} rewrite rules of the group are
    %% 
    \begin{align*}
      L(P) &→ L'(T_{11}, …,T_{n1}, P) \\[\jot]
      L'(P_{11}, m_2, …, m_n, P) &→ L_1(P, P_{11}) \\[-\jot]
      &~\vdots\\
      L'(m_1, …, m_{n-1}, P_{n1}, P) &→ L_n(P, P_{n1})
    \end{align*}
    %% 
    with $L'$ a fresh symbol associated with the group and the $m_j$ fresh meta-variables.

  \item The \emph{left-eliminated} rules for the group are the rules
    \begin{displaymath}
      \dfrac{ T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ L_j(P, P_{j1}) ⇒ T_j } ~ (L'_j)
    \end{displaymath}
    with the $L'_j$ fresh labels derived from the $L_j$ labels.

  \end{enumerate}
\end{definition}

\begin{definition}[left-unfolded]
  Given a leftmost-matching pattern family and consider the proper inference rule group indexed by
  $P$. The following system is the \emph{left-unfolded} inference system for the $P$-indexed group:
  \begin{enumerate}

  \item The left-flattening rewrite rules of the group for a fresh~$L$.

  \item The new inference rule (which refers to the rewrite rules)
    \begin{displaymath}
      \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m } ~ (L)
    \end{displaymath}

  \item The left-eliminated inference rules (which may be axioms or proper inferences).

  \end{enumerate}
\end{definition}

\begin{proposition}
  Given a set of ground sequential inference rules, which is a leftmost-matching pattern
  family. Pick one group of proper inference rules, indexed by the initial pattern $P$. The original
  system and the system where the group has been replaced with the left-unfolded group have the same
  normal forms.
\end{proposition}
\begin{proof}
  Easy: full proof tree before corresponds to proof tree after with simple conversion of the
  eliminated eliminated premise to an application of the new rule and a single use of the rewrite
  rule.
\end{proof}

Note that we can only prove that full ``big-step'' evaluations are equivalent: the new rules may
``get stuck'' in interesting ways (\TBD{example with overlapping patterns}).

\begin{lemma}
  Start with any leftmost matching ground sequential inference rule system and apply left-unfolding
  repeatedly except on axioms and the introduced inference rules
  \begin{displaymath}
    \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m }
  \end{displaymath}
  The resulting system has the same normal forms as the original system.
\end{lemma}

To finish the transform from inference rules to \HAX rules we need two additional notions.

\begin{definition}
  An inference system is \emph{rooted} if it has one rule that occurs as the root rule of every
  proof tree.
\end{definition}

\begin{definition}
  A leftmost-matching ground sequential inference rule system is \emph{left deterministic} if the
  left-flattening 
\end{definition}

\begin{theorem}
  A rooted and leftmost matching ground sequential inference system can be implemented by a 
\end{theorem}

\section{Attributes}

\begin{definition}[synthesized attributes]\label{def:synth}%
  %%
  A \emph{singleton synthesis rule} has the shape
  %%
  \begin{displaymath}
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{{↑}a_i\{{\cdots}\}}$\\
          $m_i[{\cdots}]\,{{↑}a_i\{{\cdots}\}}$
        }}\cdots\biggr)
    ~{{↑}a\{{\cdots}\}}
  \end{displaymath}
  %%
  (with the embedded subterms denoting all such subterms; the ``singleton'' restriction comes from
  the single synthesized attribute on all subterms).

  The \emph{synthesis simplification system} for the synthesis rule is
  %%
  \begin{align*}
    \op{Needs}_a\Biggl(
    c\biggl(\cdots \vcenter{\txt{
        $c_i({\cdots})$\\
        $m_i[{\cdots}]$
      }}\cdots\biggr)
    \Biggr)
    &→
    \op{Collect}\Biggl(
    c\biggl(\cdots \vcenter{\txt{
        $\op{Needs}_{{a_i}}(c_i({\cdots}))$\\
        $\op{Needs}_{{a_i}}(m_i[{\cdots}])$
      }}\cdots\biggr)    
    \Biggr)
    \\[1em]
    \op{Collect}\Biggl(
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{↑}a_i\{{\cdots}\}$\\
          $m_i[{\cdots}]\,{↑}a_i\{{\cdots}\}$
      }}\cdots\biggr)
    \Biggr)
    &→
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{↑}a_i\{{\cdots}\}$\\
          $m_i[{\cdots}]\,{↑}a_i\{{\cdots}\}$
        }}\cdots\biggr)
    ~{↑}a\{{\cdots}\}
  \end{align*}
  %%
\end{definition}

\begin{example}
  \TBD{Example synthesis simplification.}
\end{example}

\TBD{Discuss multiple dependent and independent synthesized attributes, and proof sketch that the
  simplification is correct; also the erasure of not-patterns, and check details from .}

\begin{definition}[inherited attributes]\label{def:synth}%
  %%
  \begin{align*}
    F\bigl(\cdots \vcenter{\txt{
          $A({·})\,{↑}a({·})$\\
          $X[{·}]\,{↑}x({·})$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    \cdots\vcenter{\txt{
        $B({·})\,{↑}b({·})$\\
        $Y[{·}]\,{↑}y({·})$}}
    \cdots\vcenter{\txt{
        $G({·})\,{↓}g({·})$\\
        $Z[{·}]\,{↓}z({·})$}}
    \cdots
    \\
    \intertext{becomes}
    %%
    F\bigl(\cdots \vcenter{\txt{
          $A({·})$\\
          $X[{·}]$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    F'\bigl(\cdots \vcenter{\txt{
          $\op{Needs}_a(A({·}))$)\\
          $\op{Needs}_x(X[{·}])$
        }}\cdots\bigr)
    {↓}c({·})
    \\[1em]
    F'\bigl(\cdots \vcenter{\txt{
          $A({·})\,{↑}a({·})$\\
          $X[{·}]\,{↑}x({·})$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    \cdots\vcenter{\txt{
        $B({·})\,{↑}b({·})$\\
        $Y[{·}]\,{↑}y({·})$}}
    \cdots\vcenter{\txt{
        $G({·})\,{↓}g({·})$\\
        $Z[{·}]\,{↓}z({·})$}}
    \cdots
  \end{align*}
  %% 
\end{definition}

\end{document}


%------------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% TeX-master: t
% TeX-auto-untabify: nil
% End:
