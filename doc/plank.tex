\documentclass[letterpaper,11pt]{article}

%% Style.
%\usepackage{charter}
\renewcommand{\rmdefault}{pplx}
\usepackage{eulervm}
\bibliographystyle{plain}
\usepackage[margin=1in]{geometry}

%% Format.
\input{setup}
\usepackage{cite}
\usepackage{stmaryrd}

%% Topmatter.
\title{ \hax: A Plank for Higher-order Attribute Contraction Schemes }
\author{%
  Cynthia Kop \\
  University of Copenhagen
  \and
  Kristoffer H. Rose \\
  Two Sigma Investments, LLC
  \and
  Maria Schett \\
  University of Innsbruck
  \and
  Lionel Villard \\
  IBM Research
}

%% Discussion
\newcommand{\CK}[1]{\textcolor{blue}{CK: #1}}
\newcommand{\KR}[1]{\textcolor{red}{KR: #1}}
\newcommand{\LV}[1]{\textcolor{green}{LV: #1}}
\newcommand{\MS}[1]{\textcolor{violet}{MS: #1}}

\begin{document}
\maketitle

\begin{abstract}\noindent
  %%
  We present \hax, a core (or ``plank'') calculus that can serve as the foundation for the \CRSX
  (Combinatory Reductions Systems with eXtensions) and \HAX (Higher-order Attribute Contraction
  Schemes) compiler specification languages.
  %%
  Formally, \hax is a general higher order rewriting formalism extended with first class
  \emph{associations}, and equipped with a parametric polymorphic sort system.
  %%
  In this paper we give the formal definition of the \hax calculus and its sort system, and we show
  how the central constructs of the much richer \HAX and \CRSX formalisms can be represented in
  \hax. We also outline how \hax can be implemented, and summarize central properties of the system.

  \CK{Cynthia!} \KR{Kris!} \LV{Lionel!} \MS{Maria!}
\end{abstract}

\compacttableofcontents

%------------------------------------------------------------------------

\section{Introduction}\label{sec:intro}

Several systems that manipulate programs, so-called \emph{meta-programming} systems, have emerged
over the years, ranging from generic specification languages, where the goal is not to define how
but only declare the semantics of the program manipulation, all the way to tools that support
specific aspects of program execution or compiler generation.

One direction has been to use a combination of \emph{higher order
  rewriting}~\cite{Jouannaud:klop2005} combined with \emph{higher order abstract syntax} (HOAS)
\cite{PfenningElliot:pldi1988}. This approach is used by \CRSX (Combinatory Reduction Systems with
eXtensions)~\cite{Rose:1996}, developed for writing industrial compilers at IBM
Research~\cite{Rose:hor2010,Rose:rta2011,dp60:ibm2013}, and the derived system \HAX (Higher-order
Attribute Contration Schemes)~\cite{Rose:ts2015}, developed to teach compiler construction at
NYU~\cite{RoseRose:cims2015}.

However, the direct implementation of the full \CRSX language~\cite{crsx} turned out to be quite
complex, and over time we have developed notions of what the ``core'' elements of the language
are. At the same time, \HAX has highlighted what additional programming paradigms one should add to
get a more useful programming language for writing compilers.

\TBD{Example of complex feature that can be simplified.}

The \hax calculus, presented here, represents the synthesis or what we have found to be the
essential features of a system for implementing most features of compilers.

\TBD{Plan}%
and finally Section~\ref{sec:conc} concludes and compares to related work.

%------------------------------------------------------------------------

\section{Overview}
\label{sec:overview}

In this section we outline the \hax calculus, and give several examples.

\begin{figure}[h!t]
  \begin{align}
    \tag{\hax{}Script}
    H &::= D^* 
    \\
    \tag{Declaration}
    D &::= S~\kw{data}~d\,\kw(\,F^{*\kw,}\,\kw)\,\kw;
    \bigm| S~\kw{scheme}~f\,\kw(\,F^{*\kw,}\,\kw)\,\kw;
    \bigm| S~\kw{variable}\,\kw;
    \bigm| S~\kw{rule}~M~\kw{$→$}~M\,\kw;
    \\
    \tag{Form}
    F &::= \kw[\,S^{*\kw,}\,\kw]\,S
    \bigm| \kwm\{\, S:S \,\kwm\}
    \\
    \tag{Sort}
    S &::= s\,\kwm{⟨}\,S^{*\kw,}\,\kwm{⟩}
    \bigm| α
    \\[\jot]
    \tag{Meta-Term}
    M &::= c\,\kw(\,P^{*\kw,}\,\kw)
    \bigm| v
    \bigm| m\,\kw(\,M^{*\kw,}\,\kw)
    \\
    \tag{Piece}
    P &::= \kw[\,v^{*\kw,}\,\kw]\,M
    \bigm| \kwm\{\, A^{*\kw,} \,\kwm\}
    \\
    \tag{Association}
    A &::= M\,\kw:\,M
    \bigm| \kw{$¬$}\,M
    \bigm| \kw:\,m
  \end{align}
  \vspace*{-2em}
  \caption{\hax syntax.}
  \label{fig:syntax}
\end{figure}

\begin{definition}[\hax syntax]\label{def:syntax}
  %%
  The \hax syntax is shown in Figure~\ref{fig:syntax}. The top level of a \hax script is $H$ and the
  grammar assumes that we have three categories of identifier tokens defined:
  %%
  \begin{itemize}

  \item $c,s,d,f ∈ \mathcal{C}$ stand for \emph{constructor} tokens, which are capitalized words
    like "Integer" or "A" or "CamelCaseWord". They are used for sort, function symbol, and data
    symbol names. By convention, we use $s$/$d$/$f$ for sort/data/function names, respectively, and
    $c$ when either a data or function constructor makes sense.  

  \item $v,α ∈ \mathcal{V}$ stand for \emph{variable} tokens, which are lower case words like "x" or
    "foo" or even "lowWord", used for plain variables and sort variables (respectively).

  \item $m ∈ \mathcal{M}$ stands for \emph{meta-variable} tokens, which are tokens that start with
    "#" like "#arg" or "#BigFoot" or even just "#1" or merely~"#".

  \end{itemize}
  %%
  The ``$A^{*\kw,}$'' 
  %%
  %%\MS{We mix a bit notation here, sometimes ``$A^{*\kw,}$'', but also e.g., $c(P_1,…,P_n)$. I
  %%  personally prefer the latter, but I would stick to one. Or am I missing something?}
  %%\KR{A: The former is \emph{concrete} syntax (``the commas must be there''), the latter abstract.} 
  %%\MS{Hmmm... Could you give me an intution, when to use which?}
  %%\KR{A: Use the more convenient one on each occasion. This is meant to be an example of
  %%  ``non-confusing sloppiness.''}
  %%
  notation means zero or more $A$s separated by commas.
  %%
\end{definition}

We shall use the following terminology:
%% 
\begin{itemize}

\item A meta-term of the form $c(P_1,…,P_n)$, for $n≥0$, is called a \emph{construction}; if furthermore
  the top symbol $c$ is declared with a "scheme c {…}" declaration then it is called a
  \emph{function construction}, and if it is declared with "data d {…}" then it is called a
  \emph{data construction}. If $n=0$, i.e., the function or data symbol does not take any arguments,
  we usually drop the $()$. That is, we write $0$ instead of $0()$.
    
%%    \MS{Here comes a really general question: How do data and function constructors/constructions
%%      relate to constructor and defined symbols in term rewriting (To clarify: A symbol is
%%      \emph{defined} wrt to a set of rules, if it occurs at the root of a left-hand side of a
%%      rule. The other symbols are constructors.) I have a feeling, that this is actually similar?
%%      If so, I may argue, that the distinction is easily computable and is maybe not core?  } \KR{A:
%%      Yes, one can argue this. Not sure what the right answer is.}  \MS{I'd go for simpler. Maybe we
%%      can discuss this on the call?}  \MS{Conclusion: For implementation it is easier to declare
%%      it. It is computable though.} \KR{You can see it in the type rules, now.}

\item Argument ``pieces'' $P$ of constructions take one of two forms: \emph{scopes} $[v_1,…,v_n]M$,
  $n≥0$, which introduce new local variables $v_1,…,v_n$ along with a meta-term $M$ wherein they can
  occur, and \emph{associations} $\{A_1,…,A_n\}$, $n≥0$, where each $A$ is either an \emph{entry}
  $M:M$, an \emph{exclusion} $¬M$, or a \emph{catcher} ${:}m$.

  For scopes, if $n=0$, \ie, there are no new variables introduced by the scope, then $[]$ can be
  omitted: we write $S(0)$ instead of $S([]0)$.

  \KR{Note: any suggestions for something other than \{:\#1\} for catchers are welcome!}

  \CK{Well, I still like the idea of \{ \#1 | conditions \} or \{ \#1 + key/values \}, but this
    would of course give more expansive syntax, as you can't use the same notation on both sides
    of the rule.  Also, I think you might actually need \{ \#1(x1,...,xn) | conditions \} and
    \{ \#1(s1,...,sn) + key/values \}, otherwise you cannot capture a meta-variable set below an
    abstraction (do you want to do that? It probably \emph{should} be possible\dots)}

  \KR{Your point that catchers need to be parametrized is true: we could use the form
    ${:}m(\ov{x})$.}

  \LV{I'm not sure that the issue is. I would use \{\#\} as catcher, and \{\#:\} to match for key \#. \{:\#\} could match against the value(s). Obviously in both cases \# must appear somewhere else.} 

  \CK{For an entirely different suggestion, you could use different non-metavariable notation
    for the catcher metavariables, e.g.~$\sharp$1 or \&1.}

\item A meta-term of the form $m(M_1,…,M_n)$, $n≥0$, is a \emph{meta-application}.
  A meta-term that does not contain any meta-applications is called (simply) a \emph{term}.

  \MS{E.g., in KR thesis, TeReSe, a distinction between meta term and term (i.e., a meta term
    without meta variables) is made. Do we also want to do this?}

  \CK{I'd say it's certainly desirable to do so, as we don't really want to have to deal with
    rewriting meta-terms, just terms.  Moreover, the difference is larger here than in TeReSe, as
    I'd also expect that terms have no exclusions.
    \\
  \textbf{\emph{Suggestion:}}
  In the syntax, replace ``Term'' by ``Meta-term'' (and perhaps the T by an M).  Then add
  something like: a \emph{term} is a meta-term without meta-variable tokens or exclusions; that
  is, a meta-term generated by the restricted grammar:
  \begin{align}
    \tag{Term}
    T &::= c\,\kw(\,{P'}^{*\kw,}\,\kw)
    \bigm| v
    \\
    \tag{Piece}
    P' &::= \kw[\,v^{*\kw,}\,\kw]\,T
    \bigm| \kwm\{\, {A'}^{*\kw,} \,\kwm\}
    \\
    \tag{Association}
    A' &::= T\,\kw:\,T
  \end{align}
}
\KR{Done but no grammar needed---just the wording above.}

\item A meta-term of the form $v$ is a \emph{variable occurrence}; if the variable $v$ occurs contained
  in a scope $[…v…]M$ then the variable occurrence is \emph{bound}.

\MS{$S~\kw{variable}\,\kw;$ \ldots What does this keyword indicate now?}

\CK{By my understanding, there are several different properties to $\kw{variable}$:
  \begin{itemize}
  \item variables of that sort may occur unbound in the meta-terms whose reduction
    you consider (others will only occur bound);
  \item you can \emph{match} on an explicit variable (either bound or free) of one of
    these sorts;
  \item variables of these sorts may occur free in the right-hand side of a
    rule;
  \end{itemize}
  It may also be possible / needed to restrict instantiation, i.e.~you're not
  allowed to ever substitute a variable of those sorts by a different variable. \\
  (Kris may be able to indicate the exact truth factor of each of these
  properties and whether I missed a bit.)
}
\KR{You can only substitute ``variables for variables'' when they can be syntactic, I think.}

\end{itemize}

\MS{About $F ::= \kw[\,S_1^{*\kw,}\,\kw]\,S_2$. Can $S_1$ actually be something different than a sort variable?}

\CK{They really shouldn't be.}

\KR{Why not? Is there a problem with the new Example~\ref{ex:pick}?}

\CK{My mistake, they can be of course. I was thinking of $S\langle S\rangle$, and even then, we
only really want to limit the inner $S$ to sort variables when defining data (e.g.~it's allowed
to have a scheme with sort $\mathtt{list}\langle\mathtt{nat}\rangle$, but not to define a data
constructor with this as output type).}\KR{A: Well stated. We should capture this in the text.}

\CK{(By the way, is there any reason for the commas before all the closing brackets?)}
\KR{A: This is concrete syntax notation; can be omitted.}


We distinguish four different ways to brace elements (cf.\ Figure~\ref{fig:syntax}). For data and
scheme \emph{subterms}, and for \emph{meta-application arguments} we use $\kw{( )}$.
For \emph{binders} we use $\kw{[ ]}$.
For \emph{associations} we use $\kwm{\{\,\}}$.
For \emph{sort parameters} we use $\kwm{⟨\,⟩}$.
\KR{Changed the brackets! Like it?}
\CK{Better! :)}

\CK{I actually think the greater objection is with bracing sort arguments by
  square brackets: sort constructors are far closer to function symbols than to
  binders, and this isn't just about variables: $\kw{list[list[nat]]}$ is a
  sort.  So why the square brackets?} \KR{A: Is it better as suggested (easy to change, still)?}
  \CK{Yes, I think so.  There are many other ways I also wouldn't mind, but this
  works and is relatively unconfusing.}

\CK{As for meta-variables: while I quite like giving them separate brackets
  from function applications because the arguments to meta-variables function
  somewhat like a substitution, it gets kind of icky when you use the same
  brackets for abstraction: $\kw{[x]Z[a(x)]}$ uses square brackets in two
  completely different ways.  So I guess I would support changing this (not
  strongly, but I'm not opposed to it despite my own preference for square
  meta-variable brackets and corresponding use in my thesis), or alternatively,
  changing abstractions to have the (more common!) form $\vec{x}.s$ or
  $\lambda \vec{x}.s$ rather than $[\vec{x}]s$.} \KR{See also bra-ket proposal below!}
  \CK{Ew. :P}

In Figure~\ref{fig:syntax}, the $S$ in $S~\kw{rule}~M~\kw{$→$}~M\,\kw;$ is not superflous. Consider
the following two rules:
\begin{hacs}[numbers=right,texcl]
  List⟨α⟩ rule Map([x]#(x), Nil) →  Nil;
  List⟨Int⟩ rule Map([x]#(x), Cons(#1, #2)) →  Cons(#(#1), Map([x]#(x), #2));
\end{hacs}
\MS{I am not sure, I completely understand yet.}
\CK{This states why it is important to give the sort of a rule: because
sometimes, sorts may be ambiguous.  The first rule is defined for arbitrary
lists, the second only for lists of integers, and will be met with a
compiler error if you try to use it on a list of strings.  I'm not convinced
it's a very good example, though: it doesn't make it clear why you would
\emph{want} the rule to be limited to integer lists!}

It is even possible to have function constructors that live in \emph{all} sorts:
\begin{hacs}[numbers=right,texcl]
  α scheme If(Bool, α, α);
  α rule If(True, #1, #2) → #1;
  α rule If(False, #1, #2) → #2;
\end{hacs}

\begin{example}
  Example terms without Associations are: 
  %% 
  \begin{hacs}[numbers=right, texcl]
      Zero, Plus(#X, #Y), S(Zero), x, #X, S([x,y]#X[y,x,z]), #X[x], #F[Zero], #F[#X]
      [x,y]#F[y,x]
    \end{hacs}
    \MS{So currently, a meta-application is (strictly speaking) not called a term (except for
      $\#X$). Do we want this?}

    \CK{A meta-application $\#X[\kw{0}]$ or $\#X[z]$ is a term.  However,
    \emph{scopes} are not considered terms (I would propose not calling it
    a ``pattern meta-application'' as that is misleading, though).}
    
    Example terms with Associations of the form $M \kw{:} M$, where the key is a variable or a
    constant, are
    %% 
    \begin{hacs}[numbers=right,texcl]
      Plus(x, { x : Zero }), Plus(#X, { x : Zero }), Plus(Zero, {Zero : S(Zero)}) 
    \end{hacs}
    
    Example terms, where the keys are meta-variables. \MS{I am sorry, I forgot, is this allowed?}
    \CK{Woah, the second one definitely isn't, because the key is not a term;
    even if it was, this would not be sortable with our second-order system.
    I don't think there's any problem with the first.}
    \begin{hacs}[numbers=right,texcl]
     S({ #X : #Y }), #Z[S({ #X : #Y })]                    
     S({[x]#X[x] : Zero }), 
   \end{hacs}

   \MS{The semantic of the following two is unclear, or?}
   \CK{For the former, yes -- an association should be a mapping.  But for the
   latter, couldn't it be a term carrying \emph{two} association mappings?  I
   don't know whether we ever want this, but it doesn't necessarily give
   ambiguity, I think.}
%   \begin{hacs}[numbers=right,texcl]  
%     S( {x : y, x : Zero} )
%     Plus( {x : y}, {x : Zero} )
%   \end{hacs}
   Example terms with Associations of the form $¬M$ are:
   \begin{hacs}[numbers=right,texcl]
     Plus(x, { ¬x }), Plus(x, { ¬Zero }), Plus(#X,{¬Zero}), S({ ¬#X }), 
     #Z[S({ ¬#Z[x] })], S({ ¬S([x]#X[x]) }), Plus(Zero,{¬S(Zero)}), Plus({ ¬x}, { ¬z})
   \end{hacs}
   
   Finally, Example terms with Associations of the form $: m$ are:
   \begin{hacs}[numbers=right,texcl]
     Plus(x, { : #X }), Plus( { : #X}, { : #X}), Plus( { : #X}, { : #Y})
     Plus( #X, { : #X })  // note, here \#X are distinct, the former is acutally []\#X
   \end{hacs}
   
  \MS{The semantic of the following is unclear, or?}
  \begin{hacs}[numbers=right,texcl]
    Plus( { : #X, : #Y})
  \end{hacs}
  \CK{Seems to be used despite the unclearness, though!}
\end{example}  
\MS{I reduced the space they take up and added a couple of questions in between. Is it okay like
  this or do you want me to kick them out at all?}  \KR{A: I think we should give terms in
  connection with the examples below, and make sure to explain that some are incorrectly sorted.}
\MS{Okay, I am on it!} \KR{Looking forward to it: if it works we should perhaps not collect all the
  figures on one page but use individual [h!t] figures? I added one more example, as you can see, for
even more interesting combinations…}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// N is natural number sort
N data Z ;                                            // zero
N data S(N) ;                                         // successor
N scheme Plus(N, N) ;                                // $+$ operator
N rule Plus(Z, #2) →  #2 ;                           // $0+x = x$
N rule Plus(S(#1), #2) →  S(Plus(#1, #2)) ;          // $(1+x)+y=1+(x+y)$
  \end{hacs}
  \vspace*{-1ex}
  \caption{Peano numerals.}
  \label{fig:peano}
\end{figure}

\begin{example}[Peano]\label{ex:peano}
  The classical first order Peano arithmetic rules are a simple \hax system, shown in
  Figure~\ref{fig:peano}.  The example illustrates how a sort is defined with data constructors and
  a scheme for rewriting. The example illustrates the following points:
  %%
  \begin{itemize}

  \item The defined sort is "N". All the other declarations define artifacts of sort~"N". (Notice
    that we have omitted the empty sort parameter list, it is really "N⟨⟩".)

  \item There are two \kw{data} constructors declared: "Z" with no parameters, and "S" with a single numeric
    argument.
%% The single numeric argument is specified as "[]N[]" because it has no locally scoped
%%    binders ("[]"$_-$) and the "N" sort has no sort parameters ($_-$"[]").
%%    \CK{This formulation (and likely some of the following ones) should be changed if the
%%    more readable version of the figures is kept (which I think is a good idea!).  Could make that
%%    something on the lines of explaining that N should be read []N[].}

  \item There is a single function (\kw{scheme}) constructor, "Plus", with two numeric arguments.

  \item There are two \kw{rule}s for the function symbol, implementing the usual Peano addition rules.

  \end{itemize}
  %%
  A sample rewrite sequence using this system, corresponding to the computation $1+1=2$, is
  %%
  \begin{displaymath}
    "Plus(S(Z), S(Z))" →
    "S(Plus(Z, S(Z)))" →
    "S(S(Z))"
  \end{displaymath}
\end{example}
%%
%% \MS{May I drop the empty parenthesis in Example~\ref{ex:peano}, Figure~\ref{fig:peano},
%%   Figure~\ref{fig:lambda}, and Figure~\ref{fig:list}? They create a lot of noise.}
%% \KR{Yes, done.}

%%\begin{remark}
%%  One difference between the CRSX family, including \hax, and other higher order rewriting
%%  formalisms, is that the binder mechanism is part of the parent construction, \eg, the sort of the
%%  "S" constructor defines that instances must have the shape "S([]…)" with "…" being itself a Peano
%%  number.  Otherwise, binding and substitution are in the style of CRS higher order rewrite
%%  systems~\cite{Klop+:tcs1993}.\footnote{The notation does differ from the original CRS notation in
%%    that we use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$,
%%    and we use square brackets instead of round for meta-application arguments.}
%%\end{remark}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Λ is the sort of λ terms
Λ  data Lm([Λ]Λ) ;                                        // abstraction
Λ  scheme Ap(Λ, Λ) ;                                      // application
Λ  rule Ap(Lm([x]#body(x)), #arg) → #body(#arg) ;     // β-reduction
  \end{hacs}
  \vspace*{-1ex}
  \caption{Untyped λ calculus.}
  \label{fig:lambda}
\end{figure}

\begin{example}[untyped λ calculus]\label{ex:lambda}
  The untyped λ calculus is shown in \hax in Figure~\ref{fig:lambda}.  The declarations can be
  explained as follows:
  %%
  \begin{itemize}

%%  \item The "Λ" sort includes a special "variable" case to indicate that variables can occur in
%%    terms. \CK{Should there be a qualifier like ``unbound'' in this sentence?}
%%    \KR{Perhaps---suggestions?} \MS{Wouldn't Figure~\ref{fig:list} then also require \kw{variable}?
%%      It uses variables ($x, \beta, \alpha$) as well. However, neither Figure~\ref{fig:list} nor
%%      Figure~\ref{fig:lambda} use unbound variables. What exactly do we want to express with the
%%      \kw{variable}?} \KR{A: Fixed?} 
%%    \CK{Definitely not! I think it became worse, actually. :)  The variable in this example is
%%      of type $\alpha$, not of list type, so the variable indicator doesn't refer to it.  Also,
%%      for what I've understood of syntactic, not every variable is syntactic!  If my attempted
%%      explanation earlier is correct, I don't mind rephrasing this sentence, but would prefer to
%%      do so only after we resolve whether to call terms and meta-terms something different. :)}

  \item "Λ" includes an abstraction construction, which is a "data" case, and which includes a
    subterm with a single binder scoped over that subterm. The scoped subterm is written as
    "[Λ]Λ", which should be read as ``a subterm with a locally bound variable of sort "Λ" and a
    body of sort "Λ" in which it can occur.''

  \item "Λ" includes a usual case for application construction, which is a "scheme" because it
    can (sometimes) be rewritten.

  \item We specify one rewrite "rule" for "Λ": β-reduction. As usual, the rule specifies how an
    application of an abstraction is simplified. The interesting aspect of the pattern is how the
    abstraction is matched: the part of the pattern "[x]#body(x)" means ``the scoped subterm with
    binder "x" and subterm "#bind" wherein we keep track of where "x" occurs.'' Note the similarity
    to the declaration of the subterm of the "Lm" constructor.

  \item Once an application of an abstraction is matched, the "rule" gives the result of
    simplification as "#body(#arg)", which means that we construct a copy of "#body" except all
    occurrences of the variable we matched (and kept track of) in the pattern "#body(x)" are
    substituted with what "#arg" matched.

    \KR{Note: the variable declaration has been removed as it was incorrect here.}

  \end{itemize}
  %%
  A usual λ term like $(λx.x x)(λy.y)$ is represented as
  \begin{displaymath}
    "Ap(Lm([x]Ap(x, x)), Lm([y]y))"    
  \end{displaymath}
  and simplifies like this:
  %%
  \begin{displaymath}
    "Ap(Lm([x]Ap(x, x)), Lm([y]y))" →
    "Ap(Lm([y]y), Lm([y]y))" →
    "Lm([y]y))"
  \end{displaymath}
  %%
\end{example}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
List⟨α⟩ data Nil; List⟨α⟩ data Cons(α, List⟨α⟩);

List⟨α⟩ scheme Append(List⟨α⟩, List⟨α⟩);
List⟨α⟩ rule Append(Nil, #2) →  #2;
List⟨α⟩ rule Append(Cons(#11, #12), #2) →  Cons(#11, Append(#12, #2));

List⟨α⟩ scheme Map([β]α, List⟨β⟩);
List⟨α⟩ rule Map([x]#(x), Nil) →  Nil;
List⟨α⟩ rule Map([x]#(x), Cons(#1, #2)) →  Cons(#(#1), Map([x]#(x), #2));
  \end{hacs}
  \vspace*{-1ex}
  \caption{Polymorphic lists.}
  \label{fig:list}
\end{figure}

\begin{example}[lists]\label{ex:list}
  Figure~\ref{fig:list} shows a standard definition of polymorphic lists over an arbitrary element
  sort.  The target sort "List⟨α⟩" is a usual polymorphic way to express a list of members of an
  unspecified parameter sort~"α".  Inside the scope of the "sort" declaration, "α" denotes the
  member sort of the result list of all constructs.

  \TBD{Example evaluation.}
  %%
\end{example}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Abstract Syntax.
Program⟨α,β⟩ data Block(α, β, Program⟨α,β⟩);
Program⟨α,β⟩ data Then(Program⟨α,β⟩, Program⟨α,β⟩);
Program⟨α,β⟩ data Stat(α);

// Type Environment.
Γ⟨α,β⟩ data Env({α:β});

// Create environment from Program
Γ⟨α,β⟩ scheme Mk(Program⟨α,β⟩);
Γ⟨α,β⟩ rule Mk(Stat(#)) → Env({});
Γ⟨α,β⟩ rule Mk(Then(#1, #2)) → Union(Mk(#1), Mk(#2));
Γ⟨α,β⟩ rule Mk(Block(#x, #t, #)) → Union(Env({#x:#t}, Mk(#)));

// Helper to create union of two environments.
Γ⟨α,β⟩ scheme Union(Γ⟨α,β⟩, Γ⟨α,β⟩);
Γ⟨α,β⟩ rule Union(Env({:#1}), Env({:#2})) → Env({:#1,:#2});
  \end{hacs}
  \caption{Type environment over simple AST.}
  \label{fig:te}
\end{figure}

\begin{example}[environment handling]\label{ex:te}
  %%
  Figure~\ref{fig:te} shows sorts and rules for 
  %%
\CK{This example is interesting, because it combines two catchers in
the same association set on the right! I wonder how that's defined.
(Although it's easily avoided if undesirable, by simply replacing the
``union'' by an ``add''.)}
\KR{Indeed! I think Lionel has it implemented as ``add''…but here we should describe the ideal as
  long as it allows for add, I think.}
\CK{So what \emph{should} the semantics be?  If there are conflicting
  pairs in \#1 and \#2, what happens? Does the first or the second take
  priority, or should it crash?}
\LV{Yes it's implemented as add. In this case the semantic could
be \#2 is added to \#1. Entries in \#2 override entries in \#1.}
\end{example}

\begin{figure}[h!t]
  \begin{hacs}[numbers=right,texcl]
// Booleans with conditional.
Bool data True; Bool data False; α scheme If(Bool, α, α);

// Pick number.
Int scheme Pick(List⟨Int⟩, [Int,Int]Bool);
Int rule Pick(#, [x,y]#pick(x,y)) → Pick2(#, [x,y]#pick(x,y), N);

Int scheme Pick2(List⟨Int⟩, [Int,Int]Bool, Int);
Int rule Pick2(Nil, [x,y]#pick(x,y), #n) → #n;
Int rule Pick2(Cons(#1, #rest), [x,y]#pick(x,y), #n)
  → Pick2(#rest, [x,y]#pick(x,y), #pick(#1,#n));
  \end{hacs}
  \caption{Find largest element of list of integers.}
  \label{fig:pick}
\end{figure}

\begin{example}[]\label{ex:pick}
  %%
  Figure~\ref{fig:pick} shows a simple ``pick a number from a list'' program (assuming the "List"
  sort from Example~\ref{ex:list}).

  \CK{This example seems incomplete.  For example, what's N? Is that meant to
  be 0? It's not declared; we have thus far only seen Z (of sort N, not Int).
  But if you want the largest element (as the caption suggests) of a list of
  \emph{integers}, defaulting to 0 does not seem like a good idea!  Also, the
  figure declares booleans and an if scheme, but does not use them.  Oh, and
  the second Pick2 rule is not well-typed (as the third argument of the RHS
  has type Bool rather than Int).}
  \KR{Yep, its a bit sketchy. Anyone?}
  %%
\end{example}

\KR{Below are new examples for your consideration.}

\begin{example}
  %%
  Another example from the literature: $λ$x~\cite{BlooRose:csn1995}. Changes the λ calculus from
  Example~\ref{ex:lambda} in two ways:
  %%
  \begin{enumerate}

  \item Variables are made \emph{syntactic}: they are declared with "variable", so they can be
    matched in rules but only substituted by variables.

  \item The β-reduction rule is replaced with a new scheme "Ex", which performs the substitution
    explicitly, without referring to the primitive substitution of \hax except for renaming.

  \end{enumerate}
  %%
  \begin{hacs}
     Λx variable; // explicit variable
     Λx data Lm([Λx]Λx); // abstraction
 
     Λx scheme Ap(Λx,Λx); // application
     Λx rule Ap(Lm([x]#(x)),#x) → Ex([x]#(x),#x);  //(b)
 
     Λx scheme Ex([Λx]Λx,Λx); // explicit substitution
     Λx rule Ex([x]x,#x) → #x;  // (xv)
     Λx rule Ex([x]y,#x) → y;   // (xvgc)
     Λx rule Ex([x]Ap(#f(x), #a(x)), #x) →  Ap(Ex([x]#f(x),#x), Ex([x]#a(x),#x));  // (xap)
     Λx rule Ex([x]Lm([y]#(x,y)), #x) →  Lm([y]Ex([x]#(x,y), #x));                 // (xab)
  \end{hacs}
  %%
  \KR{Example shows that we need a way to ensure that (xv) is selected before (xvgc), \ie, in the
    original formalism all the rules are mutually exclusive. This is essentially saying that \hax
    fully contains the CRSx systes from Kris' thesis…}
  %%
\end{example}

\begin{example}
  %%
  Variation: evaluator with a proper environment. \TBD{Find proper reference.}
  %%
  \begin{hacs}
    Λρ  variable; // explicit variable
    Λρ  data Lm([Λρ]Λρ); // abstraction
    Λρ  data Ap(Λρ,Λρ); // application

    Λρ  scheme E(Λρ, {Λρ:Λρ}); // evaluation context

    Λρ  rule E(x, {x : #x}) → #x;
    Λρ  rule E(x, {¬x}) → x;
    Λρ  rule E(Lm([y]#(y)), {:#}) →  Lm([y]E(#(y), {:#}));

    Λρ  rule E(Ap(x, #a), {:#}) →  E(Ap(E(x, {:#}), E(#a, {:#})), {:#});
    Λρ  rule E(Ap(Ap(#f, #1), #2), {:#}) →   E(Ap(E(Ap(#f, #1), {:#}), E(#2, {:#})), {:#});
    Λρ  rule E(Ap(Lm([x]#(x)), #a), {:#}) →  E(#(x), {:#, x : E(#a,{:#})});
  \end{hacs}
  %%
  Notice how application is now data
  %%
  \KR{Finish it…the idea is one starts with Ec(term, \{\})…}
  %%
\end{example}


%------------------------------------------------------------------------

\section{Sorting}
\label{sec:sorting}

The \hax calculus in practice restricts the terms of the grammar in Figure~\ref{fig:syntax} further
by only allowing sortable scripts. Informally, sorting ensures that
%%
\begin{itemize}
\item the pattern and contraction restrictions are obeyed;
\item binders are used in the shape declared for constructors;
\item subterms (including variable and meta-variable occurrences) have the right sort;
\item attributes are used with properly sorted values;
\item attributes are used only on constructors for which they have been declared;
\item the attributes are the same on all data constructors of a given sort;
\item \emph{all} data terms of the same sort have the same attributes.
\end{itemize}
%%
If you check with the examples, then you can see that the examples all satisfy these restrictions
except Example~\ref{ex:bool}, which breaks the last of the above constraints. \TBD{Fix but how:
  patch example or rules?}

%% \CK{About the TBD: the example breaks the rule only because some data terms are
%% missing the $\mathit{val}$ attribute, right?  This ties in to my earlier
%% comment below Figure 1, although only a little: the attribute here should be a
%% catch-all meta-variable on the left, and the empty set on the right.  You can
%% actually do that with the syntax as given, but it would be quite ugly. \\
%% The most natural solution seems to be calling it syntactic sugar: we could
%% point out that Example~\ref{ex:bool} \emph{seems} to violate the rule, but
%% only due to syntactic sugar, as explained later?  Alternatively, we could
%% change the example.  To make it a bit less ugly, a possibility is to add a
%% sort $\mathtt{DecidedBool}$ with only true/false values, to be used as the
%% values for the attribute; typically, you'd probably want to know that those
%% values will in fact be true/false rather than a Not or Or.  This sort would
%% not need to have an attribute, so would save you from having to write an
%% addition attribute set inside an attribute set.}
%% \KR{A: Attributes are now gone: only map subterms remain! Is this alright?}

\begin{notation}[vectors]
  We will use \emph{vector notation} with $\ov{X}$ denoting $X_1,…,X_n$ for some $n≥0$; $ε$ denotes
  all empty vectors. Vectors are combined by simple concatenation, and will freely abuse this
  notation and, for example, write $\ov{[\ov{x}]x}$ as an abbreviation of
  $[x_{11}…x_{1m_1}]x_1…[x_{n1}…x_{nm_n}]x_n$ for suitable $n,m_1,…,m_n ≥ 0$.
\end{notation}

\begin{figure*}[p]
  \vspace*{-3em}
  \begin{align}
    %
    \intertext{\shoveright{Sorting of \hax script \hfil \fbox{$ ⊢ H $}}}
    %
    &\dfrac
    { Γ ⊢ D_1 \quad\cdots\quad Γ ⊢ D_n }
    { ⊢ D_1…D_n }
    && (∃Γ)
    \tag{S-H}
    %
    \\
    \intertext{\shoveright{Sorting of Declaration\hfil\fbox{$ Γ ⊢ D $}}}
    %
    &\dfrac
    {}
    { Γ ⊢ s⟨\ov{α}⟩~\kw{data}~d\kw( \ov{F} \kw)\,\kw; }
    && Γ_{\op{cons}}(d) = \left⟨ s⟨\ov{α}⟩, \ov{F} \right⟩
    \tag{S-D-Data}
    %
    \\[\jot]
    %
    &\dfrac
    {}
    { Γ ⊢ S~\kw{scheme}~f\kw( \ov{F} \kw)\,\kw; }
    && Γ_{\op{cons}}(f) = \left⟨ S, \ov{F} \right⟩,~f∈Γ_{\op{fun}}
    \tag{S-D-Fun}
    %
    \\[\jot]
    %
    &\dfrac
    {}
    { Γ ⊢ s⟨\ov{α}⟩~\kw{variable}\,\kw; }
    && s ∈ Γ_{\op{hasvar}}
    \tag{S-D-Var}
    %
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},ε ⊢ f(\ov{F}) : S  \qquad Γ,Δ,\op{Con},ε ⊢ M : S }
    { Γ ⊢ S~\kw{rule}~f(\ov{F})~\kw{→}~M\,\kw; }
    && (∃Δ),~f∈Γ_{\op{fun}}
    \tag{S-D-Rule}
    %
    \\
    \intertext{\shoveright{Sorting of Term\hfil\smash{\fbox{$ Γ,Δ,RS,\ov{\mathcal{V}} ⊢ M : S $}}}}
    %
    &\dfrac
    { Γ,Δ,RS,\ov{w} ⊢ P_1 : F_1 \quad\cdots\quad Γ,Δ,RS,\ov{w} ⊢ P_n : F_n }
    { Γ,Δ,RS,\ov{w} ⊢ c\,\kw(\,P_1\kw,…\kw,P_n\,\kw) : S }
    &&\Cases{
      Γ_{\op{cons}}(c) = \left⟨ S, (F_1\kw,…\kw,F_n) \right⟩\\
      c∉Γ_{\op{fun}} ∨ RS=\op{Con}
    }
    \tag{S-M-Cons}
    % 
    \\[\jot]
    %
    &\dfrac
    { }
    { Γ,Δ,RS,\ov{w} ⊢ v : s⟨\ov{S}⟩ }
    && Δ_{\op{var}}(v) = s⟨\ov{S}⟩, ~s∈Γ_{\op{hasvar}}
    \tag{S-M-Var}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},\ov{w} ⊢ v_1 : S_1 \quad\cdots\quad  Γ,Δ,\op{Pat},\ov{w} ⊢ v_n : S_n }
    { Γ,Δ,\op{Pat},\ov{w} ⊢ m\,\kw(\,v_1\kw,…\kw,v_n\,\kw) : S }
    &&\Cases{
      ∀i\colon v_i∈\ov{w} \\
      Δ_{\op{meta}}(m) = [(S_1,…,S_n)⇒S]
    }
    \tag{S-M-MetaP}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Con},\ov{w} ⊢ M_1 : S_1 \quad\cdots\quad  Γ,Δ,\op{Con},\ov{w} ⊢ M_n : S_n }
    { Γ,Δ,\op{Con},\ov{w} ⊢ m\,\kw(\,M_1\kw,…\kw,M_n\,\kw) : S }
    && Δ_{\op{meta}}(m) = [(S_1,…,S_n)⇒S]
    \tag{S-M-MetaC}
    %
    \\
    \intertext{\shoveright{Sorting of Piece\hfil\smash{\fbox{$ Γ,Δ,RS,\ov{\mathcal{V}} ⊢ P : F $}}}}
    %
    &\dfrac
    { Γ,Δ',RS,(\ov{w}\,\ov{v}) ⊢ M : S }
    { Γ,Δ,RS,\ov{w} ⊢ \kw[\,\ov{v}\,\kw]\,M : \kw[\,\ov{S}\,\kw]\,S }
    && (∃Δ'⊇Δ),~ Δ'_{\op{var}}(\ov{v}) = \ov{S}
    \tag{S-P-Bind}
    %
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,RS,\ov{w} ⊢ A_1 : \{S_1{:}S_2\} \quad\cdots\quad Γ,Δ,RS,\ov{w} ⊢ A_n : \{S_1{:}S_2\} }
    { Γ,Δ,RS,\ov{w} ⊢ \kwm\{\,A_1\kw,…\kw,A_n\,\kwm\} : \kwm\{S_1\kw:S_2\kwm\} }
    \tag{S-P-Assoc}
    %
    \\
    \intertext{\shoveright{Sorting of Association\hfil\smash{\fbox{$ Γ,Δ,RS,\ov{\mathcal{V}} ⊢ A : \{S{:}S\} $}}}}
    %
    &\dfrac
    { Γ,Δ,RS,\ov{w} ⊢ M_1 : S_1 \qquad Γ,Δ,RS,\ov{w} ⊢ M_2 : S_2 }
    { Γ,Δ,RS,\ov{w} ⊢ M_1\kw:M_2 : \{S_1{:}S_2\} } 
    \tag{S-A-Map}
    % 
    \\[\jot]
    %
    &\dfrac
    { Γ,Δ,\op{Pat},\ov{w} ⊢ M : S_1 }
    { Γ,Δ,\op{Pat},\ov{w} ⊢ \kwm{¬}M : \{S_1{:}S_2\} }
    \tag{S-A-Not}
    % 
    \\[\jot]
    %
    &\dfrac
    { }
    { Γ,Δ,RS,\ov{w} ⊢ \kw:m : \{S_1{:}S_2\} }
    && Δ_{\op{meta}}(m) = \{S_1{:}S_2\}
    \tag{S-A-All}
    %
  \end{align}
  \caption{\hax sorting rules.}
  \label{fig:sortrules}
\end{figure*}

\begin{definition}[well-sorted]\label{def:sort}
  Given a \hax script $H$, a sort $\op{Void}∈S$ which does not occur in $H$, and a sort environment
  $Γ$, and define the additional pseudo-syntax rules
  %%
  \begin{align}
    RS &::= \op{Pat} \mid \op{Con} \tag{RuleSide} \\
    MF &::= [\ov{S}⇒S] \mid \{S_1{:}S_2\} \tag{MetaForm}
  \end{align}
  %% 
  The \hax script is \emph{well-sorted for $Γ$} if $Γ$ is the smallest sort environment for which we
  can prove
  %%
  \begin{displaymath}
    ⊢ H
  \end{displaymath}
  %%
  using the rules of Figure~\ref{fig:sortrules}.

  Each proof will need to invent a \emph{global sort environment} witness $Γ$, a structure that
  combines
  %% 
  \begin{itemize}

  \item $Γ_{\op{hasvar}}\colon 2^{\mathcal{C}}$ is a set of sorts names (the sorts that allow variables).

  \item $Γ_{\op{cons}}\colon \mathcal{C} → S×F^*$ from constructor name to pairs of a sort and a
    list of forms.

    
  \item $Γ_{\op{fun}}\colon 2^{\mathcal{C}}$ is a set of constructor names (those declared as schemes).

  \end{itemize}
  %%
  and one \emph{rule sort environment} witness $Δ$ per rule, a structure that combines
  %% 
  \begin{itemize}

  \item $Δ_{\op{var}}\colon \mathcal{V} → S$ from variable names to sorts.

  \item $Δ_{\op{meta}}\colon \mathcal{M} → MF$ from meta-variable names to to 
    names to ``meta-forms'' 

  \end{itemize}
  %%
\end{definition}

Notes.
%%
\begin{itemize}

\item $MF$ captures the difference between regular meta-variables and ``$\kw:m$'' ones:
  \begin{itemize}

  \item The shape $[\ov{S}⇒S]$ is used for meta-variables that need to be meta-applied to
    arguments with the sorts $\ov{S}$ to then form a term of the sort~$S$.
      
  \item The shape $\{S_1{:}S_2\}$ used for meta-variables that ``catch'' all the associations in
    an association list from $S_1$ to~$S_2$.
    
  \end{itemize}

  \item\TBD{More explanation.}
    
\end{itemize}

\TBD{Example sort derivation.}

%------------------------------------------------------------------------

\section{Rewriting}
\label{sec:rewriting}

In this section we formally define rewriting in the \hax calculus. We follow [\TBD{Cynthia?}] in
defining rewriting in the context of a sort assignment.

\begin{definition}[substitution]
  
\end{definition}

\TBD{mv, fv, substitution, rewriting.}

\begin{theorem}[subject reduction]
  Given a well-sorted \hax script $H$ with the rewrite 


A well-sorted term can only rewrite to a well-sorted term.
\end{theorem}

%------------------------------------------------------------------------

\section{Properties}
\label{sec:properties}

In this section we provide proofs for several standard rewrite properties of~\hax.

\TBD{What do we know of properties of such a system…Cynthi or Maria or Julian?
  \\
  Also: decidability of type checking, possibly type inference?}


%------------------------------------------------------------------------

\section{Implementing \hax}
\label{sec:implement}

In this section we give notes on how we see \hax implemented. The implementation uses classic term
graph rewriting extended to handle binders and associations.

The basic \hax implementation consists of a term representation and a main ``progress loop.''

\begin{definition}[identifiers]
  %%
  In the implementation we keep track of the following \emph{identifiers}:
  %%
  \begin{itemize}

  \item \emph{Variable identifiers}. A variable identifier is globally unique. It should be suitable
    for \emph{comparison} and \emph{hashing}.

  \item \emph{Constructor identifiers}. A constructor identifier is globally unique and suitable for
    hashing. From the constructor identifier one can derive the kind and signature of the
    constructor:
    \begin{itemize}
    \item Is it a function or data constructor? Data constructors should be suitable for use as C
      switch keys.
    \item How many scope-formed formal arguments (declared as $[S^*]S$) does the constructor take,
      and how many local variables are bound by each?
    \item How many association-formed formal arguments (declared as $\{S:S\}$) does the constructor
      take?
    \end{itemize}
    Note that everything is assumed to be well-sorted.

  \end{itemize}
  %%
  In addition, both forms of identifiers support \emph{printing} the identifier in an identifiable
  fashion [sic].
  %%
\end{definition}

\begin{structure}[term representation]
  %%
  Terms are maintained as a graph structure with nodes containing:
  %%
  \begin{itemize}
  \item Constructor identifier.
  \item Reference count.
  \item Pointer to cached free variable set (more on this below).
  \item Array of free variable identifiers (with length as required by constructor to cover all
    scopes).
  \item Array of pointers to scoped subterms (with length as required by the constructor).
  \item Array of association sets (with length as required by the constructor).
  \end{itemize}
  %%
\end{structure}

\begin{structure}[association set]
  
\end{structure}



\TBD{What about dispatchification…Maria?}




%------------------------------------------------------------------------

\section{Supporting Compiler Paradigms}
\label{sec:compiling}

In this section we outline how the standard compiler construction idioms of the full \HAX language
translate into~\hax.

\begin{definition}[higher order inference rule]\label{def:infer}%
  %%
  A (higher order) \emph{inference rule} has the form
  %%
  \begin{displaymath}
    \dfrac
    { ∀\,\ov{x} : (\, C_1⇒P_1 ~\cdots~ C_n⇒P_n \,) }
    { P_0 ⇒ C_{n+1}}
    ~(L)
  \end{displaymath}
  %%
  where
  %%
  \begin{itemize}
  \item $L$ is the unique name of the rule.
  \item $P_0$ and all of $C_1,…,C_n$ are \emph{function constructions}.
  \item $P_0$ is a \emph{pattern} and all of $P_1,…,P_n$ are \emph{pattern fragments}.
  \item $∀i : \op{mv}(C_i) ⊆ \op{mv}(P_0…P_{i-1})$.
  \end{itemize}
  %%
  The \emph{inference simplification system} for the above rule is the system
  %%
  \begin{align}
    P_0 &→ L_1(P_0, [\ov{x}]C_1) \tag{$L_0$}\\
    L_1(P_0, [\ov{x}]P_1) &→ L_2(P_0, [\ov{x}]P_1, [\ov{x}]C_2) \tag{$L_1$}\\[-\jot]
    &~~\vdots\notag\\
    L_{n-1}(P_0, [\ov{x}]P_1, …, [\ov{x}]P_{n-1}) &→ L_n(P_0, [\ov{x}]P_1, …, [\ov{x}]P_{n-1}, [\ov{x}]C_n) \tag{$L_{n-1}$}\\
    L_n(P_0, [\ov{x}]P_1, …, [\ov{x}]P_n) &→ C_{n+1} \tag{$L_n$}
  \end{align}
  %%
  (where all symbols, including the variables $\ov{x}$, are the same as in the initial rule). All
  these rules need to be part of the "sort" declaration for the sort of $P_0$ and $C_{n+1}$, along
  with "scheme" declarations for all the introduced $L_i$ symbols.
  %%
\end{definition}

\begin{example}
  \TBD{Example inference simplification.}
\end{example}

We can prove that the inference simplification system for an inference rule implements the same
semantics for non-overlapping $P_0$s. Even with an identical prefix $P_0,\ov{x},C_1$ for two rules,
the system can be generated: in that case the two $L_1$ symbols of the rules must be aliased to a
common function symbol; in general $L_1…L_k$ must be collapsed for identical prefixes
$P_0,\ov{x},C_1,P_1, C_2,…,P_{k-1}, C_k$. \TBD{Explain?}

%------------------------------------------------------------------------

\section{A Constraint Model}
\label{sec:constraints}

In this section, we introduce a notion of \emph{constraint associations} and primitives for
\emph{constraint solving}.

\TBD{Develop this…Eva?}

%------------------------------------------------------------------------

\section{Conclusion}
\label{sec:conc}

With \hax, we have presented a rather small calculus that can serve as the underlying formalism for
reasoning about as well as implementing the \CRSX and \HAX languages.

\TBD{What is covered.}

~\cite{Knuth:mst1968} 
~\cite{Aho+:2006}


\paragraph*{Related work.}

We would like to give credit to SIS~\cite{Mosses:daimi1979}, which shares with \hax the use of
\emph{simplification} using a λ-calculus based formalism.

The most prominent system that supports implementation of compilers in formal (rewriting and
attribute grammar) form is ASF+SDF~\cite{Brand+:toplas2002}, which is based on first order
rewriting. While modules have been added for symbol table management, these lack the full
integration and easy way to handle scoped intermediate languages. The successor,
Rascal~\cite{Bos+:eptcs2011} adds a module for HOAS, but Rascal specifications operate in a world of
side effects, which we find hard to reconcile with higher-order term structures (with scopes).

The notion of ``higher-order'' used by \hax is similar to but not quite the same as in higher-order
attribute grammars (HAG)~\cite{VogtSwierstraKuiper:pldi1989}. Like HAGs, \hax specifications permit
constructing and passing of abstract syntax fragments in attributes but the ``higher order'' aspect
of \hax also covers the rewriting side, where we can build parameterized abstractions over any part
of a specification, including with attributes. Indeed, one can use substitution inside attributes,
and have absence of attributes and substitution block rewriting.

\paragraph*{Future work.} \TBD{Speculate!}


\paragraph*{Acknowledgements.} \TBD{Thank everyone.}

EU-funded Marie Skłodowska-Curie ``HORIP'' action collaboration with Cynthia Kop.


%------------------------------------------------------------------------

\bibliography{crs}


\TBD{End of sane part.}
\hrule
\vspace*{1pc}

%------------------------------------------------------------------------
\appendix

\section{Bra-Ket}

\KR{Just for fun: Here is ``bra-ket'' notation (from physics), also kind of cool. I'd love this, and
  it would be different and make us associate even more to the \hax symbol. The explanation then
  associates a \emph{bra} with a binder state and a \emph{ket} with a substitution of it.}
\CK{That's\dots\ very weird to me. But then, I never did physics after high school! But in general,
  I think this notation is unlikely to appeal to rewriters.}
\begin{align}
  \tag{\hax{}Script}
  H &::= D^* 
  \\
  \tag{Declaration}
  D &::= S~\kw{data}~d\,\kw(\,F^{*\kw,}\,\kw)\,\kw;
  \bigm| S~\kw{scheme}~f\,\kw(\,F^{*\kw,}\,\kw)\,\kw;
  \bigm| S~\kw{variable}\,\kw;
  \bigm| S~\kw{rule}~M~\kw{$→$}~M\,\kw;
  \\
  \tag{Form}
  F &::= \kwm{⟨}\,S^{*\kw,}\,\kwm|\,S
  \bigm| \kwm\{\, S:S \,\kwm\}
  \\
  \tag{Sort}
  S &::= s\,\kw[\,S^{*\kw,}\,\kw]
  \bigm| α
  \\[\jot]
  \tag{Term}
  M &::= c\,\kw(\,P^{*\kw,}\,\kw)
  \bigm| v
  \bigm| m\,\kwm|\,M^{*\kw,}\,\kwm{⟩}
  \\
  \tag{Piece}
  P &::= \kwm{⟨}\,v^{*\kw,}\,\kwm|\,M
  \bigm| \kwm\{\, A^{*\kw,} \,\kwm\}
  \\
  \tag{Association}
  A &::= M\,\kw:\,M
  \bigm| \kw{$¬$}\,M
  \bigm| \kw:\,m
\end{align}
\KR{We now distinguish \emph{five} different ways to brace elements; all empty can be omitted
  except associations.
  For data and scheme \emph{subterms}, we use $\kw{( )}$.
  For \emph{binders} we use $\kwm{⟨~|}$.
  For \emph{meta-application arguments} we use $\kwm{|~⟩}$.
  For \emph{associations} we use $\kwm{\{\,\}}$.
  For \emph{sort parameters} we use $\kwm{[\,]}$.}
\begin{hacs}
  List[α] scheme Map(⟨β|α, List[β]);
  List[α] rule Map(⟨x|#|x⟩, Nil) →  Nil;
  List[Int] rule Map(⟨x|#|x⟩, Cons(#1, #2)) →  Cons(#|#1⟩, Map(⟨x|#|x⟩, #2));
  Int scheme Pick(List[Int], ⟨Int,Int|Bool);
  Int rule Pick(#, ⟨x,y|#p|x,y⟩) → If(#p|#,#⟩, Pick(#, ⟨x,y|#p|x,y⟩), #);
\end{hacs}

\section{Sugar}

\begin{notation}
  %% 
  \HAX permits some additional syntactic sugar:
  %% 
  \begin{itemize}

  \item Empty parenthesis and brackets can be omitted.

  \item The \kw{data} and \kw{rule} keywords can be omitted.

  \item \TBD{Update to simplified syntax.} Sort cases can be written with \kw{\texttt{|}} and without
    \kw{\texttt{\{\}}}…

  \item "attribute" declarations can be combined: $"attribute"~a_1~\set{AF}_1,…, a_n~\set{AF}_n ;$
    is an abbreviation of $"attribute"~a_1~\set{AF}_1;…; "attribute"~a_n~\set{AF}_n;$.

  \item An additional SortCase contruct is allowed:
    \begin{displaymath}
      \kw{template}~P~\kw{$→$}~M\,\kw;  \quad⇒\quad
      \kw{scheme}~P'\,\kw; ~ \kw{\texttt{|}} ~ \kw{data} ~ T'\,\kw; ~ \kw{rule} ~ P~\kw{$→$}~M\,\kw;
    \end{displaymath}
    where $P'$ and $T'$ are variants of $P$ and $P$ that have been cleared of "#"s.

  \item Finally, we rewrite special \emph{synthesis rules}:
    \begin{displaymath}
      c(\,\ov{\set{PB}}\,)~→~\ov{↑a~\set{V}}\,\kw;
      \quad⇒\quad
      \kw{rule}~c(\,\ov{\set{PB}}\,)~→~c(\,\ov{\set{PB}'}\,)~\ov{↑a~\set{V}}\,\kw;
    \end{displaymath}
    where $\set{PB}_i'$ is $\set{PB}_i$ with negative attribute patterns $\{¬{…}\}$ removed.

  \item We rewrite special \emph{inheritance rules}:
    \begin{displaymath}
      c(\,\ov{\set{PB}}\,)~→~\ov{↓v~\set{V}}\,\kw;
      \quad⇒\quad
      \kw{rule}~c(\,\ov{\set{PB'}}\,)~\ov{↓v~\set{V}}~→~c(\,\ov{\set{PB}'}\,)\,\kw;
    \end{displaymath}
    where 

  \item As defined below, every term $f(…)\ov{A}$ for a symbol $f$ defined with
    \begin{displaymath}
      \kw{\texttt{|} scheme}~f\,\kw(…\kw)~\ov{\set{AI}}
    \end{displaymath}
    must include an $A_i$ instance for every attribute defined by some $\set{AI}_i$.  The system
    automatically includes missing inherited attributes as follows:
    \begin{itemize}
    \item In patterns, a missing attribute is inserted as "↓a(#a)" or "↓a{:#a}" as appropriate.
    \item Missing attributes that were defined in the pattern are inserted the same.
    \item Remaining missing attributes must be of a map sort and are inserted as~"↓a{}".
    \end{itemize}

  \item We allow two more forms of \set{PA}:
    \begin{displaymath}
      \set{PA} ::= {…} \bigm| \kw{$↑$}\,m \bigm| \kw{$↓$}\,m
    \end{displaymath}
    They expand to all relevant synthesized and inherited attributes, respectively.

  \end{itemize}
\end{notation}

\begin{example}
  With syntactic sugar, we can simplify the Peano example to
  %%
  \begin{hacs}[numbers=right]
    sort N | Z | S(N) | scheme Plus(N, N) ;
    Plus(Z, S(#2)) → #2 ; 
    Plus(S(#1), #2) → S(Plus(#1, #2)) ;
  \end{hacs}
\end{example}

\begin{example}[untyped λ calculus]
  The untyped λ calculus is specified as follows in \hax with syntactic sugar:
  %%
  \begin{hacs}
    sort L | variable | Lm([x]Lam[x as L]) | scheme Ap(L, L) | x ;
    rule Ap(Lm([x]#body(x)), #arg) →  #body(#arg) ;
  \end{hacs}
  %%
  The example shows how binding is declared and used for substitution in the style of CRS
  systems~\cite{Klop+:tcs1993}:\footnote{The notation differs from the original CRS notation in that
    we use ``\#'' as a marker for meta-variables instead of the original reserved use of $Z$, and we
    use square brackets for substitution variables instead of round.}
  %%
  (Note that the same example in the (non-raw) full \HAX notation can include a parser for the
  native custom λ calculus syntax:
  %%
  \begin{hacs}
    token ID | [a-z] [a-z0-9_]* ;
    sort V | symbol ⟦⟨ID⟩⟧ ;
    sort L | ⟦λ⟨V binds x⟩.⟨L[x as L]⟩⟧ | scheme ⟦⟨L@1⟩⟨L@2⟩⟧@1
           | ⟦⟨V⟩⟧@2 | sugar ⟦(⟨L#⟩)⟧@2 →  #;
    ⟦ (λx.⟨L#body(x)⟩) ⟨L#arg⟩ ⟧ →  #body(#arg) ;
  \end{hacs}
  %%
  including precedence markers, syntactic sugar, \etc; for details see the full \HAX
  manual. Essentially the syntax-rich example translates to a parser and the former.)
\end{example}

\section{Inference Systems}
\label{sec:infer}

A common notation for specifying program analysis and …

A set of of inference rules is ...

\begin{definition}
  %%
  A \HAX \emph{ground sequential inference rule} has the form
  %%
  \begin{equation}
    \dfrac{ M_1 ⇒ P_1 \quad\cdots\quad M_n ⇒ P_n }{ P_0 ⇒ M_{n+1} }
    \label{eq:infer}
  \end{equation}
  %%
  where $n≥0$ and
  %%
  \begin{enumerate}
  \item $P_0$ (the \emph{initial} pattern) can be any \HAX pattern.
  \item $M_i$ (the \emph{tests}, $1≤i≤n$) are \HAX terms, and are allowed occurrences of meta-variables from $P_0…P_{i-1}$.
  \item $P_i$ (the \emph{constraints}, $i>0$) must be \HAX subpatterns.
  \item $M_{n+1}$ (the \emph{conclusion}) is allowed occurrences of all meta-variables.
  \end{enumerate}
  %%
  An inference rule with $n=0$ is called an \emph{axiom}, with $n>0$ a \emph{proper inference}.
  %%
  The $M_i⇒P_i$ over the line are called \emph{premise judgments}. The $P_0⇒M_{n+1}$ under the line
  is called the \emph{conclusion judgment}.
  %%
  Below we will vary the indexing scheme to capture various enumerations of sets of inference rules.
\end{definition}

\begin{definition}[pattern family]\label{def:patfam}
  Consider a set of ground sequential inference rules.  Such a set can obviously be indexed by the
  distinct initial patterns into families of rules
  \begin{displaymath}
    \dfrac{ M_{ij1} ⇒ P_{ij1} \cdots M_{ijn_{ij}} ⇒ P_{ijn_{ij}} }{ P_i ⇒ M_{ij} } ~(L_{ij})
  \end{displaymath}
  where all the $P_i$ used to index the family are pairwise distinct.  The groups obtained in this
  way are a \emph{pattern family}.
\end{definition}

\begin{definition}[leftmost matching]
  Consider a pattern family as in Definition~\ref{def:patfam}.  The family is said to be
  \emph{leftmost matching} if the group of rules for each $P_i$ satisfies one of the following
  conditions:
  \begin{itemize}
  \item either the family contains a single axiom, \ie, $1≤j≤1$ with $n_{ij}=0$,
  \item or the family contains only proper inferences, \ie, $1≤j≤m_i$ with $n_{ij}>0$.
  \end{itemize}
\end{definition}

%% Sub-index each non-axiom $P_i$-group by leftmost premise construction into sub-families of
%%    the form
%%    \begin{displaymath}
%%      \dfrac{ M_{ij} ⇒ P_{ijk1} \quad M_{ijk2} ⇒ P_{ijk2} \quad\cdots\quad M_{ijkn_{ijk}} ⇒ P_{ijkn_{ijk}} }{ P_i ⇒ T_{ijk} }
%%    \end{displaymath}
%%    where all the $T_{ij}$ used to index the sub-family within a $P_i$-group are pairwise disjoint.

\begin{definition}[left-operations]
  Given a leftmost-matching pattern family. Each $P$-indexed group of proper inference rules will
  have the following form:
  \begin{displaymath}
    \dfrac{ T_{j1} ⇒ P_{j1} \quad T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ P ⇒ T_j } ~ (L_j)
  \end{displaymath}
  with one $j$ per rule in the family, which is by definition non-empty ($1≤j≤n$) and contains only
  proper inferences ($n_j≥1$).
  %%
  \begin{enumerate}

  \item Given a label $L$, the \emph{left-flattening} rewrite rules of the group are
    %% 
    \begin{align*}
      L(P) &→ L'(T_{11}, …,T_{n1}, P) \\[\jot]
      L'(P_{11}, m_2, …, m_n, P) &→ L_1(P, P_{11}) \\[-\jot]
      &~\vdots\\
      L'(m_1, …, m_{n-1}, P_{n1}, P) &→ L_n(P, P_{n1})
    \end{align*}
    %% 
    with $L'$ a fresh symbol associated with the group and the $m_j$ fresh meta-variables.

  \item The \emph{left-eliminated} rules for the group are the rules
    \begin{displaymath}
      \dfrac{ T_{j2} ⇒ P_{j2} \quad\cdots\quad T_{jn_j} ⇒ P_{jn_j} }{ L_j(P, P_{j1}) ⇒ T_j } ~ (L'_j)
    \end{displaymath}
    with the $L'_j$ fresh labels derived from the $L_j$ labels.

  \end{enumerate}
\end{definition}

\begin{definition}[left-unfolded]
  Given a leftmost-matching pattern family and consider the proper inference rule group indexed by
  $P$. The following system is the \emph{left-unfolded} inference system for the $P$-indexed group:
  \begin{enumerate}

  \item The left-flattening rewrite rules of the group for a fresh~$L$.

  \item The new inference rule (which refers to the rewrite rules)
    \begin{displaymath}
      \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m } ~ (L)
    \end{displaymath}

  \item The left-eliminated inference rules (which may be axioms or proper inferences).

  \end{enumerate}
\end{definition}

\begin{proposition}
  Given a set of ground sequential inference rules, which is a leftmost-matching pattern
  family. Pick one group of proper inference rules, indexed by the initial pattern $P$. The original
  system and the system where the group has been replaced with the left-unfolded group have the same
  normal forms.
\end{proposition}
\begin{proof}
  Easy: full proof tree before corresponds to proof tree after with simple conversion of the
  eliminated eliminated premise to an application of the new rule and a single use of the rewrite
  rule.
\end{proof}

Note that we can only prove that full ``big-step'' evaluations are equivalent: the new rules may
``get stuck'' in interesting ways (\TBD{example with overlapping patterns}).

\begin{lemma}
  Start with any leftmost matching ground sequential inference rule system and apply left-unfolding
  repeatedly except on axioms and the introduced inference rules
  \begin{displaymath}
    \dfrac{ L(P) → m \quad m ⇒ m' }{ P ⇒ m }
  \end{displaymath}
  The resulting system has the same normal forms as the original system.
\end{lemma}

To finish the transform from inference rules to \HAX rules we need two additional notions.

\begin{definition}
  An inference system is \emph{rooted} if it has one rule that occurs as the root rule of every
  proof tree.
\end{definition}

\begin{definition}
  A leftmost-matching ground sequential inference rule system is \emph{left deterministic} if the
  left-flattening 
\end{definition}

\begin{theorem}
  A rooted and leftmost matching ground sequential inference system can be implemented by a 
\end{theorem}

\section{Attributes}

\begin{definition}[synthesized attributes]\label{def:synth}%
  %%
  A \emph{singleton synthesis rule} has the shape
  %%
  \begin{displaymath}
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{{↑}a_i\{{\cdots}\}}$\\
          $m_i[{\cdots}]\,{{↑}a_i\{{\cdots}\}}$
        }}\cdots\biggr)
    ~{{↑}a\{{\cdots}\}}
  \end{displaymath}
  %%
  (with the embedded subterms denoting all such subterms; the ``singleton'' restriction comes from
  the single synthesized attribute on all subterms).

  The \emph{synthesis simplification system} for the synthesis rule is
  %%
  \begin{align*}
    \op{Needs}_a\Biggl(
    c\biggl(\cdots \vcenter{\txt{
        $c_i({\cdots})$\\
        $m_i[{\cdots}]$
      }}\cdots\biggr)
    \Biggr)
    &→
    \op{Collect}\Biggl(
    c\biggl(\cdots \vcenter{\txt{
        $\op{Needs}_{{a_i}}(c_i({\cdots}))$\\
        $\op{Needs}_{{a_i}}(m_i[{\cdots}])$
      }}\cdots\biggr)    
    \Biggr)
    \\[1em]
    \op{Collect}\Biggl(
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{↑}a_i\{{\cdots}\}$\\
          $m_i[{\cdots}]\,{↑}a_i\{{\cdots}\}$
      }}\cdots\biggr)
    \Biggr)
    &→
    c\biggl(\cdots \vcenter{\txt{
          $c_i({\cdots})\,{↑}a_i\{{\cdots}\}$\\
          $m_i[{\cdots}]\,{↑}a_i\{{\cdots}\}$
        }}\cdots\biggr)
    ~{↑}a\{{\cdots}\}
  \end{align*}
  %%
\end{definition}

\begin{example}
  \TBD{Example synthesis simplification.}
\end{example}

\TBD{Discuss multiple dependent and independent synthesized attributes, and proof sketch that the
  simplification is correct; also the erasure of not-patterns, and check details from .}

\begin{definition}[inherited attributes]\label{def:synth}%
  %%
  \begin{align*}
    F\bigl(\cdots \vcenter{\txt{
          $A({·})\,{↑}a({·})$\\
          $X[{·}]\,{↑}x({·})$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    \cdots\vcenter{\txt{
        $B({·})\,{↑}b({·})$\\
        $Y[{·}]\,{↑}y({·})$}}
    \cdots\vcenter{\txt{
        $G({·})\,{↓}g({·})$\\
        $Z[{·}]\,{↓}z({·})$}}
    \cdots
    \\
    \intertext{becomes}
    %%
    F\bigl(\cdots \vcenter{\txt{
          $A({·})$\\
          $X[{·}]$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    F'\bigl(\cdots \vcenter{\txt{
          $\op{Needs}_a(A({·}))$)\\
          $\op{Needs}_x(X[{·}])$
        }}\cdots\bigr)
    {↓}c({·})
    \\[1em]
    F'\bigl(\cdots \vcenter{\txt{
          $A({·})\,{↑}a({·})$\\
          $X[{·}]\,{↑}x({·})$
        }}\cdots\bigr)
    {↓}c({·})
    &→
    \cdots\vcenter{\txt{
        $B({·})\,{↑}b({·})$\\
        $Y[{·}]\,{↑}y({·})$}}
    \cdots\vcenter{\txt{
        $G({·})\,{↓}g({·})$\\
        $Z[{·}]\,{↓}z({·})$}}
    \cdots
  \end{align*}
  %% 
\end{definition}

\end{document}


%------------------------------------------------------------------------
% Tell Emacs that this is a LaTeX document and how it is formatted:
% Local Variables:
% mode:latex
% fill-column:100
% TeX-master: t
% TeX-auto-untabify: nil
% End:
